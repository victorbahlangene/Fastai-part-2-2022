{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victorbahlangene/Fastai-part-2-2022/blob/main/Copy_of_03_pytorch_computer_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08f47c6a-3318-4e3f-8bb3-c520e00e63dd",
      "metadata": {
        "id": "08f47c6a-3318-4e3f-8bb3-c520e00e63dd"
      },
      "source": [
        "# 03. PyTorch Computer Vision\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0bedcfc-e12a-4a81-9913-84c6a888742a",
      "metadata": {
        "id": "a0bedcfc-e12a-4a81-9913-84c6a888742a"
      },
      "source": [
        "## 0. Computer vision libraries in PyTorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c263a60d-d788-482f-b9e7-9cab4f6b1f72",
      "metadata": {
        "id": "c263a60d-d788-482f-b9e7-9cab4f6b1f72",
        "outputId": "fe15f065-65dc-4314-b406-9a00dd4e5a34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 1.12.1+cu113\n",
            "torchvision version: 0.13.1+cu113\n"
          ]
        }
      ],
      "source": [
        "# Import PyTorch\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Import torchvision\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Import matplotlib for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check versions\n",
        "# Note: your PyTorch version shouldn't be lower than 1.10.0 and torchvision version shouldn't be lower than 0.11\n",
        "print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48d6bfe7-91da-44eb-9ab6-7c41c1e9fa8e",
      "metadata": {
        "id": "48d6bfe7-91da-44eb-9ab6-7c41c1e9fa8e"
      },
      "source": [
        "## 1. Getting a dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "486f8377-6810-4367-859d-69dccc7aef95",
      "metadata": {
        "id": "486f8377-6810-4367-859d-69dccc7aef95"
      },
      "outputs": [],
      "source": [
        "# Setup training data\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"data\", # where to download data to?\n",
        "    train=True, # get training data\n",
        "    download=True, # download data if it doesn't exist on disk\n",
        "    transform=ToTensor(), # images come as PIL format, we want to turn into Torch tensors\n",
        "    target_transform=None # you can transform labels as well\n",
        ")\n",
        "\n",
        "# Setup testing data\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False, # get test data\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.data.shape, test_data.data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcfDUoWS84fK",
        "outputId": "0bce4699-ff63-45f8-a168-19e396c435fb"
      },
      "id": "VcfDUoWS84fK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000, 28, 28]), torch.Size([10000, 28, 28]))"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a63246f6-3645-49de-88fe-ec18e78bfbaf",
      "metadata": {
        "id": "a63246f6-3645-49de-88fe-ec18e78bfbaf"
      },
      "source": [
        "Let's check out the first sample of the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43bfd3d9-a132-41e8-8ccd-5ae25a7da59a",
      "metadata": {
        "id": "43bfd3d9-a132-41e8-8ccd-5ae25a7da59a"
      },
      "outputs": [],
      "source": [
        "# See first training sample\n",
        "image, label = train_data[0]\n",
        "image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ad9d782-06cb-4591-ae3c-3a8b2389a1b2",
      "metadata": {
        "id": "9ad9d782-06cb-4591-ae3c-3a8b2389a1b2"
      },
      "source": [
        "### 1.1 Input and output shapes of a computer vision model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2997d9f-b574-4d23-aa34-1a4df1751226",
      "metadata": {
        "id": "c2997d9f-b574-4d23-aa34-1a4df1751226",
        "outputId": "c7bb524b-da84-4b42-9fab-4a440eaa1623",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "# What's the shape of the image?\n",
        "image.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bu1TqnlR9OmX",
        "outputId": "3fb707f7-b061-46bc-f2ce-1539baaffa3f"
      },
      "id": "bu1TqnlR9OmX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc4f768c-c3f6-454d-a633-673ad1d6eca0",
      "metadata": {
        "id": "fc4f768c-c3f6-454d-a633-673ad1d6eca0",
        "outputId": "091a26b2-cf67-40cd-e834-e0d0202152ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 60000, 10000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "# How many samples are there?\n",
        "len(train_data.data), len(train_data.targets), len(test_data.data), len(test_data.targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e22849c6-d93f-4b38-8403-5ebf0deaf008",
      "metadata": {
        "id": "e22849c6-d93f-4b38-8403-5ebf0deaf008",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0ce0e40-0269-4441-ae74-d7c86a4dc075"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['T-shirt/top',\n",
              " 'Trouser',\n",
              " 'Pullover',\n",
              " 'Dress',\n",
              " 'Coat',\n",
              " 'Sandal',\n",
              " 'Shirt',\n",
              " 'Sneaker',\n",
              " 'Bag',\n",
              " 'Ankle boot']"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "# See classes aka. vocab\n",
        "class_names = train_data.classes\n",
        "class_names"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb625d80-6a98-471e-a758-4de0ce0f3a64",
      "metadata": {
        "id": "fb625d80-6a98-471e-a758-4de0ce0f3a64"
      },
      "source": [
        "### 1.2 Visualizing our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1df1f2c-28c9-43bf-aaef-cf996c9ae1c5",
      "metadata": {
        "id": "b1df1f2c-28c9-43bf-aaef-cf996c9ae1c5",
        "outputId": "398822c0-4825-4010-c33e-fc56233b96d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: torch.Size([1, 28, 28])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "image, label = train_data[0]\n",
        "print(f\"Image shape: {image.shape}\")\n",
        "plt.imshow(image.squeeze()) # image shape is [1, 28, 28] (colour channels, height, width)\n",
        "plt.title(label);"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeKqy9wK97Fq",
        "outputId": "ac5aeb1e-121d-4e60-8f7c-11cb9bb45537"
      },
      "id": "VeKqy9wK97Fq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92f09917-88f7-4446-b65f-baae586914c9",
      "metadata": {
        "id": "92f09917-88f7-4446-b65f-baae586914c9",
        "outputId": "9418dc5c-6402-4d12-fba6-fd4d9382d86a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.imshow(image.squeeze(), cmap=\"gray\")\n",
        "plt.title(class_names[label]);"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "range(1, 4 * 4 + 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V27KWFGu-A-D",
        "outputId": "ea9320a9-2a1b-4a73-af06-55d0e4477565"
      },
      "id": "V27KWFGu-A-D",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(1, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQD7gf0M-TuX",
        "outputId": "37fcc3af-c3a6-409e-d441-47d0474aa2f5"
      },
      "id": "JQD7gf0M-TuX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randint(0, len(train_data), size=[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6IwRXBB-MsT",
        "outputId": "d2d1fedc-ee2c-4e1f-aa04-88791fe63935"
      },
      "id": "I6IwRXBB-MsT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([47210])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randint(0, len(train_data), size=[1]).item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lasBs8nO-MiS",
        "outputId": "33f4d50d-d3e4-4c2b-fce4-8547b04c2977"
      },
      "id": "lasBs8nO-MiS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18954"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = train_data[torch.randint(0, len(train_data), size=[1]).item()]\n",
        "X.shape, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5EvPapo-0Z-",
        "outputId": "b3bbdc37-7afd-4a23-ab71-33e9df75e8d0"
      },
      "id": "x5EvPapo-0Z-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 28, 28]), 9)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CBxGfA_r-0QI"
      },
      "id": "CBxGfA_r-0QI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iV0BnYrc-AxR"
      },
      "id": "iV0BnYrc-AxR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7188ed7a-5959-48c4-ac7f-19129a2adc83",
      "metadata": {
        "id": "7188ed7a-5959-48c4-ac7f-19129a2adc83",
        "outputId": "3555e279-1e4c-40dd-8914-ff77ccced8ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x648 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plot more images\n",
        "torch.manual_seed(42)\n",
        "fig = plt.figure(figsize=(9, 9))\n",
        "rows, cols = 4, 4\n",
        "for i in range(1, rows * cols + 1):\n",
        "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
        "    img, label = train_data[random_idx]\n",
        "    fig.add_subplot(rows, cols, i)\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "    plt.title(class_names[label])\n",
        "    plt.axis(False);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43cdd23d-bd1f-4e8c-ba20-22d2b6ac14b1",
      "metadata": {
        "id": "43cdd23d-bd1f-4e8c-ba20-22d2b6ac14b1"
      },
      "source": [
        "## 2. Prepare DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb2dbf90-a326-43cb-b25b-71af142fafeb",
      "metadata": {
        "id": "bb2dbf90-a326-43cb-b25b-71af142fafeb",
        "outputId": "95ff261e-24f6-403b-d246-39ed57bce03b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x7f9c4def5210>, <torch.utils.data.dataloader.DataLoader object at 0x7f9c4def51d0>)\n",
            "Length of train dataloader: 1875 batches of 32\n",
            "Length of test dataloader: 313 batches of 32\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Setup the batch size hyperparameter\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Turn datasets into iterables (batches)\n",
        "train_dataloader = DataLoader(train_data, # dataset to turn into iterable\n",
        "    batch_size=BATCH_SIZE, # how many samples per batch?\n",
        "    shuffle=True # shuffle data every epoch?\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(test_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False # don't necessarily have to shuffle the testing data\n",
        ")\n",
        "\n",
        "# Let's check out what we've created\n",
        "print(f\"Dataloaders: {train_dataloader, test_dataloader}\")\n",
        "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
        "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a925ee7-484b-4149-be8f-3ad790172a5f",
      "metadata": {
        "id": "7a925ee7-484b-4149-be8f-3ad790172a5f",
        "outputId": "c74ecdc6-b11c-4ace-c122-d9ad02960070",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "# Check out what's inside the training dataloader\n",
        "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
        "train_features_batch.shape, train_labels_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c863d66a-49be-43be-84dc-372a5d6fc2c2",
      "metadata": {
        "id": "c863d66a-49be-43be-84dc-372a5d6fc2c2",
        "outputId": "69100780-304d-4435-cfa7-c59d0d8f7110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size: torch.Size([1, 28, 28])\n",
            "Label: 6, label size: torch.Size([])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Show a sample\n",
        "torch.manual_seed(42)\n",
        "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
        "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
        "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.title(class_names[label])\n",
        "plt.axis(\"Off\");\n",
        "print(f\"Image size: {img.shape}\")\n",
        "print(f\"Label: {label}, label size: {label.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db1695cf-f53d-4c7c-ad39-dfed76533125",
      "metadata": {
        "id": "db1695cf-f53d-4c7c-ad39-dfed76533125"
      },
      "source": [
        "## 3. Model 0: Build a baseline model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nn.Flatten??"
      ],
      "metadata": {
        "id": "_onLBATBC1tS"
      },
      "id": "_onLBATBC1tS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn(32, 1, 5, 5)\n",
        "input.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TffGNZAQDGFE",
        "outputId": "7a67abd2-0908-4ee4-e9ae-067d196ba91f"
      },
      "id": "TffGNZAQDGFE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 1, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = nn.Flatten()\n",
        "m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuR8_PvODF5p",
        "outputId": "5a8fc8a2-0017-4ef6-9c30-4198205aa9b3"
      },
      "id": "XuR8_PvODF5p",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Flatten(start_dim=1, end_dim=-1)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = m(input)\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytiUswi1C1f3",
        "outputId": "23d3721e-3620-42a6-9879-e9c71abe1cf4"
      },
      "id": "ytiUswi1C1f3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 25])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = nn.Flatten(1, -1)\n",
        "m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFd5ZUDrDhWl",
        "outputId": "9adf0d30-1bc2-45e1-a1f1-8f17ed8bfc91"
      },
      "id": "oFd5ZUDrDhWl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Flatten(start_dim=1, end_dim=-1)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input2 = torch.randn(32,1,5,5,7,7)\n",
        "input2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vl77rMcREKDI",
        "outputId": "35183c15-b66f-4618-da6c-af8e106e6b5c"
      },
      "id": "Vl77rMcREKDI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 1, 5, 5, 7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = m(input2)\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQh7AuVGC1XC",
        "outputId": "5ed575f9-0971-4539-88e2-d619bd14d391"
      },
      "id": "jQh7AuVGC1XC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 1225])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KQ1RJTcNDnsf"
      },
      "id": "KQ1RJTcNDnsf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_batch.shape,train_features_batch[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gU_TUwIEtRe",
        "outputId": "8d5853d0-a83c-473d-99ce-de109a1d24d7"
      },
      "id": "-gU_TUwIEtRe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 1, 28, 28]), torch.Size([1, 28, 28]))"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "405319f1-f242-4bd9-90f5-3abdc50782ac",
      "metadata": {
        "id": "405319f1-f242-4bd9-90f5-3abdc50782ac",
        "outputId": "ead2b550-81dc-4ef1-9476-57cf1c27f475",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape before flattening: torch.Size([1, 28, 28]) -> [color_channels, height, width]\n",
            "Shape after flattening: torch.Size([1, 784]) -> [color_channels, height*width]\n"
          ]
        }
      ],
      "source": [
        "# Create a flatten layer\n",
        "flatten_model = nn.Flatten() # all nn modules function as a model (can do a forward pass)\n",
        "\n",
        "# Get a single sample\n",
        "x = train_features_batch[0]\n",
        "\n",
        "# Flatten the sample\n",
        "output = flatten_model(x) # perform forward pass\n",
        "\n",
        "# Print out what happened\n",
        "print(f\"Shape before flattening: {x.shape} -> [color_channels, height, width]\")\n",
        "print(f\"Shape after flattening: {output.shape} -> [color_channels, height*width]\")\n",
        "\n",
        "# Try uncommenting below and see what happens\n",
        "#print(x)\n",
        "#print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1449f427-6859-41ae-8133-50b58ffbce72",
      "metadata": {
        "id": "1449f427-6859-41ae-8133-50b58ffbce72"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "class FashionMNISTModelV0(nn.Module):\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "        super().__init__()\n",
        "        self.layer_stack = nn.Sequential(\n",
        "            nn.Flatten(), # neural networks like their inputs in vector form\n",
        "            nn.Linear(in_features=input_shape, out_features=hidden_units), # in_features = number of features in a data sample (784 pixels)\n",
        "            nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer_stack(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd18384a-76f9-4b5a-a013-fda077f16865",
      "metadata": {
        "id": "dd18384a-76f9-4b5a-a013-fda077f16865",
        "outputId": "a1dc4969-57e7-437a-b68c-8bf125f213d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FashionMNISTModelV0(\n",
              "  (layer_stack): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
              "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Need to setup model with input parameters\n",
        "model_0 = FashionMNISTModelV0(input_shape=784, # one for every pixel (28x28)\n",
        "    hidden_units=10, # how many units in the hiden layer\n",
        "    output_shape=len(class_names) # one for every class\n",
        ")\n",
        "model_0.to(\"cpu\") # keep model on CPU to begin with"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03243179-1cdc-45d9-8b8c-82538ac02e9c",
      "metadata": {
        "id": "03243179-1cdc-45d9-8b8c-82538ac02e9c"
      },
      "source": [
        "### 3.1 Setup loss, optimizer and evaluation metrics\n",
        "\n",
        "Since we're working on a classification problem, let's bring in our [`helper_functions.py` script](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/helper_functions.py) and subsequently the `accuracy_fn()` we defined in [notebook 02](https://www.learnpytorch.io/02_pytorch_classification/).\n",
        "\n",
        "> **Note:** Rather than importing and using our own accuracy function or evaluation metric(s), you could import various evaluation metrics from the [TorchMetrics package](https://torchmetrics.readthedocs.io/en/latest/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31c91f17-d810-46a4-97c3-c734f93430b1",
      "metadata": {
        "id": "31c91f17-d810-46a4-97c3-c734f93430b1",
        "outputId": "9ce5a11c-e2f0-46bf-84da-9048d6da5363",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading helper_functions.py\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"helper_functions.py already exists, skipping download\")\n",
        "else:\n",
        "  print(\"Downloading helper_functions.py\")\n",
        "  # Note: you need the \"raw\" GitHub URL for this to work\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    f.write(request.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce3d13b8-f018-4b44-8bba-375074dc4c5f",
      "metadata": {
        "id": "ce3d13b8-f018-4b44-8bba-375074dc4c5f"
      },
      "outputs": [],
      "source": [
        "# Import accuracy metric\n",
        "from helper_functions import accuracy_fn # Note: could also use torchmetrics.Accuracy()\n",
        "\n",
        "# Setup loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss() # this is also called \"criterion\"/\"cost function\" in some places\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy_fn??"
      ],
      "metadata": {
        "id": "1pYdjDPHDhzC"
      },
      "id": "1pYdjDPHDhzC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWwscIY8LXAY",
        "outputId": "96a8f21c-4e52-4b96-c0bb-1fcffdfceb25"
      },
      "id": "UWwscIY8LXAY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('layer_stack.1.weight',\n",
              "              tensor([[ 0.0273,  0.0296, -0.0084,  ..., -0.0142,  0.0093,  0.0135],\n",
              "                      [-0.0188, -0.0354,  0.0187,  ..., -0.0106, -0.0001,  0.0115],\n",
              "                      [-0.0008,  0.0017,  0.0045,  ..., -0.0127, -0.0188,  0.0059],\n",
              "                      ...,\n",
              "                      [-0.0116,  0.0273, -0.0344,  ...,  0.0176,  0.0283, -0.0011],\n",
              "                      [-0.0230,  0.0257,  0.0291,  ..., -0.0187, -0.0087,  0.0001],\n",
              "                      [ 0.0176, -0.0147,  0.0053,  ..., -0.0336, -0.0221,  0.0205]])),\n",
              "             ('layer_stack.1.bias',\n",
              "              tensor([-0.0093,  0.0283, -0.0033,  0.0255,  0.0017,  0.0037, -0.0302, -0.0123,\n",
              "                       0.0018,  0.0163])),\n",
              "             ('layer_stack.2.weight',\n",
              "              tensor([[ 0.0614, -0.0687,  0.0021,  0.2718,  0.2109,  0.1079, -0.2279, -0.1063,\n",
              "                        0.2019,  0.2847],\n",
              "                      [-0.1495,  0.1344, -0.0740,  0.2006, -0.0475, -0.2514, -0.3130, -0.0118,\n",
              "                        0.0932, -0.1864],\n",
              "                      [ 0.2488,  0.1500,  0.1907,  0.1457, -0.3050, -0.0580,  0.1643,  0.1565,\n",
              "                       -0.2877, -0.1792],\n",
              "                      [ 0.2305, -0.2618,  0.2397, -0.0610,  0.0232,  0.1542,  0.0851, -0.2027,\n",
              "                        0.1030, -0.2715],\n",
              "                      [-0.1596, -0.0555, -0.0633,  0.2302, -0.1726,  0.2654,  0.1473,  0.1029,\n",
              "                        0.2252, -0.2160],\n",
              "                      [-0.2725,  0.0118,  0.1559,  0.1596,  0.0132,  0.3024,  0.1124,  0.1366,\n",
              "                       -0.1533,  0.0965],\n",
              "                      [-0.1184, -0.2555, -0.2057, -0.1909, -0.0477, -0.1324,  0.2905,  0.1307,\n",
              "                       -0.2629,  0.0133],\n",
              "                      [ 0.2727, -0.0127,  0.0513,  0.0863, -0.1043, -0.2047, -0.1185, -0.0825,\n",
              "                        0.2488, -0.2571],\n",
              "                      [ 0.0425, -0.1209, -0.0336, -0.0281, -0.1227,  0.0730,  0.0747, -0.1816,\n",
              "                        0.1943,  0.2853],\n",
              "                      [-0.1310,  0.0645, -0.1171,  0.2168, -0.0245, -0.2820,  0.0736,  0.2621,\n",
              "                        0.0012, -0.0810]])),\n",
              "             ('layer_stack.2.bias',\n",
              "              tensor([-0.0087,  0.1791,  0.2712, -0.0791,  0.1685,  0.1762,  0.2825,  0.2266,\n",
              "                      -0.2612, -0.2613]))])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwZFdvGJLOCf",
        "outputId": "58cb875c-4acf-45fb-b833-bfa6f1b16e5a"
      },
      "id": "VwZFdvGJLOCf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CrossEntropyLoss()"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGVWLRo5LP5b",
        "outputId": "2184f264-6d98-4426-c739-4ef009a18413"
      },
      "id": "fGVWLRo5LP5b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGD (\n",
              "Parameter Group 0\n",
              "    dampening: 0\n",
              "    foreach: None\n",
              "    lr: 0.1\n",
              "    maximize: False\n",
              "    momentum: 0\n",
              "    nesterov: False\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4109f867-83f2-4394-a925-8acdc63ccffe",
      "metadata": {
        "id": "4109f867-83f2-4394-a925-8acdc63ccffe"
      },
      "source": [
        "### 3.2 Creating a function to time our experiments\n",
        "\n",
        "Loss function and optimizer ready!\n",
        "\n",
        "It's time to start training a model.\n",
        "\n",
        "But how about we do a little experiment while we train.\n",
        "\n",
        "I mean, let's make a timing function to measure the time it takes our model to train on CPU versus using a GPU.\n",
        "\n",
        "We'll train this model on the CPU but the next one on the GPU and see what happens.\n",
        "\n",
        "Our timing function will import the [`timeit.default_timer()` function](https://docs.python.org/3/library/timeit.html#timeit.default_timer) from the Python [`timeit` module](https://docs.python.org/3/library/timeit.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31adc3fe-ce90-4b4e-b0d4-3613abae5714",
      "metadata": {
        "id": "31adc3fe-ce90-4b4e-b0d4-3613abae5714"
      },
      "outputs": [],
      "source": [
        "from timeit import default_timer as timer\n",
        "def print_train_time(start: float, end: float, device: torch.device = None):\n",
        "    \"\"\"Prints difference between start and end time.\n",
        "\n",
        "    Args:\n",
        "        start (float): Start time of computation (preferred in timeit format).\n",
        "        end (float): End time of computation.\n",
        "        device ([type], optional): Device that compute is running on. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        float: time between start and end in seconds (higher is longer).\n",
        "    \"\"\"\n",
        "    total_time = end - start\n",
        "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
        "    return total_time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING START"
      ],
      "metadata": {
        "id": "seq1HDpqRz1B"
      },
      "id": "seq1HDpqRz1B"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import tqdm for progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Set the seed and start the timer\n",
        "torch.manual_seed(42)\n",
        "train_time_start_on_cpu = timer()\n",
        "\n",
        "# Set the number of epochs (we'll keep this small for faster training times)\n",
        "epochs = 3\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n-------\")\n",
        "  ### Training\n",
        "  train_loss = 0\n",
        "  # Loop through training batches\n",
        "  for batch, (X,y) in enumerate(train_dataloader):\n",
        "    model_0.train()\n",
        "    # 1. Forward pass\n",
        "    y_pred = model_0(X)\n",
        "\n",
        "    # 2. Calculate loss (per batch)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss # accumulatively add up the loss per epoch\n",
        "\n",
        "    # 3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print out how many samples have been seen\n",
        "    if batch % 400 == 0:\n",
        "      print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
        "\n",
        "  # Divide total train loss by length of train dataloader (average loss per epoch)\n",
        "  train_loss /= len(train_dataloader)\n",
        "  # print(f\"train_loss: {train_loss}\")\n",
        "\n",
        "  ### Testing\n",
        "  # Setup variables for accumulatively adding loss and accuracy\n",
        "  test_loss, test_acc = 0, 0\n",
        "  model_0.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X_test,y_test in test_dataloader:\n",
        "      # 1. Forward pass\n",
        "      test_pred = model_0(X_test)\n",
        "\n",
        "      # 2. Calculate loss (accumatively)\n",
        "      test_loss += loss_fn(test_pred, y_test) # accumulatively add up the loss per epoch\n",
        "\n",
        "      # 3. Calculate accuracy (preds need to be same as y_true)\n",
        "      test_acc += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "    # Calculations on test metrics need to happen inside torch.inference_mode()\n",
        "    # Divide total test loss by length of test dataloader (per batch)\n",
        "    test_loss /= len(test_dataloader)\n",
        "\n",
        "    # Divide total accuracy by length of test dataloader (per batch)\n",
        "    test_acc /= len(test_dataloader)\n",
        "\n",
        "  ## Print out what's happening\n",
        "  print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Calculate training time\n",
        "train_time_end_on_cpu = timer()\n",
        "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu,\n",
        "                                           end=train_time_end_on_cpu,\n",
        "                                           device=str(next(model_0.parameters()).device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587,
          "referenced_widgets": [
            "1d3fc81888b945319bb25135d2594c58",
            "a2c6fde355824f5caa73c0e1c5e1d4b6",
            "d8889e84a3484ed6a5b7b43d571a3439",
            "7c1b38953b7d41a5baf80174726b8e8f",
            "a0836412b4db4586ba8f2463573b39e7",
            "b6e5057dec9340e6bbe0f57c35e5e8f6",
            "365b29782c984b4aafbc47e97cce55ad",
            "73f668aae3db427e9ed6b15d9bc483dd",
            "d4f47ee32ab147e1980487b68844974d",
            "ca61dba35b08488f9d20f60fe436a09e",
            "ea70f864b12f441cb9f38a00a86144ff"
          ]
        },
        "id": "I9rs4cv4RyTQ",
        "outputId": "8e556661-480b-4b26-f459-51e187425c11"
      },
      "id": "I9rs4cv4RyTQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d3fc81888b945319bb25135d2594c58"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "-------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n",
            "\n",
            "Train loss: 0.47643 | Test loss: 0.48250, Test acc: 83.00%\n",
            "\n",
            "Epoch: 1\n",
            "-------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n",
            "\n",
            "Train loss: 0.45556 | Test loss: 0.47251, Test acc: 83.63%\n",
            "\n",
            "Epoch: 2\n",
            "-------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n",
            "\n",
            "Train loss: 0.44364 | Test loss: 0.47143, Test acc: 83.58%\n",
            "\n",
            "Train time on cpu: 23.789 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W_J_ooXzSFan"
      },
      "id": "W_J_ooXzSFan",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pMt0hhzcRyDP"
      },
      "id": "pMt0hhzcRyDP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING END"
      ],
      "metadata": {
        "id": "6TxPqA_GR4Af"
      },
      "id": "6TxPqA_GR4Af"
    },
    {
      "cell_type": "markdown",
      "id": "07b9560e-f5dc-45d6-b3b2-ddae17a71b34",
      "metadata": {
        "id": "07b9560e-f5dc-45d6-b3b2-ddae17a71b34"
      },
      "source": [
        "### 3.3 Creating a training loop and training a model on batches of data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c07bbf10-81e3-47f0-990d-9a4a838276ab",
      "metadata": {
        "id": "c07bbf10-81e3-47f0-990d-9a4a838276ab",
        "outputId": "da8e5b65-4e7c-4046-a48e-3cd925a9200f",
        "colab": {
          "referenced_widgets": [
            "0132aa6e08d747e7af202440f9615a86"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0132aa6e08d747e7af202440f9615a86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "-------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n",
            "\n",
            "Train loss: 0.59039 | Test loss: 0.50954, Test acc: 82.04%\n",
            "\n",
            "Epoch: 1\n",
            "-------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n",
            "\n",
            "Train loss: 0.47633 | Test loss: 0.47989, Test acc: 83.20%\n",
            "\n",
            "Epoch: 2\n",
            "-------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n",
            "\n",
            "Train loss: 0.45503 | Test loss: 0.47664, Test acc: 83.43%\n",
            "\n",
            "Train time on cpu: 14.975 seconds\n"
          ]
        }
      ],
      "source": [
        "# # Import tqdm for progress bar\n",
        "# from tqdm.auto import tqdm\n",
        "\n",
        "# # Set the seed and start the timer\n",
        "# torch.manual_seed(42)\n",
        "# train_time_start_on_cpu = timer()\n",
        "\n",
        "# # Set the number of epochs (we'll keep this small for faster training times)\n",
        "# epochs = 3\n",
        "\n",
        "# # Create training and testing loop\n",
        "# for epoch in tqdm(range(epochs)):\n",
        "#   print(f\"Epoch: {epoch}\\n-------\")\n",
        "#   ### Training\n",
        "#   train_loss = 0\n",
        "#   # Add a loop to loop through training batches\n",
        "#   for batch, (X, y) in enumerate(train_dataloader):\n",
        "#     model_0.train()\n",
        "#     # 1. Forward pass\n",
        "#     y_pred = model_0(X)\n",
        "\n",
        "#     # 2. Calculate loss (per batch)\n",
        "#     loss = loss_fn(y_pred, y)\n",
        "#     train_loss += loss # accumulatively add up the loss per epoch\n",
        "\n",
        "#     # 3. Optimizer zero grad\n",
        "#     optimizer.zero_grad()\n",
        "\n",
        "#     # 4. Loss backward\n",
        "#     loss.backward()\n",
        "\n",
        "#     # 5. Optimizer step\n",
        "#     optimizer.step()\n",
        "\n",
        "#     # Print out how many samples have been seen\n",
        "#     if batch % 400 == 0:\n",
        "#         print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
        "\n",
        "#   # Divide total train loss by length of train dataloader (average loss per batch per epoch)\n",
        "#   train_loss /= len(train_dataloader)\n",
        "\n",
        "#     ### Testing\n",
        "#     # Setup variables for accumulatively adding up loss and accuracy\n",
        "#     test_loss, test_acc = 0, 0\n",
        "#     model_0.eval()\n",
        "#     with torch.inference_mode():\n",
        "#         for X, y in test_dataloader:\n",
        "#             # 1. Forward pass\n",
        "#             test_pred = model_0(X)\n",
        "\n",
        "#             # 2. Calculate loss (accumatively)\n",
        "#             test_loss += loss_fn(test_pred, y) # accumulatively add up the loss per epoch\n",
        "\n",
        "#             # 3. Calculate accuracy (preds need to be same as y_true)\n",
        "#             test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "#         # Calculations on test metrics need to happen inside torch.inference_mode()\n",
        "#         # Divide total test loss by length of test dataloader (per batch)\n",
        "#         test_loss /= len(test_dataloader)\n",
        "\n",
        "#         # Divide total accuracy by length of test dataloader (per batch)\n",
        "#         test_acc /= len(test_dataloader)\n",
        "\n",
        "#     ## Print out what's happening\n",
        "#     print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n",
        "\n",
        "# # Calculate training time\n",
        "# train_time_end_on_cpu = timer()\n",
        "# total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu,\n",
        "#                                            end=train_time_end_on_cpu,\n",
        "#                                            device=str(next(model_0.parameters()).device))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7442511b-bfe9-4ec7-9f5b-9c808f8e560b",
      "metadata": {
        "id": "7442511b-bfe9-4ec7-9f5b-9c808f8e560b"
      },
      "source": [
        "## 4. Make predictions and get Model 0 results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8317dd04-9de2-4fd7-97bd-1e202621397d",
      "metadata": {
        "id": "8317dd04-9de2-4fd7-97bd-1e202621397d",
        "outputId": "b8acb365-870e-4627-c2bb-688367ad702b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model_name': 'FashionMNISTModelV0',\n",
              " 'model_loss': 0.47663894295692444,\n",
              " 'model_acc': 83.42651757188499}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "def eval_model(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn):\n",
        "    \"\"\"Returns a dictionary containing the results of model predicting on data_loader.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.\n",
        "        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.\n",
        "        loss_fn (torch.nn.Module): The loss function of model.\n",
        "        accuracy_fn: An accuracy function to compare the models predictions to the truth labels.\n",
        "\n",
        "    Returns:\n",
        "        (dict): Results of model making predictions on data_loader.\n",
        "    \"\"\"\n",
        "    loss, acc = 0, 0\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X, y in data_loader:\n",
        "            # Make predictions with the model\n",
        "            y_pred = model(X)\n",
        "\n",
        "            # Accumulate the loss and accuracy values per batch\n",
        "            loss += loss_fn(y_pred, y)\n",
        "            acc += accuracy_fn(y_true=y,\n",
        "                                y_pred=y_pred.argmax(dim=1)) # For accuracy, need the prediction labels (logits -> pred_prob -> pred_labels)\n",
        "\n",
        "        # Scale loss and acc to find the average loss/acc per batch\n",
        "        loss /= len(data_loader)\n",
        "        acc /= len(data_loader)\n",
        "\n",
        "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
        "            \"model_loss\": loss.item(),\n",
        "            \"model_acc\": acc}\n",
        "\n",
        "# Calculate model 0 results on test dataset\n",
        "model_0_results = eval_model(model=model_0, data_loader=test_dataloader,\n",
        "    loss_fn=loss_fn, accuracy_fn=accuracy_fn\n",
        ")\n",
        "model_0_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b76784d-4cdb-43d2-a6da-8e4da9a812a9",
      "metadata": {
        "id": "3b76784d-4cdb-43d2-a6da-8e4da9a812a9"
      },
      "source": [
        "## 5. Setup device agnostic-code (for using a GPU if there is one)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17b69fe9-f974-4538-922c-20c5cc8220cc",
      "metadata": {
        "id": "17b69fe9-f974-4538-922c-20c5cc8220cc",
        "outputId": "484d03a7-285a-4d1d-9214-0a612f3a0ec1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Setup device agnostic code\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7893907-5f82-4c5e-8fde-fa542a9f25af",
      "metadata": {
        "id": "d7893907-5f82-4c5e-8fde-fa542a9f25af"
      },
      "source": [
        "## 6. Model 1: Building a better model with non-linearity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ccce5f2-b1e5-47a6-a7f3-6bc096b35ffb",
      "metadata": {
        "id": "2ccce5f2-b1e5-47a6-a7f3-6bc096b35ffb"
      },
      "outputs": [],
      "source": [
        "# Create a model with non-linear and linear layers\n",
        "class FashionMNISTModelV1(nn.Module):\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "        super().__init__()\n",
        "        self.layer_stack = nn.Sequential(\n",
        "            nn.Flatten(), # flatten inputs into single vector\n",
        "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        return self.layer_stack(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "907091ec-7e46-470b-a305-788a3009b837",
      "metadata": {
        "id": "907091ec-7e46-470b-a305-788a3009b837",
        "outputId": "c5e32814-98c7-49f1-947f-0b9a6aaf67f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "model_1 = FashionMNISTModelV1(input_shape=784, # number of input features\n",
        "    hidden_units=10,\n",
        "    output_shape=len(class_names) # number of output classes desired\n",
        ").to(device) # send model to GPU if it's available\n",
        "next(model_1.parameters()).device # check model device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b54a4e9d-a7ad-404c-920f-485fcff18a92",
      "metadata": {
        "id": "b54a4e9d-a7ad-404c-920f-485fcff18a92"
      },
      "source": [
        "### 6.1 Setup loss, optimizer and evaluation metrics\n",
        "\n",
        "As usual, we'll setup a loss function, an optimizer and an evaluation metric (we could do multiple evaluation metrics but we'll stick with accuracy for now)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe7e463b-d46c-4f00-853c-fdf0a28d74c8",
      "metadata": {
        "id": "fe7e463b-d46c-4f00-853c-fdf0a28d74c8"
      },
      "outputs": [],
      "source": [
        "from helper_functions import accuracy_fn\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_1.parameters(),\n",
        "                            lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1eb30af6-a355-49a2-a59f-25169fd27a6e",
      "metadata": {
        "id": "1eb30af6-a355-49a2-a59f-25169fd27a6e"
      },
      "source": [
        "### 6.2 Functionizing training and test loops\n",
        "\n",
        "So far we've been writing train and test loops over and over.\n",
        "\n",
        "Let's write them again but this time we'll put them in functions so they can be called again and again.\n",
        "\n",
        "And because we're using device-agnostic code now, we'll be sure to call `.to(device)` on our feature (`X`) and target (`y`) tensors.\n",
        "\n",
        "For the training loop we'll create a function called `train_step()` which takes in a model, a `DataLoader` a loss function and an optimizer.\n",
        "\n",
        "The testing loop will be similar but it'll be called `test_step()` and it'll take in a model, a `DataLoader`, a loss function and an evaluation function.\n",
        "\n",
        "> **Note:** Since these are functions, you can customize them in any way you like. What we're making here can be considered barebones training and testing functions for our specific classification use case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d239ed2-4028-4603-8db3-ffca2b727819",
      "metadata": {
        "id": "3d239ed2-4028-4603-8db3-ffca2b727819"
      },
      "outputs": [],
      "source": [
        "def train_step(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               accuracy_fn,\n",
        "               device: torch.device = device):\n",
        "    train_loss, train_acc = 0, 0\n",
        "    for batch, (X, y) in enumerate(data_loader):\n",
        "        # Send data to GPU\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 1. Forward pass\n",
        "        y_pred = model(X)\n",
        "\n",
        "        # 2. Calculate loss\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss\n",
        "        train_acc += accuracy_fn(y_true=y,\n",
        "                                 y_pred=y_pred.argmax(dim=1)) # Go from logits -> pred labels\n",
        "\n",
        "        # 3. Optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Loss backward\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "    # Calculate loss and accuracy per epoch and print out what's happening\n",
        "    train_loss /= len(data_loader)\n",
        "    train_acc /= len(data_loader)\n",
        "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
        "\n",
        "def test_step(data_loader: torch.utils.data.DataLoader,\n",
        "              model: torch.nn.Module,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              accuracy_fn,\n",
        "              device: torch.device = device):\n",
        "    test_loss, test_acc = 0, 0\n",
        "    model.eval() # put model in eval mode\n",
        "    # Turn on inference context manager\n",
        "    with torch.inference_mode():\n",
        "        for X, y in data_loader:\n",
        "            # Send data to GPU\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # 1. Forward pass\n",
        "            test_pred = model(X)\n",
        "\n",
        "            # 2. Calculate loss and accuracy\n",
        "            test_loss += loss_fn(test_pred, y)\n",
        "            test_acc += accuracy_fn(y_true=y,\n",
        "                y_pred=test_pred.argmax(dim=1) # Go from logits -> pred labels\n",
        "            )\n",
        "\n",
        "        # Adjust metrics and print out\n",
        "        test_loss /= len(data_loader)\n",
        "        test_acc /= len(data_loader)\n",
        "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bb8094b-01a0-4b84-9526-ba8888d04901",
      "metadata": {
        "id": "2bb8094b-01a0-4b84-9526-ba8888d04901",
        "outputId": "aa52fcdd-afe0-4dc9-e73b-23841d529b63",
        "colab": {
          "referenced_widgets": [
            "03eed0dd4e134aea983b4c5383502cf0"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03eed0dd4e134aea983b4c5383502cf0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "---------\n",
            "Train loss: 1.09199 | Train accuracy: 61.34%\n",
            "Test loss: 0.95636 | Test accuracy: 65.00%\n",
            "\n",
            "Epoch: 1\n",
            "---------\n",
            "Train loss: 0.78101 | Train accuracy: 71.93%\n",
            "Test loss: 0.72227 | Test accuracy: 73.91%\n",
            "\n",
            "Epoch: 2\n",
            "---------\n",
            "Train loss: 0.67027 | Train accuracy: 75.94%\n",
            "Test loss: 0.68500 | Test accuracy: 75.02%\n",
            "\n",
            "Train time on cuda: 16.943 seconds\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Measure time\n",
        "from timeit import default_timer as timer\n",
        "train_time_start_on_gpu = timer()\n",
        "\n",
        "epochs = 3\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    print(f\"Epoch: {epoch}\\n---------\")\n",
        "    train_step(data_loader=train_dataloader,\n",
        "        model=model_1,\n",
        "        loss_fn=loss_fn,\n",
        "        optimizer=optimizer,\n",
        "        accuracy_fn=accuracy_fn\n",
        "    )\n",
        "    test_step(data_loader=test_dataloader,\n",
        "        model=model_1,\n",
        "        loss_fn=loss_fn,\n",
        "        accuracy_fn=accuracy_fn\n",
        "    )\n",
        "\n",
        "train_time_end_on_gpu = timer()\n",
        "total_train_time_model_1 = print_train_time(start=train_time_start_on_gpu,\n",
        "                                            end=train_time_end_on_gpu,\n",
        "                                            device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32a544e3-9dbe-4aa1-b074-22e28b8f2f2a",
      "metadata": {
        "id": "32a544e3-9dbe-4aa1-b074-22e28b8f2f2a",
        "outputId": "600a1960-8b7b-4c31-f20e-4ee980bcccc9"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_1084458/2906876561.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Note: This will error due to `eval_model()` not using device agnostic code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m model_1_results = eval_model(model=model_1, \n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdata_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_1084458/2300884397.py\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(model, data_loader, loss_fn, accuracy_fn)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# Make predictions with the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m# Accumulate the loss and accuracy values per batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/code/pytorch/env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_1084458/3744982926.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/code/pytorch/env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/code/pytorch/env/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/code/pytorch/env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/code/pytorch/env/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Note: This will error due to `eval_model()` not using device agnostic code\n",
        "model_1_results = eval_model(model=model_1,\n",
        "    data_loader=test_dataloader,\n",
        "    loss_fn=loss_fn,\n",
        "    accuracy_fn=accuracy_fn)\n",
        "model_1_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a3481a5-489d-4db9-ac95-c3ce385978b7",
      "metadata": {
        "id": "6a3481a5-489d-4db9-ac95-c3ce385978b7"
      },
      "source": [
        "Oh no!\n",
        "\n",
        "It looks like our `eval_model()` function errors out with:\n",
        "\n",
        "> `RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)`\n",
        "\n",
        "It's because we've setup our data and model to use device-agnostic code but not our evaluation function.\n",
        "\n",
        "How about we fix that by passing a target `device` parameter to our `eval_model()` function?\n",
        "\n",
        "Then we'll try calculating the results again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3665d99-1adc-4d9f-bfc6-e5601a80691c",
      "metadata": {
        "id": "f3665d99-1adc-4d9f-bfc6-e5601a80691c",
        "outputId": "dea6b4c0-cf77-490b-f338-07f326d199b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model_name': 'FashionMNISTModelV1',\n",
              " 'model_loss': 0.6850008964538574,\n",
              " 'model_acc': 75.01996805111821}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Move values to device\n",
        "torch.manual_seed(42)\n",
        "def eval_model(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn,\n",
        "               device: torch.device = device):\n",
        "    \"\"\"Evaluates a given model on a given dataset.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.\n",
        "        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.\n",
        "        loss_fn (torch.nn.Module): The loss function of model.\n",
        "        accuracy_fn: An accuracy function to compare the models predictions to the truth labels.\n",
        "        device (str, optional): Target device to compute on. Defaults to device.\n",
        "\n",
        "    Returns:\n",
        "        (dict): Results of model making predictions on data_loader.\n",
        "    \"\"\"\n",
        "    loss, acc = 0, 0\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X, y in data_loader:\n",
        "            # Send data to the target device\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            y_pred = model(X)\n",
        "            loss += loss_fn(y_pred, y)\n",
        "            acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
        "\n",
        "        # Scale loss and acc\n",
        "        loss /= len(data_loader)\n",
        "        acc /= len(data_loader)\n",
        "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
        "            \"model_loss\": loss.item(),\n",
        "            \"model_acc\": acc}\n",
        "\n",
        "# Calculate model 1 results with device-agnostic code\n",
        "model_1_results = eval_model(model=model_1, data_loader=test_dataloader,\n",
        "    loss_fn=loss_fn, accuracy_fn=accuracy_fn,\n",
        "    device=device\n",
        ")\n",
        "model_1_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9e916cf-f873-4481-a983-bac26ce4cac2",
      "metadata": {
        "id": "a9e916cf-f873-4481-a983-bac26ce4cac2",
        "outputId": "138d9158-c9b5-4a0b-d8ec-7457ee8bc17e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model_name': 'FashionMNISTModelV0',\n",
              " 'model_loss': 0.47663894295692444,\n",
              " 'model_acc': 83.42651757188499}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check baseline results\n",
        "model_0_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "340cbf14-e83f-4981-8a93-5fedb6b51418",
      "metadata": {
        "id": "340cbf14-e83f-4981-8a93-5fedb6b51418"
      },
      "source": [
        "Woah, in this case, it looks like adding non-linearities to our model made it perform worse than the baseline.\n",
        "\n",
        "That's a thing to note in machine learning, sometimes the thing you thought should work doesn't.\n",
        "\n",
        "And then the thing you thought might not work does.\n",
        "\n",
        "It's part science, part art.\n",
        "\n",
        "From the looks of things, it seems like our model is **overfitting** on the training data.\n",
        "\n",
        "Overfitting means our model is learning the training data well but those patterns aren't generalizing to the testing data.\n",
        "\n",
        "Two of the main to fix overfitting include:\n",
        "1. Using a smaller or different model (some models fit certain kinds of data better than others).\n",
        "2. Using a larger dataset (the more data, the more chance a model has to learn generalizable patterns).\n",
        "\n",
        "There are more, but I'm going to leave that as a challenge for you to explore.\n",
        "\n",
        "Try searching online, \"ways to prevent overfitting in machine learning\" and see what comes up.\n",
        "\n",
        "In the meantime, let's take a look at number 1: using a different model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac22d685-1b8d-4215-90de-c0476cb0fbdf",
      "metadata": {
        "id": "ac22d685-1b8d-4215-90de-c0476cb0fbdf"
      },
      "source": [
        "## 7. Model 2: Building a Convolutional Neural Network (CNN)\n",
        "\n",
        "Alright, time to step things up a notch.\n",
        "\n",
        "It's time to create a [Convolutional Neural Network](https://en.wikipedia.org/wiki/Convolutional_neural_network) (CNN or ConvNet).\n",
        "\n",
        "CNN's are known for their capabilities to find patterns in visual data.\n",
        "\n",
        "And since we're dealing with visual data, let's see if using a CNN model can improve upon our baseline.\n",
        "\n",
        "The CNN model we're going to be using is known as TinyVGG from the [CNN Explainer](https://poloclub.github.io/cnn-explainer/) website.\n",
        "\n",
        "It follows the typical structure of a convolutional neural network:\n",
        "\n",
        "`Input layer -> [Convolutional layer -> activation layer -> pooling layer] -> Output layer`\n",
        "\n",
        "Where the contents of `[Convolutional layer -> activation layer -> pooling layer]` can be upscaled and repeated multiple times, depending on requirements."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c358955-1d20-4903-b872-a239d2753d88",
      "metadata": {
        "id": "9c358955-1d20-4903-b872-a239d2753d88"
      },
      "source": [
        "### What model should I use?\n",
        "\n",
        "> **Question:** Wait, you say CNN's are good for images, are there any other model types I should be aware of?\n",
        "\n",
        "Good question.\n",
        "\n",
        "This table is a good general guide for which model to use (though there are exceptions).\n",
        "\n",
        "| **Problem type** | **Model to use (generally)** | **Code example** |\n",
        "| ----- | ----- | ----- |\n",
        "| Structured data (Excel spreadsheets, row and column data) | Gradient boosted models, Random Forests, XGBoost | [`sklearn.ensemble`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble), [XGBoost library](https://xgboost.readthedocs.io/en/stable/) |\n",
        "| Unstructured data (images, audio, language) | Convolutional Neural Networks, Transformers | [`torchvision.models`](https://pytorch.org/vision/stable/models.html), [HuggingFace Transformers](https://huggingface.co/docs/transformers/index) |\n",
        "\n",
        "> **Note:** The table above is only for reference, the model you end up using will be highly dependant on the problem you're working on and the constraints you have (amount of data, latency requirements).\n",
        "\n",
        "Enough talking about models, let's now build a CNN that replicates the model on the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
        "\n",
        "![TinyVGG architecture, as setup by CNN explainer website](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-cnn-explainer-model.png)\n",
        "\n",
        "To do so, we'll leverage the [`nn.Conv2d()`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) and [`nn.MaxPool2d()`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html) layers from `torch.nn`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dce60214-63fd-46e2-89ba-125445ac76b7",
      "metadata": {
        "id": "dce60214-63fd-46e2-89ba-125445ac76b7",
        "outputId": "5a95fd7d-5e4d-4a85-e66c-639a96871e68"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FashionMNISTModelV2(\n",
              "  (block_1): Sequential(\n",
              "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block_2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a convolutional neural network\n",
        "class FashionMNISTModelV2(nn.Module):\n",
        "    \"\"\"\n",
        "    Model architecture copying TinyVGG from:\n",
        "    https://poloclub.github.io/cnn-explainer/\n",
        "    \"\"\"\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "        super().__init__()\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_shape,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3, # how big is the square that's going over the image?\n",
        "                      stride=1, # default\n",
        "                      padding=1),# options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                         stride=2) # default stride value is same as kernel_size\n",
        "        )\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            # Where did this in_features shape come from?\n",
        "            # It's because each layer of our network compresses and changes the shape of our inputs data.\n",
        "            nn.Linear(in_features=hidden_units*7*7,\n",
        "                      out_features=output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.block_1(x)\n",
        "        # print(x.shape)\n",
        "        x = self.block_2(x)\n",
        "        # print(x.shape)\n",
        "        x = self.classifier(x)\n",
        "        # print(x.shape)\n",
        "        return x\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model_2 = FashionMNISTModelV2(input_shape=1,\n",
        "    hidden_units=10,\n",
        "    output_shape=len(class_names)).to(device)\n",
        "model_2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a20f25e-cc16-4f85-a69b-62008c01d0ed",
      "metadata": {
        "id": "0a20f25e-cc16-4f85-a69b-62008c01d0ed"
      },
      "source": [
        "Nice!\n",
        "\n",
        "Our biggest model yet!\n",
        "\n",
        "What we've done is a common practice in machine learning.\n",
        "\n",
        "Find a model architecture somewhere and replicate it with code."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6478cc5a-7b33-425d-9ab3-6d40168a1aee",
      "metadata": {
        "id": "6478cc5a-7b33-425d-9ab3-6d40168a1aee"
      },
      "source": [
        "### 7.1 Stepping through `nn.Conv2d()`\n",
        "\n",
        "We could start using our model above and see what happens but let's first step through the two new layers we've added:\n",
        "* [`nn.Conv2d()`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html), also known as a convolutional layer.\n",
        "* [`nn.MaxPool2d()`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html), also known as a max pooling layer.\n",
        "\n",
        "> **Question:** What does the \"2d\" in `nn.Conv2d()` stand for?\n",
        ">\n",
        "> The 2d is for 2-dimensional data. As in, our images have two dimensions: height and width. Yes, there's color channel dimension but each of the color channel dimensions have two dimensions too: height and width.\n",
        ">\n",
        "> For other dimensional data (such as 1D for text or 3D for 3D objects) there's also `nn.Conv1d()` and `nn.Conv3d()`.\n",
        "\n",
        "To test the layers out, let's create some toy data just like the data used on CNN Explainer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "058b01ac-3f6a-4472-bcbf-3377974e3254",
      "metadata": {
        "id": "058b01ac-3f6a-4472-bcbf-3377974e3254",
        "outputId": "f29e7425-742b-41a8-8780-0ca87fc4dacb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image batch shape: torch.Size([32, 3, 64, 64]) -> [batch_size, color_channels, height, width]\n",
            "Single image shape: torch.Size([3, 64, 64]) -> [color_channels, height, width]\n",
            "Single image pixel values:\n",
            "tensor([[[ 1.9269,  1.4873,  0.9007,  ...,  1.8446, -1.1845,  1.3835],\n",
            "         [ 1.4451,  0.8564,  2.2181,  ...,  0.3399,  0.7200,  0.4114],\n",
            "         [ 1.9312,  1.0119, -1.4364,  ..., -0.5558,  0.7043,  0.7099],\n",
            "         ...,\n",
            "         [-0.5610, -0.4830,  0.4770,  ..., -0.2713, -0.9537, -0.6737],\n",
            "         [ 0.3076, -0.1277,  0.0366,  ..., -2.0060,  0.2824, -0.8111],\n",
            "         [-1.5486,  0.0485, -0.7712,  ..., -0.1403,  0.9416, -0.0118]],\n",
            "\n",
            "        [[-0.5197,  1.8524,  1.8365,  ...,  0.8935, -1.5114, -0.8515],\n",
            "         [ 2.0818,  1.0677, -1.4277,  ...,  1.6612, -2.6223, -0.4319],\n",
            "         [-0.1010, -0.4388, -1.9775,  ...,  0.2106,  0.2536, -0.7318],\n",
            "         ...,\n",
            "         [ 0.2779,  0.7342, -0.3736,  ..., -0.4601,  0.1815,  0.1850],\n",
            "         [ 0.7205, -0.2833,  0.0937,  ..., -0.1002, -2.3609,  2.2465],\n",
            "         [-1.3242, -0.1973,  0.2920,  ...,  0.5409,  0.6940,  1.8563]],\n",
            "\n",
            "        [[-0.7978,  1.0261,  1.1465,  ...,  1.2134,  0.9354, -0.0780],\n",
            "         [-1.4647, -1.9571,  0.1017,  ..., -1.9986, -0.7409,  0.7011],\n",
            "         [-1.3938,  0.8466, -1.7191,  ..., -1.1867,  0.1320,  0.3407],\n",
            "         ...,\n",
            "         [ 0.8206, -0.3745,  1.2499,  ..., -0.0676,  0.0385,  0.6335],\n",
            "         [-0.5589, -0.3393,  0.2347,  ...,  2.1181,  2.4569,  1.3083],\n",
            "         [-0.4092,  1.5199,  0.2401,  ..., -0.2558,  0.7870,  0.9924]]])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Create sample batch of random numbers with same size as image batch\n",
        "images = torch.randn(size=(32, 3, 64, 64)) # [batch_size, color_channels, height, width]\n",
        "test_image = images[0] # get a single image for testing\n",
        "print(f\"Image batch shape: {images.shape} -> [batch_size, color_channels, height, width]\")\n",
        "print(f\"Single image shape: {test_image.shape} -> [color_channels, height, width]\")\n",
        "print(f\"Single image pixel values:\\n{test_image}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd3291c2-854e-4d0c-97b9-8bf46085fc43",
      "metadata": {
        "id": "bd3291c2-854e-4d0c-97b9-8bf46085fc43"
      },
      "source": [
        "Let's create an example `nn.Conv2d()` with various parameters:\n",
        "* `in_channels` (int) - Number of channels in the input image.\n",
        "* `out_channels` (int) - Number of channels produced by the convolution.\n",
        "* `kernel_size` (int or tuple) - Size of the convolving kernel/filter.\n",
        "* `stride` (int or tuple, optional) - How big of a step the convolving kernel takes at a time. Default: 1.\n",
        "* `padding` (int, tuple, str) - Padding added to all four sides of input. Default: 0.\n",
        "\n",
        "![example of going through the different parameters of a Conv2d layer](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-conv2d-layer.gif)\n",
        "\n",
        "*Example of what happens when you change the hyperparameters of a `nn.Conv2d()` layer.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebd39562-1dad-40e3-90f5-750a5dac24e2",
      "metadata": {
        "id": "ebd39562-1dad-40e3-90f5-750a5dac24e2",
        "outputId": "4443bb45-85a7-4129-a3c6-3b423cd9a692"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 1.5396,  0.0516,  0.6454,  ..., -0.3673,  0.8711,  0.4256],\n",
              "         [ 0.3662,  1.0114, -0.5997,  ...,  0.8983,  0.2809, -0.2741],\n",
              "         [ 1.2664, -1.4054,  0.3727,  ..., -0.3409,  1.2191, -0.0463],\n",
              "         ...,\n",
              "         [-0.1541,  0.5132, -0.3624,  ..., -0.2360, -0.4609, -0.0035],\n",
              "         [ 0.2981, -0.2432,  1.5012,  ..., -0.6289, -0.7283, -0.5767],\n",
              "         [-0.0386, -0.0781, -0.0388,  ...,  0.2842,  0.4228, -0.1802]],\n",
              "\n",
              "        [[-0.2840, -0.0319, -0.4455,  ..., -0.7956,  1.5599, -1.2449],\n",
              "         [ 0.2753, -0.1262, -0.6541,  ..., -0.2211,  0.1999, -0.8856],\n",
              "         [-0.5404, -1.5489,  0.0249,  ..., -0.5932, -1.0913, -0.3849],\n",
              "         ...,\n",
              "         [ 0.3870, -0.4064, -0.8236,  ...,  0.1734, -0.4330, -0.4951],\n",
              "         [-0.1984, -0.6386,  1.0263,  ..., -0.9401, -0.0585, -0.7833],\n",
              "         [-0.6306, -0.2052, -0.3694,  ..., -1.3248,  0.2456, -0.7134]],\n",
              "\n",
              "        [[ 0.4414,  0.5100,  0.4846,  ..., -0.8484,  0.2638,  1.1258],\n",
              "         [ 0.8117,  0.3191, -0.0157,  ...,  1.2686,  0.2319,  0.5003],\n",
              "         [ 0.3212,  0.0485, -0.2581,  ...,  0.2258,  0.2587, -0.8804],\n",
              "         ...,\n",
              "         [-0.1144, -0.1869,  0.0160,  ..., -0.8346,  0.0974,  0.8421],\n",
              "         [ 0.2941,  0.4417,  0.5866,  ..., -0.1224,  0.4814, -0.4799],\n",
              "         [ 0.6059, -0.0415, -0.2028,  ...,  0.1170,  0.2521, -0.4372]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-0.2560, -0.0477,  0.6380,  ...,  0.6436,  0.7553, -0.7055],\n",
              "         [ 1.5595, -0.2209, -0.9486,  ..., -0.4876,  0.7754,  0.0750],\n",
              "         [-0.0797,  0.2471,  1.1300,  ...,  0.1505,  0.2354,  0.9576],\n",
              "         ...,\n",
              "         [ 1.1065,  0.6839,  1.2183,  ...,  0.3015, -0.1910, -0.1902],\n",
              "         [-0.3486, -0.7173, -0.3582,  ...,  0.4917,  0.7219,  0.1513],\n",
              "         [ 0.0119,  0.1017,  0.7839,  ..., -0.3752, -0.8127, -0.1257]],\n",
              "\n",
              "        [[ 0.3841,  1.1322,  0.1620,  ...,  0.7010,  0.0109,  0.6058],\n",
              "         [ 0.1664,  0.1873,  1.5924,  ...,  0.3733,  0.9096, -0.5399],\n",
              "         [ 0.4094, -0.0861, -0.7935,  ..., -0.1285, -0.9932, -0.3013],\n",
              "         ...,\n",
              "         [ 0.2688, -0.5630, -1.1902,  ...,  0.4493,  0.5404, -0.0103],\n",
              "         [ 0.0535,  0.4411,  0.5313,  ...,  0.0148, -1.0056,  0.3759],\n",
              "         [ 0.3031, -0.1590, -0.1316,  ..., -0.5384, -0.4271, -0.4876]],\n",
              "\n",
              "        [[-1.1865, -0.7280, -1.2331,  ..., -0.9013, -0.0542, -1.5949],\n",
              "         [-0.6345, -0.5920,  0.5326,  ..., -1.0395, -0.7963, -0.0647],\n",
              "         [-0.1132,  0.5166,  0.2569,  ...,  0.5595, -1.6881,  0.9485],\n",
              "         ...,\n",
              "         [-0.0254, -0.2669,  0.1927,  ..., -0.2917,  0.1088, -0.4807],\n",
              "         [-0.2609, -0.2328,  0.1404,  ..., -0.1325, -0.8436, -0.7524],\n",
              "         [-1.1399, -0.1751, -0.8705,  ...,  0.1589,  0.3377,  0.3493]]],\n",
              "       grad_fn=<SqueezeBackward1>)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Create a convolutional layer with same dimensions as TinyVGG\n",
        "# (try changing any of the parameters and see what happens)\n",
        "conv_layer = nn.Conv2d(in_channels=3,\n",
        "                       out_channels=10,\n",
        "                       kernel_size=3,\n",
        "                       stride=1,\n",
        "                       padding=0) # also try using \"valid\" or \"same\" here\n",
        "\n",
        "# Pass the data through the convolutional layer\n",
        "conv_layer(test_image) # Note: If running PyTorch <1.11.0, this will error because of shape issues (nn.Conv.2d() expects a 4d tensor as input)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb0184ad-5c16-4e1c-bcfa-70ecf15377da",
      "metadata": {
        "id": "cb0184ad-5c16-4e1c-bcfa-70ecf15377da"
      },
      "source": [
        "If we try to pass a single image in, we get a shape mismatch error:\n",
        "\n",
        "> `RuntimeError: Expected 4-dimensional input for 4-dimensional weight [10, 3, 3, 3], but got 3-dimensional input of size [3, 64, 64] instead`\n",
        ">\n",
        "> **Note:** If you're running PyTorch 1.11.0+, this error won't occur.\n",
        "\n",
        "This is because our `nn.Conv2d()` layer expects a 4-dimensional tensor as input with size `(N, C, H, W)` or `[batch_size, color_channels, height, width]`.\n",
        "\n",
        "Right now our single image `test_image` only has a shape of `[color_channels, height, width]` or `[3, 64, 64]`.\n",
        "\n",
        "We can fix this for a single image using `test_image.unsqueeze(dim=0)` to add an extra dimension for `N`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abba741d-a1ed-44ed-ba53-41d589433a2c",
      "metadata": {
        "id": "abba741d-a1ed-44ed-ba53-41d589433a2c",
        "outputId": "be8713ec-4cf6-48af-b74b-69c42b672fd2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 64, 64])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add extra dimension to test image\n",
        "test_image.unsqueeze(dim=0).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7280a49-4ee0-452b-a514-61115b6a444c",
      "metadata": {
        "id": "c7280a49-4ee0-452b-a514-61115b6a444c",
        "outputId": "3e7ff97d-34be-4b5a-d799-b3760c434e76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 62, 62])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Pass test image with extra dimension through conv_layer\n",
        "conv_layer(test_image.unsqueeze(dim=0)).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "181df81b-7c5a-46cc-b8d5-a592bf755a13",
      "metadata": {
        "id": "181df81b-7c5a-46cc-b8d5-a592bf755a13"
      },
      "source": [
        "Hmm, notice what happens to our shape (the same shape as the first layer of TinyVGG on [CNN Explainer](https://poloclub.github.io/cnn-explainer/)), we get different channel sizes as well as different pixel sizes.\n",
        "\n",
        "What if we changed the values of `conv_layer`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04445d45-cf2f-4c1d-b215-bc50865a207a",
      "metadata": {
        "id": "04445d45-cf2f-4c1d-b215-bc50865a207a",
        "outputId": "8b665d4b-81a1-4d09-9aed-bd6ea1fd0e18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 30, 30])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "# Create a new conv_layer with different values (try setting these to whatever you like)\n",
        "conv_layer_2 = nn.Conv2d(in_channels=3, # same number of color channels as our input image\n",
        "                         out_channels=10,\n",
        "                         kernel_size=(5, 5), # kernel is usually a square so a tuple also works\n",
        "                         stride=2,\n",
        "                         padding=0)\n",
        "\n",
        "# Pass single image through new conv_layer_2 (this calls nn.Conv2d()'s forward() method on the input)\n",
        "conv_layer_2(test_image.unsqueeze(dim=0)).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b27dbdbb-3e32-4ffa-803e-cf943d96c72b",
      "metadata": {
        "id": "b27dbdbb-3e32-4ffa-803e-cf943d96c72b"
      },
      "source": [
        "Woah, we get another shape change.\n",
        "\n",
        "Now our image is of shape `[1, 10, 30, 30]` (it will be different if you use different values) or `[batch_size=1, color_channels=10, height=30, width=30]`.\n",
        "\n",
        "What's going on here?\n",
        "\n",
        "Behind the scenes, our `nn.Conv2d()` is compressing the information stored in the image.\n",
        "\n",
        "It does this by performing operations on the input (our test image) against its internal parameters.\n",
        "\n",
        "The goal of this is similar to all of the other neural networks we've been building.\n",
        "\n",
        "Data goes in and the layers try to update their internal parameters (patterns) to lower the loss function thanks to some help of the optimizer.\n",
        "\n",
        "The only difference is *how* the different layers calculate their parameter updates or in PyTorch terms, the operation present in the layer `forward()` method.\n",
        "\n",
        "If we check out our `conv_layer_2.state_dict()` we'll find a similar weight and bias setup as we've seen before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46027ed1-c3a7-46bd-bab7-17f8c20e354b",
      "metadata": {
        "id": "46027ed1-c3a7-46bd-bab7-17f8c20e354b",
        "outputId": "b8fd688b-0f66-407b-de4b-94a59f77bdae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('weight', tensor([[[[ 0.0883,  0.0958, -0.0271,  0.1061, -0.0253],\n",
            "          [ 0.0233, -0.0562,  0.0678,  0.1018, -0.0847],\n",
            "          [ 0.1004,  0.0216,  0.0853,  0.0156,  0.0557],\n",
            "          [-0.0163,  0.0890,  0.0171, -0.0539,  0.0294],\n",
            "          [-0.0532, -0.0135, -0.0469,  0.0766, -0.0911]],\n",
            "\n",
            "         [[-0.0532, -0.0326, -0.0694,  0.0109, -0.1140],\n",
            "          [ 0.1043, -0.0981,  0.0891,  0.0192, -0.0375],\n",
            "          [ 0.0714,  0.0180,  0.0933,  0.0126, -0.0364],\n",
            "          [ 0.0310, -0.0313,  0.0486,  0.1031,  0.0667],\n",
            "          [-0.0505,  0.0667,  0.0207,  0.0586, -0.0704]],\n",
            "\n",
            "         [[-0.1143, -0.0446, -0.0886,  0.0947,  0.0333],\n",
            "          [ 0.0478,  0.0365, -0.0020,  0.0904, -0.0820],\n",
            "          [ 0.0073, -0.0788,  0.0356, -0.0398,  0.0354],\n",
            "          [-0.0241,  0.0958, -0.0684, -0.0689, -0.0689],\n",
            "          [ 0.1039,  0.0385,  0.1111, -0.0953, -0.1145]]],\n",
            "\n",
            "\n",
            "        [[[-0.0903, -0.0777,  0.0468,  0.0413,  0.0959],\n",
            "          [-0.0596, -0.0787,  0.0613, -0.0467,  0.0701],\n",
            "          [-0.0274,  0.0661, -0.0897, -0.0583,  0.0352],\n",
            "          [ 0.0244, -0.0294,  0.0688,  0.0785, -0.0837],\n",
            "          [-0.0616,  0.1057, -0.0390, -0.0409, -0.1117]],\n",
            "\n",
            "         [[-0.0661,  0.0288, -0.0152, -0.0838,  0.0027],\n",
            "          [-0.0789, -0.0980, -0.0636, -0.1011, -0.0735],\n",
            "          [ 0.1154,  0.0218,  0.0356, -0.1077, -0.0758],\n",
            "          [-0.0384,  0.0181, -0.1016, -0.0498, -0.0691],\n",
            "          [ 0.0003, -0.0430, -0.0080, -0.0782, -0.0793]],\n",
            "\n",
            "         [[-0.0674, -0.0395, -0.0911,  0.0968, -0.0229],\n",
            "          [ 0.0994,  0.0360, -0.0978,  0.0799, -0.0318],\n",
            "          [-0.0443, -0.0958, -0.1148,  0.0330, -0.0252],\n",
            "          [ 0.0450, -0.0948,  0.0857, -0.0848, -0.0199],\n",
            "          [ 0.0241,  0.0596,  0.0932,  0.1052, -0.0916]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0291, -0.0497, -0.0127, -0.0864,  0.1052],\n",
            "          [-0.0847,  0.0617,  0.0406,  0.0375, -0.0624],\n",
            "          [ 0.1050,  0.0254,  0.0149, -0.1018,  0.0485],\n",
            "          [-0.0173, -0.0529,  0.0992,  0.0257, -0.0639],\n",
            "          [-0.0584, -0.0055,  0.0645, -0.0295, -0.0659]],\n",
            "\n",
            "         [[-0.0395, -0.0863,  0.0412,  0.0894, -0.1087],\n",
            "          [ 0.0268,  0.0597,  0.0209, -0.0411,  0.0603],\n",
            "          [ 0.0607,  0.0432, -0.0203, -0.0306,  0.0124],\n",
            "          [-0.0204, -0.0344,  0.0738,  0.0992, -0.0114],\n",
            "          [-0.0259,  0.0017, -0.0069,  0.0278,  0.0324]],\n",
            "\n",
            "         [[-0.1049, -0.0426,  0.0972,  0.0450, -0.0057],\n",
            "          [-0.0696, -0.0706, -0.1034, -0.0376,  0.0390],\n",
            "          [ 0.0736,  0.0533, -0.1021, -0.0694, -0.0182],\n",
            "          [ 0.1117,  0.0167, -0.0299,  0.0478, -0.0440],\n",
            "          [-0.0747,  0.0843, -0.0525, -0.0231, -0.1149]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0773,  0.0875,  0.0421, -0.0805, -0.1140],\n",
            "          [-0.0938,  0.0861,  0.0554,  0.0972,  0.0605],\n",
            "          [ 0.0292, -0.0011, -0.0878, -0.0989, -0.1080],\n",
            "          [ 0.0473, -0.0567, -0.0232, -0.0665, -0.0210],\n",
            "          [-0.0813, -0.0754,  0.0383, -0.0343,  0.0713]],\n",
            "\n",
            "         [[-0.0370, -0.0847, -0.0204, -0.0560, -0.0353],\n",
            "          [-0.1099,  0.0646, -0.0804,  0.0580,  0.0524],\n",
            "          [ 0.0825, -0.0886,  0.0830, -0.0546,  0.0428],\n",
            "          [ 0.1084, -0.0163, -0.0009, -0.0266, -0.0964],\n",
            "          [ 0.0554, -0.1146,  0.0717,  0.0864,  0.1092]],\n",
            "\n",
            "         [[-0.0272, -0.0949,  0.0260,  0.0638, -0.1149],\n",
            "          [-0.0262, -0.0692, -0.0101, -0.0568, -0.0472],\n",
            "          [-0.0367, -0.1097,  0.0947,  0.0968, -0.0181],\n",
            "          [-0.0131, -0.0471, -0.1043, -0.1124,  0.0429],\n",
            "          [-0.0634, -0.0742, -0.0090, -0.0385, -0.0374]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0037, -0.0245, -0.0398, -0.0553, -0.0940],\n",
            "          [ 0.0968, -0.0462,  0.0306, -0.0401,  0.0094],\n",
            "          [ 0.1077,  0.0532, -0.1001,  0.0458,  0.1096],\n",
            "          [ 0.0304,  0.0774,  0.1138, -0.0177,  0.0240],\n",
            "          [-0.0803, -0.0238,  0.0855,  0.0592, -0.0731]],\n",
            "\n",
            "         [[-0.0926, -0.0789, -0.1140, -0.0891, -0.0286],\n",
            "          [ 0.0779,  0.0193, -0.0878, -0.0926,  0.0574],\n",
            "          [-0.0859, -0.0142,  0.0554, -0.0534, -0.0126],\n",
            "          [-0.0101, -0.0273, -0.0585, -0.1029, -0.0933],\n",
            "          [-0.0618,  0.1115, -0.0558, -0.0775,  0.0280]],\n",
            "\n",
            "         [[ 0.0318,  0.0633,  0.0878,  0.0643, -0.1145],\n",
            "          [ 0.0102,  0.0699, -0.0107, -0.0680,  0.1101],\n",
            "          [-0.0432, -0.0657, -0.1041,  0.0052,  0.0512],\n",
            "          [ 0.0256,  0.0228, -0.0876, -0.1078,  0.0020],\n",
            "          [ 0.1053,  0.0666, -0.0672, -0.0150, -0.0851]]],\n",
            "\n",
            "\n",
            "        [[[-0.0557,  0.0209,  0.0629,  0.0957, -0.1060],\n",
            "          [ 0.0772, -0.0814,  0.0432,  0.0977,  0.0016],\n",
            "          [ 0.1051, -0.0984, -0.0441,  0.0673, -0.0252],\n",
            "          [-0.0236, -0.0481,  0.0796,  0.0566,  0.0370],\n",
            "          [-0.0649, -0.0937,  0.0125,  0.0342, -0.0533]],\n",
            "\n",
            "         [[-0.0323,  0.0780,  0.0092,  0.0052, -0.0284],\n",
            "          [-0.1046, -0.1086, -0.0552, -0.0587,  0.0360],\n",
            "          [-0.0336, -0.0452,  0.1101,  0.0402,  0.0823],\n",
            "          [-0.0559, -0.0472,  0.0424, -0.0769, -0.0755],\n",
            "          [-0.0056, -0.0422, -0.0866,  0.0685,  0.0929]],\n",
            "\n",
            "         [[ 0.0187, -0.0201, -0.1070, -0.0421,  0.0294],\n",
            "          [ 0.0544, -0.0146, -0.0457,  0.0643, -0.0920],\n",
            "          [ 0.0730, -0.0448,  0.0018, -0.0228,  0.0140],\n",
            "          [-0.0349,  0.0840, -0.0030,  0.0901,  0.1110],\n",
            "          [-0.0563, -0.0842,  0.0926,  0.0905, -0.0882]]],\n",
            "\n",
            "\n",
            "        [[[-0.0089, -0.1139, -0.0945,  0.0223,  0.0307],\n",
            "          [ 0.0245, -0.0314,  0.1065,  0.0165, -0.0681],\n",
            "          [-0.0065,  0.0277,  0.0404, -0.0816,  0.0433],\n",
            "          [-0.0590, -0.0959, -0.0631,  0.1114,  0.0987],\n",
            "          [ 0.1034,  0.0678,  0.0872, -0.0155, -0.0635]],\n",
            "\n",
            "         [[ 0.0577, -0.0598, -0.0779, -0.0369,  0.0242],\n",
            "          [ 0.0594, -0.0448, -0.0680,  0.0156, -0.0681],\n",
            "          [-0.0752,  0.0602, -0.0194,  0.1055,  0.1123],\n",
            "          [ 0.0345,  0.0397,  0.0266,  0.0018, -0.0084],\n",
            "          [ 0.0016,  0.0431,  0.1074, -0.0299, -0.0488]],\n",
            "\n",
            "         [[-0.0280, -0.0558,  0.0196,  0.0862,  0.0903],\n",
            "          [ 0.0530, -0.0850, -0.0620, -0.0254, -0.0213],\n",
            "          [ 0.0095, -0.1060,  0.0359, -0.0881, -0.0731],\n",
            "          [-0.0960,  0.1006, -0.1093,  0.0871, -0.0039],\n",
            "          [-0.0134,  0.0722, -0.0107,  0.0724,  0.0835]]],\n",
            "\n",
            "\n",
            "        [[[-0.1003,  0.0444,  0.0218,  0.0248,  0.0169],\n",
            "          [ 0.0316, -0.0555, -0.0148,  0.1097,  0.0776],\n",
            "          [-0.0043, -0.1086,  0.0051, -0.0786,  0.0939],\n",
            "          [-0.0701, -0.0083, -0.0256,  0.0205,  0.1087],\n",
            "          [ 0.0110,  0.0669,  0.0896,  0.0932, -0.0399]],\n",
            "\n",
            "         [[-0.0258,  0.0556, -0.0315,  0.0541, -0.0252],\n",
            "          [-0.0783,  0.0470,  0.0177,  0.0515,  0.1147],\n",
            "          [ 0.0788,  0.1095,  0.0062, -0.0993, -0.0810],\n",
            "          [-0.0717, -0.1018, -0.0579, -0.1063, -0.1065],\n",
            "          [-0.0690, -0.1138, -0.0709,  0.0440,  0.0963]],\n",
            "\n",
            "         [[-0.0343, -0.0336,  0.0617, -0.0570, -0.0546],\n",
            "          [ 0.0711, -0.1006,  0.0141,  0.1020,  0.0198],\n",
            "          [ 0.0314, -0.0672, -0.0016,  0.0063,  0.0283],\n",
            "          [ 0.0449,  0.1003, -0.0881,  0.0035, -0.0577],\n",
            "          [-0.0913, -0.0092, -0.1016,  0.0806,  0.0134]]],\n",
            "\n",
            "\n",
            "        [[[-0.0622,  0.0603, -0.1093, -0.0447, -0.0225],\n",
            "          [-0.0981, -0.0734, -0.0188,  0.0876,  0.1115],\n",
            "          [ 0.0735, -0.0689, -0.0755,  0.1008,  0.0408],\n",
            "          [ 0.0031,  0.0156, -0.0928, -0.0386,  0.1112],\n",
            "          [-0.0285, -0.0058, -0.0959, -0.0646, -0.0024]],\n",
            "\n",
            "         [[-0.0717, -0.0143,  0.0470, -0.1130,  0.0343],\n",
            "          [-0.0763, -0.0564,  0.0443,  0.0918, -0.0316],\n",
            "          [-0.0474, -0.1044, -0.0595, -0.1011, -0.0264],\n",
            "          [ 0.0236, -0.1082,  0.1008,  0.0724, -0.1130],\n",
            "          [-0.0552,  0.0377, -0.0237, -0.0126, -0.0521]],\n",
            "\n",
            "         [[ 0.0927, -0.0645,  0.0958,  0.0075,  0.0232],\n",
            "          [ 0.0901, -0.0190, -0.0657, -0.0187,  0.0937],\n",
            "          [-0.0857,  0.0262, -0.1135,  0.0605,  0.0427],\n",
            "          [ 0.0049,  0.0496,  0.0001,  0.0639, -0.0914],\n",
            "          [-0.0170,  0.0512,  0.1150,  0.0588, -0.0840]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0888, -0.0257, -0.0247, -0.1050, -0.0182],\n",
            "          [ 0.0817,  0.0161, -0.0673,  0.0355, -0.0370],\n",
            "          [ 0.1054, -0.1002, -0.0365, -0.1115, -0.0455],\n",
            "          [ 0.0364,  0.1112,  0.0194,  0.1132,  0.0226],\n",
            "          [ 0.0667,  0.0926,  0.0965, -0.0646,  0.1062]],\n",
            "\n",
            "         [[ 0.0699, -0.0540, -0.0551, -0.0969,  0.0290],\n",
            "          [-0.0936,  0.0488,  0.0365, -0.1003,  0.0315],\n",
            "          [-0.0094,  0.0527,  0.0663, -0.1148,  0.1059],\n",
            "          [ 0.0968,  0.0459, -0.1055, -0.0412, -0.0335],\n",
            "          [-0.0297,  0.0651,  0.0420,  0.0915, -0.0432]],\n",
            "\n",
            "         [[ 0.0389,  0.0411, -0.0961, -0.1120, -0.0599],\n",
            "          [ 0.0790, -0.1087, -0.1005,  0.0647,  0.0623],\n",
            "          [ 0.0950, -0.0872, -0.0845,  0.0592,  0.1004],\n",
            "          [ 0.0691,  0.0181,  0.0381,  0.1096, -0.0745],\n",
            "          [-0.0524,  0.0808, -0.0790, -0.0637,  0.0843]]]])), ('bias', tensor([ 0.0364,  0.0373, -0.0489, -0.0016,  0.1057, -0.0693,  0.0009,  0.0549,\n",
            "        -0.0797,  0.1121]))])\n"
          ]
        }
      ],
      "source": [
        "# Check out the conv_layer_2 internal parameters\n",
        "print(conv_layer_2.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b708eb6-ae46-4d8c-a8a4-1392827d3e37",
      "metadata": {
        "id": "8b708eb6-ae46-4d8c-a8a4-1392827d3e37"
      },
      "source": [
        "Look at that! A bunch of random numbers for a weight and bias tensor.\n",
        "\n",
        "The shapes of these are manipulated by the inputs we passed to `nn.Conv2d()` when we set it up.\n",
        "\n",
        "Let's check them out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5518d61-c0b7-4351-b5ea-4d6b6144291a",
      "metadata": {
        "id": "e5518d61-c0b7-4351-b5ea-4d6b6144291a",
        "outputId": "8ff6fcb3-aa4e-4736-d9d4-a6df96d19170"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "conv_layer_2 weight shape: \n",
            "torch.Size([10, 3, 5, 5]) -> [out_channels=10, in_channels=3, kernel_size=5, kernel_size=5]\n",
            "\n",
            "conv_layer_2 bias shape: \n",
            "torch.Size([10]) -> [out_channels=10]\n"
          ]
        }
      ],
      "source": [
        "# Get shapes of weight and bias tensors within conv_layer_2\n",
        "print(f\"conv_layer_2 weight shape: \\n{conv_layer_2.weight.shape} -> [out_channels=10, in_channels=3, kernel_size=5, kernel_size=5]\")\n",
        "print(f\"\\nconv_layer_2 bias shape: \\n{conv_layer_2.bias.shape} -> [out_channels=10]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0de23c7-4501-4156-80a4-ac889a636a42",
      "metadata": {
        "id": "f0de23c7-4501-4156-80a4-ac889a636a42"
      },
      "source": [
        "> **Question:** What should we set the parameters of our `nn.Conv2d()` layers?\n",
        ">\n",
        "> That's a good one. But similar to many other things in machine learning, the values of these aren't set in stone (and recall, because these values are ones we can set ourselves, they're referred to as \"**hyperparameters**\").\n",
        ">\n",
        "> The best way to find out is to try out different values and see how they effect your model's performance.\n",
        ">\n",
        "> Or even better, find a working example on a problem similar to yours (like we've done with TinyVGG) and copy it.\n",
        "\n",
        "We're working with a different of layer here to what we've seen before.\n",
        "\n",
        "But the premise remains the same: start with random numbers and update them to better represent the data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6370d45d-ca44-4fa0-a2d7-efaf0a207b91",
      "metadata": {
        "id": "6370d45d-ca44-4fa0-a2d7-efaf0a207b91"
      },
      "source": [
        "### 7.2 Stepping through `nn.MaxPool2d()`\n",
        "Now let's check out what happens when we move data through `nn.MaxPool2d()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1164c753-19d9-43b7-a04f-017d0f7188c3",
      "metadata": {
        "id": "1164c753-19d9-43b7-a04f-017d0f7188c3",
        "outputId": "1c94c3c0-dddb-4b28-d0ad-e650bc082de8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test image original shape: torch.Size([3, 64, 64])\n",
            "Test image with unsqueezed dimension: torch.Size([1, 3, 64, 64])\n",
            "Shape after going through conv_layer(): torch.Size([1, 10, 62, 62])\n",
            "Shape after going through conv_layer() and max_pool_layer(): torch.Size([1, 10, 31, 31])\n"
          ]
        }
      ],
      "source": [
        "# Print out original image shape without and with unsqueezed dimension\n",
        "print(f\"Test image original shape: {test_image.shape}\")\n",
        "print(f\"Test image with unsqueezed dimension: {test_image.unsqueeze(dim=0).shape}\")\n",
        "\n",
        "# Create a sample nn.MaxPoo2d() layer\n",
        "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "# Pass data through just the conv_layer\n",
        "test_image_through_conv = conv_layer(test_image.unsqueeze(dim=0))\n",
        "print(f\"Shape after going through conv_layer(): {test_image_through_conv.shape}\")\n",
        "\n",
        "# Pass data through the max pool layer\n",
        "test_image_through_conv_and_max_pool = max_pool_layer(test_image_through_conv)\n",
        "print(f\"Shape after going through conv_layer() and max_pool_layer(): {test_image_through_conv_and_max_pool.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de029abd-6674-4bfa-99ab-322f339f89f4",
      "metadata": {
        "id": "de029abd-6674-4bfa-99ab-322f339f89f4"
      },
      "source": [
        "Notice the change in the shapes of what's happening in and out of a `nn.MaxPool2d()` layer.\n",
        "\n",
        "The `kernel_size` of the `nn.MaxPool2d()` layer will effects the size of the output shape.\n",
        "\n",
        "In our case, the shape halves from a `62x62` image to `31x31` image.\n",
        "\n",
        "Let's see this work with a smaller tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6a2b196-4845-4b40-9212-e75406e88875",
      "metadata": {
        "id": "e6a2b196-4845-4b40-9212-e75406e88875",
        "outputId": "4d6cb9e4-d47c-459e-a1cd-adc496cba4d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random tensor:\n",
            "tensor([[[[0.3367, 0.1288],\n",
            "          [0.2345, 0.2303]]]])\n",
            "Random tensor shape: torch.Size([1, 1, 2, 2])\n",
            "\n",
            "Max pool tensor:\n",
            "tensor([[[[0.3367]]]]) <- this is the maximum value from random_tensor\n",
            "Max pool tensor shape: torch.Size([1, 1, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "# Create a random tensor with a similiar number of dimensions to our images\n",
        "random_tensor = torch.randn(size=(1, 1, 2, 2))\n",
        "print(f\"Random tensor:\\n{random_tensor}\")\n",
        "print(f\"Random tensor shape: {random_tensor.shape}\")\n",
        "\n",
        "# Create a max pool layer\n",
        "max_pool_layer = nn.MaxPool2d(kernel_size=2) # see what happens when you change the kernel_size value\n",
        "\n",
        "# Pass the random tensor through the max pool layer\n",
        "max_pool_tensor = max_pool_layer(random_tensor)\n",
        "print(f\"\\nMax pool tensor:\\n{max_pool_tensor} <- this is the maximum value from random_tensor\")\n",
        "print(f\"Max pool tensor shape: {max_pool_tensor.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "002e586e-dcb3-40fe-a7dd-a1c18a3b8da0",
      "metadata": {
        "id": "002e586e-dcb3-40fe-a7dd-a1c18a3b8da0"
      },
      "source": [
        "Notice the final two dimensions between `random_tensor` and `max_pool_tensor`, they go from `[2, 2]` to `[1, 1]`.\n",
        "\n",
        "In essence, they get halved.\n",
        "\n",
        "And the change would be different for different values of `kernel_size` for `nn.MaxPool2d()`.\n",
        "\n",
        "Also notice the value leftover in `max_pool_tensor` is the **maximum** value from `random_tensor`.\n",
        "\n",
        "What's happening here?\n",
        "\n",
        "This is another important piece of the puzzle of neural networks.\n",
        "\n",
        "Essentially, **every layer in a neural network is trying to compress data from higher dimensional space to lower dimensional space**.\n",
        "\n",
        "In other words, take a lot of numbers (raw data) and learn patterns in those numbers, patterns that are predictive whilst also being *smaller* in size than the original values.\n",
        "\n",
        "From an artificial intelligence perspective, you could consider the whole goal of a neural network to *compress* information.\n",
        "\n",
        "![each layer of a neural network compresses the original input data into a smaller representation that is (hopefully) capable of making predictions on future input data](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-conv-net-as-compression.png)\n",
        "\n",
        "This means, that from the point of view of a neural network, intelligence is compression.\n",
        "\n",
        "This is the idea of the use of a `nn.MaxPool2d()` layer: take the maximum value from a portion of a tensor and disregard the rest.\n",
        "\n",
        "In essence, lowering the dimensionality of a tensor whilst still retaining a (hopefully) significant portion of the information.\n",
        "\n",
        "It is the same story for a `nn.Conv2d()` layer.\n",
        "\n",
        "Except instead of just taking the maximum, the `nn.Conv2d()` performs a conovlutional operation on the data (see this in action on the [CNN Explainer webpage](https://poloclub.github.io/cnn-explainer/)).\n",
        "\n",
        "> **Exercise:** What do you think the [`nn.AvgPool2d()`](https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html) layer does? Try making a random tensor like we did above and passing it through. Check the input and output shapes as well as the input and output values.\n",
        "\n",
        "> **Extra-curriculum:** Lookup \"most common convolutional neural networks\", what architectures do you find? Are any of them contained within the [`torchvision.models`](https://pytorch.org/vision/stable/models.html) library? What do you think you could do with these?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39a3c646-52f0-4f4b-8527-2fc33d0dfb13",
      "metadata": {
        "id": "39a3c646-52f0-4f4b-8527-2fc33d0dfb13"
      },
      "source": [
        "### 7.3 Setup a loss function and optimizer for `model_2`\n",
        "\n",
        "We've stepped through the layers in our first CNN enough.\n",
        "\n",
        "But remember, if something still isn't clear, try starting small.\n",
        "\n",
        "Pick a single layer of a model, pass some data through it and see what happens.\n",
        "\n",
        "Now it's time to move forward and get to training!\n",
        "\n",
        "Let's setup a loss function and an optimizer.\n",
        "\n",
        "We'll use the functions as before, `nn.CrossEntropyLoss()` as the loss function (since we're working with multi-class classification data).\n",
        "\n",
        "And `torch.optim.SGD()` as the optimizer to optimize `model_2.parameters()` with a learning rate of `0.1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06a76a1b-5f6f-4018-bf7b-8388b385476f",
      "metadata": {
        "id": "06a76a1b-5f6f-4018-bf7b-8388b385476f"
      },
      "outputs": [],
      "source": [
        "# Setup loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_2.parameters(),\n",
        "                             lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "758bc223-a244-4604-a07a-e2fc2f96c2f6",
      "metadata": {
        "id": "758bc223-a244-4604-a07a-e2fc2f96c2f6"
      },
      "source": [
        "### 7.4 Training and testing `model_2` using our training and test functions\n",
        "\n",
        "Loss and optimizer ready!\n",
        "\n",
        "Time to train and test.\n",
        "\n",
        "We'll use our `train_step()` and `test_step()` functions we created before.\n",
        "\n",
        "We'll also measure the time to compare it to our other models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "861d126e-d876-40b3-9b7a-66cfc2f1bf05",
      "metadata": {
        "id": "861d126e-d876-40b3-9b7a-66cfc2f1bf05",
        "outputId": "49b86ffe-fdb9-45ec-bed6-012215359332"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc69ce706c5c45099e57919dfcae065c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "---------\n",
            "Train loss: 0.59411 | Train accuracy: 78.41%\n",
            "Test loss: 0.39967 | Test accuracy: 85.70%\n",
            "\n",
            "Epoch: 1\n",
            "---------\n",
            "Train loss: 0.36450 | Train accuracy: 86.81%\n",
            "Test loss: 0.34607 | Test accuracy: 87.48%\n",
            "\n",
            "Epoch: 2\n",
            "---------\n",
            "Train loss: 0.32553 | Train accuracy: 88.33%\n",
            "Test loss: 0.32664 | Test accuracy: 88.23%\n",
            "\n",
            "Train time on cuda: 21.099 seconds\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Measure time\n",
        "from timeit import default_timer as timer\n",
        "train_time_start_model_2 = timer()\n",
        "\n",
        "# Train and test model\n",
        "epochs = 3\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    print(f\"Epoch: {epoch}\\n---------\")\n",
        "    train_step(data_loader=train_dataloader,\n",
        "        model=model_2,\n",
        "        loss_fn=loss_fn,\n",
        "        optimizer=optimizer,\n",
        "        accuracy_fn=accuracy_fn,\n",
        "        device=device\n",
        "    )\n",
        "    test_step(data_loader=test_dataloader,\n",
        "        model=model_2,\n",
        "        loss_fn=loss_fn,\n",
        "        accuracy_fn=accuracy_fn,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "train_time_end_model_2 = timer()\n",
        "total_train_time_model_2 = print_train_time(start=train_time_start_model_2,\n",
        "                                           end=train_time_end_model_2,\n",
        "                                           device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfec7b7e-4dba-4016-957a-a29c6c10fde0",
      "metadata": {
        "id": "cfec7b7e-4dba-4016-957a-a29c6c10fde0"
      },
      "source": [
        "Woah! Looks like the convolutional and max pooling layers helped improve performance a little.\n",
        "\n",
        "Let's evaluate `model_2`'s results with our `eval_model()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1bf8b89-1389-4395-a1c4-9c6e94d9e71c",
      "metadata": {
        "id": "c1bf8b89-1389-4395-a1c4-9c6e94d9e71c",
        "outputId": "50beb128-6e28-4c67-d2be-603712c3acb7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model_name': 'FashionMNISTModelV2',\n",
              " 'model_loss': 0.32664385437965393,\n",
              " 'model_acc': 88.22883386581469}"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get model_2 results\n",
        "model_2_results = eval_model(\n",
        "    model=model_2,\n",
        "    data_loader=test_dataloader,\n",
        "    loss_fn=loss_fn,\n",
        "    accuracy_fn=accuracy_fn\n",
        ")\n",
        "model_2_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24c5ff68-b0bc-4b09-9da6-696736bc262d",
      "metadata": {
        "id": "24c5ff68-b0bc-4b09-9da6-696736bc262d"
      },
      "source": [
        "## 8. Compare model results and training time\n",
        "\n",
        "We've trained three different models.\n",
        "\n",
        "1. `model_0` - our baseline model with two `nn.Linear()` layers.\n",
        "2. `model_1` - the same setup as our baseline model except with `nn.ReLU()` layers in between the `nn.Linear()` layers.\n",
        "3. `model_2` - our first CNN model that mimics the TinyVGG architecture on the CNN Explainer website.\n",
        "\n",
        "This is a regular practice in machine learning.\n",
        "\n",
        "Building multiple models and performing multiple training experiments to see which performs best.\n",
        "\n",
        "Let's combine our model results dictionaries into a DataFrame and find out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52d84ee1-1ad4-4860-b147-f8912c1febc7",
      "metadata": {
        "id": "52d84ee1-1ad4-4860-b147-f8912c1febc7",
        "outputId": "87cfbdba-9bea-4a57-8d10-735c2315f6bd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>model_loss</th>\n",
              "      <th>model_acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FashionMNISTModelV0</td>\n",
              "      <td>0.476639</td>\n",
              "      <td>83.426518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FashionMNISTModelV1</td>\n",
              "      <td>0.685001</td>\n",
              "      <td>75.019968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FashionMNISTModelV2</td>\n",
              "      <td>0.326644</td>\n",
              "      <td>88.228834</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            model_name  model_loss  model_acc\n",
              "0  FashionMNISTModelV0    0.476639  83.426518\n",
              "1  FashionMNISTModelV1    0.685001  75.019968\n",
              "2  FashionMNISTModelV2    0.326644  88.228834"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "compare_results = pd.DataFrame([model_0_results, model_1_results, model_2_results])\n",
        "compare_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c67f3fb5-ce7b-40b8-86a0-2797492de0ef",
      "metadata": {
        "id": "c67f3fb5-ce7b-40b8-86a0-2797492de0ef"
      },
      "source": [
        "Nice!\n",
        "\n",
        "We can add the training time values too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "297af38f-e69f-4c6f-9027-fcaf0482a55c",
      "metadata": {
        "id": "297af38f-e69f-4c6f-9027-fcaf0482a55c",
        "outputId": "efe4af34-8f27-429c-e457-ccec397b478f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>model_loss</th>\n",
              "      <th>model_acc</th>\n",
              "      <th>training_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FashionMNISTModelV0</td>\n",
              "      <td>0.476639</td>\n",
              "      <td>83.426518</td>\n",
              "      <td>14.974887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FashionMNISTModelV1</td>\n",
              "      <td>0.685001</td>\n",
              "      <td>75.019968</td>\n",
              "      <td>16.942553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FashionMNISTModelV2</td>\n",
              "      <td>0.326644</td>\n",
              "      <td>88.228834</td>\n",
              "      <td>21.098929</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            model_name  model_loss  model_acc  training_time\n",
              "0  FashionMNISTModelV0    0.476639  83.426518      14.974887\n",
              "1  FashionMNISTModelV1    0.685001  75.019968      16.942553\n",
              "2  FashionMNISTModelV2    0.326644  88.228834      21.098929"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add training times to results comparison\n",
        "compare_results[\"training_time\"] = [total_train_time_model_0,\n",
        "                                    total_train_time_model_1,\n",
        "                                    total_train_time_model_2]\n",
        "compare_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbbe5832-1081-4c76-8d5b-06c7a06da7b9",
      "metadata": {
        "id": "fbbe5832-1081-4c76-8d5b-06c7a06da7b9"
      },
      "source": [
        "It looks like our CNN (`FashionMNISTModelV2`) model performed the best (lowest loss, highest accuracy) but had the longest training time.\n",
        "\n",
        "And our baseline model (`FashionMNISTModelV0`) performed better than `model_1` (`FashionMNISTModelV1`) but took longer to train (this is likely because we used a CPU to train `model_0` but a GPU to train `model_1`).\n",
        "\n",
        "The tradeoffs here are known as the **performance-speed** tradeoff.\n",
        "\n",
        "Generally, you get better performance out of a larger, more complex model (like we did with `model_2`).\n",
        "\n",
        "However, this performance increase often comes at a sacrifice of training speed and inference speed.\n",
        "\n",
        "\n",
        "> **Note:** The training times you get will be very dependant on the hardware you use.\n",
        ">\n",
        "> Generally, the more CPU cores you have, the faster your models will train on CPU. And similar for GPUs.\n",
        ">\n",
        "> Newer hardware (in terms of age) will also often train models faster due to incorporating technology advances.\n",
        "\n",
        "How about we get visual?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eb0df60-9318-47d0-adce-f8788ed3999e",
      "metadata": {
        "id": "5eb0df60-9318-47d0-adce-f8788ed3999e",
        "outputId": "bf7c4107-472b-47bd-8b86-3ae5c1417559"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeIAAAEGCAYAAAC5PJY3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbLklEQVR4nO3de7BmVX3m8e8DKBdRJgawmmvjCCJyh1ERNCG0CRFBSDRA0AEzUzrxmlFLcTROJt7AEsqhUCbECCjYgAoMhIsXgqUBEbu5dIMNxsJWEUYgIIE01+Y3f+zV9Mvh9Dnvge5eQH8/VafO+6699t5rrYJ+zlr7ffdOVSFJkvpYq3cDJElakxnEkiR1ZBBLktSRQSxJUkcGsSRJHa3TuwF65tl4441r9uzZvZshSc8Y8+fPv7OqNplsm0GsGZs9ezbz5s3r3QxJesZI8osVbXNpWpKkjgxiSZI6MoglSerIIJYkqSODWJKkjgxiSZI6MoglSerIIJYkqSODWJKkjgxiSZI6MoglSerIIJYkqSODWJKkjgxiSZI6MoglSerIIJYkqaN1ejdAzzwLf30Ps4++sHczJGm1WXzMAavs2M6IJUnqyCCWJKkjg1iSpI4MYkmSOjKIJUnqyCCWJKkjg1iSpI4MYkmSOjKIJUnqyCCWJKkjg1iSpI4MYkmSOjKIJUnqyCCWJKmjVRbESZYmuXbkZ/YM91+cZONJyg9KcvSTbNPsJJXkEyNlGyd5OMmJ7f3fJFmSZNOROvdNfJ1krSQnJLk+ycIkP06yTZIftf7+Mskdo/1vffrBhDZdm+T6Gfbje0n2HKdOklOTvGPCtoOTXJRkyySXJVmU5IYk75tJOyRJT92qfB7x/VW168o+aFWdD5z/FA5xM/AG4K/b+zcDN0yocyfwAeDDUxznUGAzYOeqejTJFsC/V9UrAZIcBexZVe9etkMSgOcn2bKqfpXkZU+hH+OaCxwN/N1I2WGt/BHgA1V1dZLnA/OTfKeqfrIa2iVJYjUuTSfZMMmlSa5uM8g3tvLnJbkwyXVtdnnoyG7vGam/fat/1Mjsdet2zAXt91at/NQ2W70iyc1J3jRyzPuBRSMzykOBsyc098vAoUleOEWXZgG3VdWjAFV1S1XdPcZQnN3OCXA4QyAuG6P1kpzS+ntNkn1b+fpJzmz9PAtYf2SfP0zywzZOX0+y4YTzfRfYPsmsVn8DYA5wXlXdVlVXt/bfCywCNh+jD5KklWRVBvH6I8uy5wIPAIdU1e7AvsBxGaaI+wO3VtUuVbUjcMnIMe5s9U8CPjjJOU4EvlJVOwNnACeMbJsF7MMw+z1mwn5nAoe1WexS4NYJ2+9jCOOplmrPBg5s/TsuyW5T1B31DeBP2usDgQtGtr0LoKp2Ygjp05KsB/wlsKT181PAHjAsqwMfA+a0cZoHvH/0ZFW1FDgH+LNWdBBwWQvex7RLB7sBPxqzH5KklWBVBvH9VbVr+zkECPDpJAsYZmmbAy8CFgJzkhyb5DVVdc/IMc5pv+cDsyc5x17A19rrrzIE7zLnVdWjbZn1RRP2uwR4HUPYnbWC9p8AHJnkBZNtrKpbgJcCHwEeBS5Nst8KjjXqLuDuJIcxzECXjGzbp/WDqroR+AWwHfBa4PRWvgBY0Oq/CtgBuDzJtcCRwNaTnHMuw3I0LF+WfkybRX8T+Kuq+rfJGp3k7UnmJZm3dMk9k1WRJD0Jq/Ia8URHAJsAe1TVw0kWA+tV1U+T7AG8HvhMkm9X1d+2fR5sv5eO2dYaef3gyOs8rlLVQ0nmM1wHfjnDzJQJdX6b5GvAO1d4sqoHgYuBi5P8BjgYuHSMdp4FfAE4akJ5nlh1+ekmKQvwnao6fJrzXQ7MSrIL8GqWhzJJnsMQwmdU1Tkr2J+qOhk4GWDdWdtO1hZJ0pOwOr++tBFwewvhfWkztySbMSy7ng58Dth9Bse8guWhcgTwzzPY9zjgw1X1r1PUOR54B5P8EZBk99Z2kqwF7Mwwgx3HucBngW9NKP8+Qz9Ish2wFXDThPId27kArgT2TvKStm2Dtt/jVFUxLKWfBlxUVQ+0+gH+AVhUVceP2XZJ0kq0OoP4DGDPJPMYQuXGVr4TcFVbWv0o8MkZHPO9wNvacvdbmfqa7uNU1Q1Vddo0de5kCM11J9m8KXBB++rRAoZPIJ845rnvrapjq+qhCZu+CKydZCHDrPmoNus+Cdiw9fNDwFXtOHcwzKrntm1XAtuv4LRzgV0Yro8vszfDuP3ByPX814/TB0nSypFhsiSNb91Z29asIz/fuxmStNosPuaAp7R/kvlVNen9H7yzliRJHRnEkiR1ZBBLktSRQSxJUkcGsSRJHRnEkiR1ZBBLktSRQSxJUkcGsSRJHRnEkiR1ZBBLktSRQSxJUkcGsSRJHT3hObvSdHbafCPmPcUnkUiSBs6IJUnqyCCWJKkjg1iSpI4MYkmSOjKIJUnqyCCWJKkjg1iSpI4MYkmSOjKIJUnqyCCWJKkjg1iSpI4MYkmSOjKIJUnqyCCWJKkjg1iSpI4MYkmSOjKIJUnqyCCWJKkjg1iSpI4MYkmSOjKIJUnqyCCWJKkjg1iSpI4MYkmSOjKIJUnqyCCWJKkjg1iSpI4MYkmSOjKIJUnqyCCWJKkjg1iSpI4MYkmSOjKIJUnqyCCWJKkjg1iSpI7W6d0APfMs/PU9zD76wt7NkPQMs/iYA3o34WnJGbEkSR0ZxJIkdWQQS5LUkUEsSVJHU35YK8kLp9peVXet3OZIkrRmme5T0/OBAjLJtgJevNJbJEnSGmTKIK6qbVZXQyRJWhONdY04g7ck+ev2fqskr1i1TZMk6dlv3A9rfRHYC/jz9v5e4AurpEWSJK1Bxr2z1iuravck1wBU1d1JnrsK2yVJ0hph3Bnxw0nWZviAFkk2AR5dZa2SJGkNMW4QnwCcC2ya5FPAPwOfXmWtkiRpDTHW0nRVnZFkPrAfw1eZDq6qRau0ZZIkrQFmckOP24G5o9u8oYckSU/NdEvT84F57fcdwE+Bf2mv50+1Y5KlSa4d+Zk9k4YlWZxk40nKD0py9EyONbLv7CSV5BMjZRsneTjJie393yRZkmTTkTr3TXydZK0kJyS5PsnCJD9Osk2SH7X+/jLJHaP9b336wYQ2XZvk+hn243tJ9hynTpJTk7xjwraDk1zUXn85ye0zbYMkaeWYMoirapuqejHwLeDAqtq4qn4XeANwzjTHvr+qdh35WbwyGlxV51fVMU/hEDcztH+ZNwM3TKhzJ/CBaY5zKLAZsHNV7QQcAvy2ql5ZVbsCHwfOmqT/z0+yJUCSlz2FfoxrLnDYhLLDWL66cSqw/2pohyRpEuN+WOs/VdVFy95U1cXA783kREk2THJpkqvbDPKNrfx5SS5Mcl2bXR46stt7Rupv3+ofNTJ73bodc0H7vVUrP7XNVq9IcnOSN40c835g0ciM8lDg7AnN/TJw6DT32p4F3FZVj7YxuaWq7h5jKM5u5wQ4nMcv96+X5JTW32uS7NvK109yZuvnWcD6I/v8YZIftnH6epINJ5zvu8D2SWa1+hsAc4DzWru/D3iJQZI6GTeI70zysba8unWSjwL/Os0+648sy54LPAAcUlW7A/sCxyUJw2zs1qrapap2BC4ZPW+rfxLwwUnOcSLwlaraGTiD4dPdy8wC9mGY/U6cQZ8JHJZkC2ApcOuE7fcxhPH7pujf2cCBrX/HJdltirqjvgH8SXt9IHDByLZ3AbQZ9uHAaUnWA/4SWNL6+SlgDxiW1YGPAXPaOM0D3j96sqpayrB68Wet6CDgsqq6d8z20s719iTzksxbuuSemewqSZrCuEF8OLAJw1eYzgM2bWVTGV2aPoTh09afTrKAYZa2OfAiYCEwJ8mxSV5TVaP/yi9b/p4PzJ7kHHsBX2uvv8oQvMucV1WPVtVP2nlGXQK8rvXhrBW0/wTgyCQvmGxjVd0CvBT4CMN3qi9Nst8KjjXqLuDuJIcBi4AlI9v2af2gqm4EfgFsB7wWOL2VLwAWtPqvAnYALk9yLXAksPUk5xxdnh5dlh5bVZ1cVXtW1Z5rb7DRTHeXJK3AuF9fugt4XwulR6vqvun2mcQRDGG+R1U9nGQxsF5V/TTJHsDrgc8k+XZV/W3b58H2e+mYba2R1w+OvH7c06Oq6qH2dawPAC9nmJkyoc5vk3wNeOcKT1b1IHAxcHGS3wAHA5eO0c6zGG4RetSE8smecvXY6SYpC/Cdqpruj6LLgVlJdgFezROvGUuSOhn3oQ87Zbi95ULghiTzk+w4w3NtBNzeQnhf2swtyWYMy66nA58Ddp/BMa9geagcwXCjkXEdB3y4qqZaYj8eeAeT/BGQZPfWdpKsBezMMIMdx7nAZxk+BDfq+wz9IMl2wFbATRPKd2znArgS2DvJS9q2Ddp+j1NVxbCUfhpwUVU9MGY7JUmr2LhL038HvL+qtq6qrRlmkifP8FxnAHsmmccQKje28p2Aq9rS6keBT87gmO8F3taWu9/K1Nd0H6eqbqiq06apcydDaK47yeZNgQva134WAI8wXLMe59z3VtWxVfXQhE1fBNZOspBh1nxUm3WfBGzY+vkh4Kp2nDsYZtVz27Yrge1XcNq5wC4M18cfk2Qu8EPgpUluSfJfxumDJGnlyDBZmqZScl1V7TJdmdYM687atmYd+fnezZD0DLP4mAN6N6GbJPOratL7P4z79KWbMzyL+Kvt/VuAn6+MxkmStCYbd2n6Lxg+aPVNhk8yb8wTP2gkSZJmaNwg/o/Alq3+cxge/vD9VdUoSZLWFOMuTZ/BcEON6/E5xJIkrTTjBvEdVXXB9NUkSdJMjBvE/zPJlxhuVvHYjTKqaroHP0iSpCmMG8RvY/h+6nNYvjRdTP8EJkmSNIVxg3iX9iACSZK0Eo37qekrk+ywSlsiSdIaaNwZ8T4MTyL6OcM14jDcwnjnqXeTJElTGTeI91+lrZAkaQ017mMQx32qkCRJmoFxZ8TSY3bafCPmrcE3b5eklWncD2tJkqRVwCCWJKkjg1iSpI4MYkmSOjKIJUnqyCCWJKkjg1iSpI4MYkmSOjKIJUnqyCCWJKkjg1iSpI4MYkmSOjKIJUnqyCCWJKkjg1iSpI4MYkmSOjKIJUnqyCCWJKkjg1iSpI4MYkmSOjKIJUnqyCCWJKkjg1iSpI4MYkmSOjKIJUnqyCCWJKkjg1iSpI4MYkmSOjKIJUnqyCCWJKkjg1iSpI4MYkmSOjKIJUnqyCCWJKkjg1iSpI7W6d0APfMs/PU9zD76wt7NkKSxLD7mgN5NmJIzYkmSOjKIJUnqyCCWJKkjg1iSpI4MYkmSOjKIJUnqyCCWJKkjg1iSpI4MYkmSOjKIJUnqyCCWJKkjg1iSpI4MYkmSOjKIJUnqaJUFcZKlSa4d+Zk9w/0XJ9l4kvKDkhz9JNs0O0kl+cRI2cZJHk5yYnv/N0mWJNl0pM59E18nWSvJCUmuT7IwyY+TbJPkR62/v0xyx2j/W59+MKFN1ya5fob9+F6SPcepk+TUJO+YsO3gJBe11/snuSnJz57suEqSnrxVOSO+v6p2HflZvDIOWlXnV9UxT+EQNwNvGHn/ZuCGCXXuBD4wzXEOBTYDdq6qnYBDgN9W1Suralfg48BZk/T/+Um2BEjysqfQj3HNBQ6bUHYYMDfJ2sAXgD8GdgAOT7LDamiTJKlZbUvTSTZMcmmSq9sM8o2t/HlJLkxyXZtdHjqy23tG6m/f6h81Mnvduh1zQfu9VSs/tc1Wr0hyc5I3jRzzfmDRyIzyUODsCc39MnBokhdO0aVZwG1V9ShAVd1SVXePMRRnt3MCHM4QlMvGaL0kp7T+XpNk31a+fpIzWz/PAtYf2ecPk/ywjdPXk2w44XzfBbZPMqvV3wCYA5wHvAL4WVXdXFUPAWcCbxyjD5KklWRVBvH6I8uy5wIPAIdU1e7AvsBxSQLsD9xaVbtU1Y7AJSPHuLPVPwn44CTnOBH4SlXtDJwBnDCybRawD8Psd+IM+kzgsCRbAEuBWydsv48hjN83Rf/OBg5s/TsuyW5T1B31DeBP2usDgQtGtr0LoM2wDwdOS7Ie8JfAktbPTwF7wLCsDnwMmNPGaR7w/tGTVdVS4Bzgz1rRQcBlVXUvsDnwq5Hqt7QySdJqsrqWpg8BAnw6yQKGWdrmwIuAhcCcJMcmeU1V3TNyjHPa7/nA7EnOsRfwtfb6qwzBu8x5VfVoVf2knWfUJcDrGMLurBW0/wTgyCQvmGxjVd0CvBT4CPAocGmS/VZwrFF3AXcnOQxYBCwZ2bZP6wdVdSPwC2A74LXA6a18AbCg1X8Vw5Ly5UmuBY4Etp7knKPL04exfBaeybo2WaOTvD3JvCTzli65Z7IqkqQnYZ3VeK4jgE2AParq4SSLgfWq6qdJ9gBeD3wmyber6m/bPg+230vHbOtoiDw48vpxgVNVDyWZz3Ad+OUMM1Mm1Pltkq8B71zhyaoeBC4GLk7yG+Bg4NIx2nkWw7XZoyaUTxaMj51ukrIA36mqw6c53+XArCS7AK9meSjfAmw5Um8Lnrg6MJy86mTgZIB1Z207aVhLkmZudX59aSPg9hbC+9Jmbkk2Y1h2PR34HLD7DI55BctD5Qjgn2ew73HAh6vqX6eoczzwDib5IyDJ7q3tJFkL2JlhBjuOc4HPAt+aUP59hn6QZDtgK+CmCeU7tnMBXAnsneQlbdsGbb/HqapiWEo/Dbioqh5om34MbNs+7f1chrE8f8w+SJJWgtUZxGcAeyaZxxAqN7bynYCr2tLqR4FPzuCY7wXe1pa738rU13Qfp6puqKrTpqlzJ0NorjvJ5k2BC9pXjxYAjzBcsx7n3PdW1bHtA1KjvgisnWQhw6z5qDbrPgnYsPXzQ8BV7Th3MMyq57ZtVwLbr+C0c4FdGK6PL2vHI8C7Gf4gWAScXVUTP0EuSVqFMkyWpPGtO2vbmnXk53s3Q5LGsviYA3o3gSTzq2rS+z94Zy1JkjoyiCVJ6sggliSpI4NYkqSODGJJkjoyiCVJ6sggliSpI4NYkqSODGJJkjoyiCVJ6sggliSpI4NYkqSODGJJkjp6wnN2penstPlGzHsaPM1Ekp4NnBFLktSRQSxJUkcGsSRJHRnEkiR1ZBBLktSRQSxJUkcGsSRJHRnEkiR1ZBBLktSRQSxJUkcGsSRJHRnEkiR1ZBBLktSRQSxJUkcGsSRJHRnEkiR1ZBBLktRRqqp3G/QMk+Re4Kbe7Xga2xi4s3cjnsYcn6k5PtN7Jo7R1lW1yWQb1lndLdGzwk1VtWfvRjxdJZnn+KyY4zM1x2d6z7YxcmlakqSODGJJkjoyiPVknNy7AU9zjs/UHJ+pOT7Te1aNkR/WkiSpI2fEkiR1ZBBLktSRQayxJdk/yU1Jfpbk6N7t6S3JlkkuS7IoyQ1J3tfKX5jkO0n+pf3+nd5t7SnJ2kmuSfKP7b3jMyLJf0jyjSQ3tv+W9nKMlkvy39v/X9cnmZtkvWfb+BjEGkuStYEvAH8M7AAcnmSHvq3q7hHgA1X1MuBVwLvamBwNXFpV2wKXtvdrsvcBi0beOz6P97+BS6pqe2AXhrFyjIAkmwPvBfasqh2BtYHDeJaNj0Gscb0C+FlV3VxVDwFnAm/s3Kauquq2qrq6vb6X4R/QzRnG5bRW7TTg4C4NfBpIsgVwAPClkWLHp0nyAuC1wD8AVNVDVfVbHKNR6wDrJ1kH2AC4lWfZ+BjEGtfmwK9G3t/SygQkmQ3sBvwIeFFV3QZDWAObdmxab58HPgQ8OlLm+Cz3YuAO4JS2fP+lJM/DMQKgqn4NfA74JXAbcE9VfZtn2fgYxBpXJinzu29Akg2BbwJ/VVX/1rs9TxdJ3gDcXlXze7flaWwdYHfgpKraDfh3nuHLrCtTu/b7RmAbYDPgeUne0rdVK59BrHHdAmw58n4LhiWiNVqS5zCE8BlVdU4r/k2SWW37LOD2Xu3rbG/goCSLGS5l/EGS03F8Rt0C3FJVP2rvv8EQzI7RYA7w86q6o6oeBs4BXs2zbHwMYo3rx8C2SbZJ8lyGD0yc37lNXSUJw7W9RVV1/Mim84Ej2+sjgf+7utv2dFBVH6mqLapqNsN/L/9UVW/B8XlMVf0/4FdJXtqK9gN+gmO0zC+BVyXZoP3/th/DZzGeVePjnbU0tiSvZ7jmtzbw5ar6VN8W9ZVkH+AHwEKWXwP9HwzXic8GtmL4h+TNVXVXl0Y+TST5feCDVfWGJL+L4/OYJLsyfJjtucDNwNsYJkmOEZDkfwGHMnxL4RrgvwIb8iwaH4NYkqSOXJqWJKkjg1iSpI4MYkmSOjKIJUnqyCCWJKkjg1iSRrQnIb04ybpJLmlP/XnnyPaTk+w28v7dSd7Wp7V6NjCIJT3jtAcArIrjvhxYu6puBv4ImA/sDLy9bd8FWKuqrhnZ7csMTwiSnhSDWNJKk+S8JPPb82PfPlK+f5Krk1yX5NJWtmGSU5IsTLIgyZ+28vtG9ntTklPb61OTHJ/kMuDYJK9IckV7WMIVy+5O1Z5//LmR474nyX5Jzh057uuSLLsl6agjWH6XpoeB9RnuB73MJ4CPj+5QVUuAxUle8WTHTWu2VfJXpaQ11l9U1V1J1gd+nOSbDH/w/z3w2qr6eZIXtrp/zfA0nZ3gsRv8T2c7YE5VLV32CMGqeiTJHODTwJ8yzF63AXZr214I3A18IckmVXUHw92rTpnk+HsDc9vr7wBvZbhT2meTHATMr6rJ7rE+D3gNcNUYfZAexyCWtDK9N8kh7fWWwLbAJsD3q+rnACO3IpzDcA9qWvndYxz/61W1tL3eCDgtybYMTwJ7zshx/09VPTJ6viRfBd6S5BRgL+A/T3L8WQyPJaTt/+dt3+cA32J4iMXxDLdW/EpVLbvf+u3A9mO0X3oCg1jSStHuJz0H2KuqliT5HrAewyM0J7uX7orKR8vWm7Dt30defwK4rKoOac+D/t40xz0FuAB4gCHQH5mkzv2TnBPgnQwPoN8LeIjh3sc/ZPmDT9Zr+0oz5jViSSvLRsDdLYS3B17Vyn8I/F6SbQBGlqa/Dbx72c4jS9O/SfKyJGsBy2bXKzrfr9vro0bKvw38t2Uf6Fp2vrakfCvwMeDUFRxzEfCS0YLWrjcAXwE2YHjAR/H4wN4OuH6KtkorZBBLWlkuAdZJsoBhtnolQLsm+3bgnCTXAWe1+p8Efqd9Peg6YN9WfjTwj8A/AbdNcb7PAp9JcjnDE8GW+RLDE3kWtOP++ci2M4BfVdVPVnDMC4Hfn1D2ceCTNTwh51vAngxP3Pr7kTp7A9+doq3SCvn0JUlrjCQnAtdU1T+sYPv6wGXA3iPXoqc75m7A+6vqrSuvpVqTGMSS1ghJ5jNcY35dVT04Rb0/AhZV1S/HPO7rgH+pqsUrpaFa4xjEkiR15DViSZI6MoglSerIIJYkqSODWJKkjgxiSZI6+v8akQOoR3MTUQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize our model results\n",
        "compare_results.set_index(\"model_name\")[\"model_acc\"].plot(kind=\"barh\")\n",
        "plt.xlabel(\"accuracy (%)\")\n",
        "plt.ylabel(\"model\");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ba50d51-adb3-4e49-9b9a-85173e747352",
      "metadata": {
        "id": "0ba50d51-adb3-4e49-9b9a-85173e747352"
      },
      "source": [
        "## 9. Make and evaluate random predictions with best model\n",
        "\n",
        "Alright, we've compared our models to each other, let's further evaluate our best performing model, `model_2`.\n",
        "\n",
        "To do so, let's create a function `make_predictions()` where we can pass the model and some data for it to predict on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1d5d3e7-9601-4141-8bd7-9abbd016bf6c",
      "metadata": {
        "id": "d1d5d3e7-9601-4141-8bd7-9abbd016bf6c"
      },
      "outputs": [],
      "source": [
        "def make_predictions(model: torch.nn.Module, data: list, device: torch.device = device):\n",
        "    pred_probs = []\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for sample in data:\n",
        "            # Prepare sample\n",
        "            sample = torch.unsqueeze(sample, dim=0).to(device) # Add an extra dimension and send sample to device\n",
        "\n",
        "            # Forward pass (model outputs raw logit)\n",
        "            pred_logit = model(sample)\n",
        "\n",
        "            # Get prediction probability (logit -> prediction probability)\n",
        "            pred_prob = torch.softmax(pred_logit.squeeze(), dim=0)\n",
        "\n",
        "            # Get pred_prob off GPU for further calculations\n",
        "            pred_probs.append(pred_prob.cpu())\n",
        "\n",
        "    # Stack the pred_probs to turn list into a tensor\n",
        "    return torch.stack(pred_probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "420c7461-eaa9-4459-9e68-53574c758765",
      "metadata": {
        "id": "420c7461-eaa9-4459-9e68-53574c758765",
        "outputId": "9444bd91-f130-4867-e4db-083820567347"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test sample image shape: torch.Size([1, 28, 28])\n",
            "Test sample label: 5 (Sandal)\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "test_samples = []\n",
        "test_labels = []\n",
        "for sample, label in random.sample(list(test_data), k=9):\n",
        "    test_samples.append(sample)\n",
        "    test_labels.append(label)\n",
        "\n",
        "# View the first test sample shape and label\n",
        "print(f\"Test sample image shape: {test_samples[0].shape}\\nTest sample label: {test_labels[0]} ({class_names[test_labels[0]]})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9f40dd9-7987-42a9-84cc-65dc912a6345",
      "metadata": {
        "id": "e9f40dd9-7987-42a9-84cc-65dc912a6345"
      },
      "source": [
        "And now we can use our `make_predictions()` function to predict on `test_samples`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79de2ac1-7d4b-4f81-ae8a-90099bca2a3d",
      "metadata": {
        "id": "79de2ac1-7d4b-4f81-ae8a-90099bca2a3d",
        "outputId": "b0f7cb3c-7a7c-41b6-8040-7ca6e9ba9661"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2.3550e-07, 1.7185e-08, 4.6618e-07, 6.1371e-08, 5.1185e-08, 9.9957e-01,\n",
              "         3.7702e-07, 1.5924e-05, 3.7681e-05, 3.7831e-04],\n",
              "        [7.3275e-02, 6.7410e-01, 3.7231e-03, 8.8129e-02, 1.0114e-01, 6.9186e-05,\n",
              "         5.8674e-02, 4.2595e-04, 3.8635e-04, 7.1354e-05]])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make predictions on test samples with model 2\n",
        "pred_probs= make_predictions(model=model_2,\n",
        "                             data=test_samples)\n",
        "\n",
        "# View first two prediction probabilities list\n",
        "pred_probs[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22d3c080-4eb6-4b5d-a5c4-2319e78228af",
      "metadata": {
        "id": "22d3c080-4eb6-4b5d-a5c4-2319e78228af"
      },
      "source": [
        "Excellent!\n",
        "\n",
        "And now we can go from prediction probabilities to prediction labels by taking the `torch.argmax()` of the output of the `torch.softmax()` activation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9d97bcc-4310-4851-a1f8-6bcd757e9b26",
      "metadata": {
        "id": "f9d97bcc-4310-4851-a1f8-6bcd757e9b26",
        "outputId": "59430183-ea19-456e-9a0e-17d25b1f4b9d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([5, 1, 7, 4, 3, 0, 4, 7, 1])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Turn the prediction probabilities into prediction labels by taking the argmax()\n",
        "pred_classes = pred_probs.argmax(dim=1)\n",
        "pred_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1141af97-0990-4920-83d4-c13cca3f9abc",
      "metadata": {
        "id": "1141af97-0990-4920-83d4-c13cca3f9abc",
        "outputId": "28a0b16b-9492-4ab8-ecd0-c26c823ced6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([5, 1, 7, 4, 3, 0, 4, 7, 1], tensor([5, 1, 7, 4, 3, 0, 4, 7, 1]))"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Are our predictions in the same form as our test labels?\n",
        "test_labels, pred_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ea04387-c9ad-424f-8297-defd7b685683",
      "metadata": {
        "id": "4ea04387-c9ad-424f-8297-defd7b685683"
      },
      "source": [
        "Now our predicted classes are in the same format as our test labels, we can compare.\n",
        "\n",
        "Since we're dealing with image data, let's stay true to the data explorer's motto.\n",
        "\n",
        "\"Visualize, visualize, visualize!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "679cb5f7-bb66-42dd-a4d6-400b27b7c019",
      "metadata": {
        "id": "679cb5f7-bb66-42dd-a4d6-400b27b7c019",
        "outputId": "33ef8db9-8fb5-4b93-e112-1e5b4c92bef6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg4AAAIFCAYAAAC6fHX6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABca0lEQVR4nO3dd5xV1b3///dS6UMRQZoiYKWodDWxxx71atTYI9ZoitdfLDGxbLbeXEtMTLMkGjXJtcXE3ojfiBFFxUJRrIjYQJoUKSKS9ftj7wnHWZ89rDNzZpiB1/PxyCPymbPL2WftfdZZ533Wdt57AQAAxNhgbe8AAABoPug4AACAaHQcAABANDoOAAAgGh0HAAAQjY4DAACIRscBAABE26icB7vUrZL0ar7cG5JO8olfVpcNu9TdJulhn/i/1fKYbpL+KGlzSS0kzfCJP6gu26ux3j75tgfV5TEudTN84vvUqF0n6euSWkrqK+mt/E//U9tzLFl+lKR/+MTPrN6GpOE+8fPW/Iz+s46LJB0naZWkf0v6rk/8C7HL17LepySd5xP/Un0eszY1Ztt1qTtZ0n/n/xygrC2skvS4T/yFddlmpeWv1yif+BkltYskHZX/c3tlx0uSbvGJ/03EOg+T9LZP/Osl24huEy51L0hqJamzpDaSPs7/dFjpfq4v1pXrbbn7Uca6Rivbx9tKavtLuir/51bK2tBySVN84r8Tsc7Bknr6xD9aso0lPvHXlLFfO0v6tbK23ErS3T7xo2OXj9zGDJX5/lBJZXUcJC33iR8sSS51t0s6U9Ivq//oUrehT/yqyu2eLpP0hE/8r/P171DBdVeUT/z3pa90OAaX/j3i2IyS9JqkmXXZvkvdLpIOljTUJ36FS10XZZ0YZBqt7frE3yrp1ny9MyTtVfMEb4BzpZBL3UY+8V+u6XE+8T+T9LN8mSVGG3aSnE/8vwtWcZikhyW9Xpf99InfKd/OKGUXxR/U2H7U86iUxnyNCnC9zUW0PUmST/wYSWPyZZ6S0XFdw3EbLGm4pEfrsbt/kvRtn/jJLnUbStq2HuuqqEqdQ+V2HEqNk7SDS92ekhJJsyQNdqnbXtKVkvZU1tu6zif+9/kL/1tJe0t6T5KL2EYPSf+o/odP/BRJcqmrkvSApI2V9Ywv9ol/IH/TfkzSM5K+pqy3+V8+8ctd6oZJukXSsvzvytfVR9JfJLXLSz/wiR9f3qGwGcfmIJWMYrjUnSepSlmHYbik213qlkvaJV/FD13qDsmf41E+8W/Wsrkekub5xK+QpNI3Kpe6SyUdouxT3HhlIxE+P7FekLSXpE6STvWJH+dS10bZG98AZZ902pSs6wZJI/La33zikzodnLWrMdpuwKVuibIL//6SznWpGynplPzPN/vE/6rmSFd1G/GJH+1Sd7ayN48vJb3uE3+MS127fN+2V3Y+j87PhVGSvimptbK2vXcd97mPsnNqrLJ2eZhL3VSf+Kr870cq67D+QdKhkvZwqbtY0hH5Ko5yqbteJe2rzO2PltRTUh9J81zqfqLsPO4qaa6kk33iP6j5STbv+FS51PWQdLekDsqOz1l5G99PUqrsdX43X8+SvKN3i6T9JP1O0l3l7G8DWpvX2z0ljZY0T9IgSS9LOiG/hgxT1qar8r+P8omf5VJ3uqQzlH14mSbpxJqjJS51lysb3ThF0rmSvp0/h/t84hOr7Ul6P+J5BGq+ri51ZyrvVOQfsl6StI2yzlMbl7pdJV2RLz4gv1b2lvSriNG3TZW9Pso7KNUjcKPzdfSruS6XuhMkna3seL0g6Xs+8avWdL3Nr9X3Sfq7pDvUgNeCUnXKOLjUbSTpQK0eyhwp6SKf+AGSTpW0yCd+hLInfLpLXV9JhyvreW0v6XRlb+zV67vMpe5QY1PXSfqjS91Yl7qLXOp65vXPJR3uEz9U2ZveL/ITRZK2VnbyDJS0UKsvYLdKOtsnfhd91RxJ++brOlrSGodky1R6bEz5xe4lScf7xA/2iV+e/2levl83SDpPklzqhrvU3Wys5h+SNnepe9ul7nqXuj1K/vY7n/gR+ZtRG2UX+mob+cSPlHSOsguSJJ0laZlP/A7KPoEOK3n8RT7xwyXtoOxNosl8KonRiG3X0k7Sa/kn6+WSTpa0k6Sd820NWcPyF0oakr8uZ+a1iyQ9me/zXpJ+nncmpOxie5JPfH0vFNtK+rNP/BCfePPCnXe2H5R0ft6G383/FLQvl7qeLnXlfKIbpuwDwHHK3sz/nB+D27Xm8/U4SWPyT+47SpqUv1FcLGmf/Px6SdKPSpb53Cd+V5/4JtFpaALXW0kaouw1HKDsje/rLnUtlL1RHekTX/3B7Gf54+/Nrzk7KvvwcWqN53S1sjfYkyXto+y6PVLZJ/5hLnW75w9dY9srQ62vq0/8F5IuVfbVwmCf+LvzP22nrLM/UlKSP2+51D1a4xhVu1bSWy5197nUfdelrnXJ34J1udT1V/be8/W8na6SdHz++Nqut1WSHpJ0h0/8TWqca4Gk8kcc2rjUTcr/e5yy78O+JmmCT/x7eX0/ZT3jI/N/d1TWKHaXdGfeA5vpUvdk9Up94i+1NuYTP8alrp+kA5SdOBNd6gYp6xD8b964/i2pl6Ru+WLv+cRX7+PLkvq41HWU1Mkn/l95/S/5+qTs0/zvXPbd1iplvc5KKj025bo3//+XJX1LkvJht9NqPjD/tDRM0m7KGs3dLnUX+uz7v71c6i6Q1FbZ98dTlTW4mtvok//37sovyD7xU1zqppRs6tsudWcoazs9lF1ISv/eVDVq2y2wStknA0naVdknq6WS5FJ3r7LX7sFalp+ibFTqfkn3l+zzofnIhJR9quid//cTPvGflrF/Rd73iX++jssG7ctnOZ5yvjt/sKQzvYvyc0HZeXz1GpZ9UdIt+cX+fp/4SXmneoCkZ13qpOxT3nMly9wdrmataCrXW+Xb/EiS8n3qo+w6PEjSE/lx3FD5J21Jg1zq/kfZSFOV8q8PcpdIesEn/ox8ffvlz2Ni/veq/Dl8oPq1vZrq+ro+ko/krnCpm6PsveYjX5D/8Im/zGVfLe2nrON6rLIRoaJ1fUNZ5/jF/Di2UfaBVqr9evuApKt94m/P/90Y1wJJ9cg4VMuf6NLSkqQf5t81lT7uIEll31Erf7J3SLrDpe5hZSdEe2VDlcN84lfmw1DVvboVJYuvUvYiuFq2/f9Jmq3s08gGykYzKqn02Hypr47ytFbtqp/LKkW8VvlF4ilJT7nUvSrpJJe6uyRdr+w74w/z4bLS7RZtIzhe+SeZ8ySN8IlfkA8Pr+k5NBWN3nYNn/vV360WDR3X1ka+qaz9HyrpEpe6gfl6jvCJf6vkcXKp20lffW71UXM9pceiom04cvvWvvznuOWjjy0lySf+6fwDxjcl/cWl7ueSFii7kB5bh+01pqZyvZ2v8Lq6Ub7tqcYoriTdpizUOjkfKt+z5G8vKhtV6Jxvz0m6wif+9zWeQx9V9rUouhbHtmEp/lr8rqQbXOpukjTXpW6TWtblJP3JJ/4npeuIuN4+K+lAl7o7fOK9GudaIKlhfo45RtJZJcM52+TDJU9LOsalbkOXfe+415pW5FK3t0td2/y/20vaUlkvtKOkOXmnYS9JW9S2Hp/4hZIW5d9bSauHgZSva5bPQjcnKus1N5TZkjZ1qdvEpa6VvvqVwWfKOkR14lK3rUvd1iWlwcq+D6xuaPNclg05suayhqeVH6P8E0f18FgHZQ1wkcsS2AfaizdbFWu7EZ5Wlhdom2/jcGWfKs024lK3gaTNfeLHSrpAX/0k98Pqr+oivu6ohNkudf3zfTq8pF6vNhxpvKRj8v8+XqvzSjO0+iu1/1I2kiiXui2UXStuUvaJfaik55UNtW+VP6atS12lRxobS2Ncb4u8Jamry4LZyofdB+Z/ay9pVr5fx9dY7nFluYxH8u2MkXRKfn2SS10vl7pNY558PczQ6vZSek2sdxt2qfum++pX56uUjc4U+aekI6ufs0td57zdrul6e6myTt31+b8b7VrQEB2Hm5WFQV5xqXtN0u+V9aruk/SOsu/pbpBU/bVBbd+5DZP0Uj5U/pyyANmLyr7bHO5S95KyRllbaLDayZKuc6l7Ttn3y9WuV/bJ/HllX1M02KcNn/iVysI3LyhLn5fu922SbnSpm+SywIvJFWccqiT9yaXu9fx4DVAWjlko6SZlx/1+Zb39NblBUlW+ngskTcj3f7Ky4cSpyr7PfDZiXc1JJdturXziX1H2mk9Q1h5u9omfWEsb2VDS/+UjSRMlXZu/tpcre5Ocku/z5eXuSx1cmO/bk1o9NC1lQcLzXeomutRtWbSwKz/jUOpsSSfnbfNErf7Z603KvgOeoCw3Un0e76ks1zBRWd7p1z7xc5X9iunOfD3PK/vuuTlqjOutKc8EHCnpKpe6yZImaXWW4hJlbfgJGddnn/h7lL1mDyrrMN8h6bm8ff9NDd8BvUZZh2u8pC4l9bHKwpCTXOqOrm0FrjjjcKKyjMMkZV+nHe9r+fWLz36+fLGkf+TH/glJPSKvt+dIau2yzEijXQuc95UYgV2/OGMeB6A5ccY8DkBz4ox5HNA4mDkSAABEq888DuuzX63tHQDq6TbV/r0r0NQ9JdrwWsFXFQAAIBpfVQAAgGi1flXhnGM4AnXmva/T1MyV1FzbsHPhoSsaHayqqgpqBx0Uzk0ze/bsoLZqVRj23mCD8PPEv/8d3iJgww3tXy5b6+zWrVtQe/rpp4Pa3LlzzXWuLU2hDUvNtx2jaah0O2bEAQAARKPjAAAAotFxAAAA0fg5JtAEWTkDKzsgSZtuGs7Ou8ceewS1994L77Vm5SasPIP1uKLMxfLly4OatY9W5qKpZRwAhBhxAAAA0eg4AACAaHQcAABANDoOAAAgGuFIoAkqCkJapk+fHtSeeOKJoPbJJ58EtVatWgU1a/Ipq9axY0dzf6zHrly5MqhZIUwATR8jDgAAIBodBwAAEI2OAwAAiEbHAQAARCMcCaxlgwYNCmoXXHBBUPvwww/N5Xv06BHUunfvHtTmz58f1Fq3bh3UrLteWoHHW2+91dwfixWEbNeuXfTyAJoORhwAAEA0Og4AACAaHQcAABCNjgMAAIhGxwEAAETjVxXAWvatb30rqB155JFBbdGiRdHrrKqqCmrLli0LatYvKBYvXhzU+vbtG9Tuvfdec9uzZs0Kau3btw9qG23E5QdojhhxAAAA0eg4AACAaHQcAABANDoOAAAgGumkSNaUu1bNmlq3HBtsEPblWrZsGdQ+//zzem2npt13392sP/300xXdDkKdO3cOatb00AsXLoxe54IFC4LaqlWrgpr3Pqpmbbtbt27mtq2psa1t1/dcAbB2MOIAAACi0XEAAADR6DgAAIBodBwAAEA0wpEGK/QYGyKzZsOzgmFFs+atXLkyqNUnCHnggQcGtdNPPz2ojRgxwlz+1FNPDWr/+Mc/glqLFi3qsHeQpB49ekQ9rihM2LZt26C2fPnyoGa1OautW8ta27Zmg5Ts9mptp9IBX6ChtWrVKqitWLEialnrHKgva+bXL7/8suLbqYkRBwAAEI2OAwAAiEbHAQAARKPjAAAAoq2T4Uhr9sWiYJkVGIsNl3To0CGoWbcktlghSMkOnFm3NLb2++67745anzULoDXToCT94he/CGq77LJLUFuyZIm5PNYstr1aIVvJbktWYPKLL76I2h8rtGjNXmoFxcqxdOnSei0PlKuc9wbLQw89FNRuueWWoHbXXXcFNStMX1+NEYS0MOIAAACi0XEAAADR6DgAAIBodBwAAEC0dTIcaYVdimZqjA2XXHXVVUHtkEMOCWrHHntsUJs8eXJQO/nkk83tnHbaaUHNmtXx17/+dVCzQo/Tpk0LatZMhUWzAD766KNBjSBkZVmhKatdFoWrrNBj69atg5o1y5x1rrRp0yaoWcFMa4bJonVa2162bJm5PFCu2FkZywlCPvDAA0Fthx12CGrnnHNOUJswYUJQW7RoUVBr165dUBs4cKC5P4cddlhQs57PWWedZS5fSYw4AACAaHQcAABANDoOAAAgGh0HAAAQbZ0MR1rKmWHr7LPPDmojR44Mam+88UZQe+6554LatddeG9TOP/98c9vW8lZAcfPNNw9qr7/+elAbOnRoULNmTzv00EPN/Zk6dapZR+VYIUErzPvpp5+ay/fq1SuoWbM6WoHJ+fPnR+2PNctj7EyUkh3s/Oyzz6KXB2pTn1kZi5a9/vrrg9qsWbOC2j777BPUnn322aBmzfBqzdJa9F5lndP333+/+diGxogDAACIRscBAABEo+MAAACi0XEAAADR1slwZDm3Tj388MOD2nHHHRfUZsyYEdS6du0a1N55552g9p3vfCeoXX755eb+nH766UHtgw8+CGpWONJ63B133BHUrrjiCnPbWDtmzpwZ1KwglNWuJXvWzzFjxgS1XXfdNahZt8u2Znm0ZuYruoW8tZ/WOq2ZToFK2WqrrYKaFT63boEt2e27f//+Qc1q2/PmzQtq1uyrK1asiKoVLd+xY0fzsQ2NEQcAABCNjgMAAIhGxwEAAESj4wAAAKLRcQAAANGa/a8qrFS4NRWulbCV7OmgX3zxxaDWu3fvqP156623opb9xje+YS5/9913BzVryumxY8dG7Q+aPmsaW+tXFVZbL6pPnz49qG299dZBrU+fPkEtNhFuTU0t2Slz61dNRctj3Wb9QkeKnzbaal+vvPJKUGvRokVQs9r2//t//8/czje/+c2gduCBBwY169dsFmu/rVqbNm3M5a0pqzfeeOOobVcaIw4AACAaHQcAABCNjgMAAIhGxwEAAERrEuFIKyBiTVtrBbSsIKRl2rRpZv3GG28MameccUZQW7RoUVDr3r17UPvwww+DmnXP9SFDhpj787WvfS2odenSJajFhiMHDx4c1Pr27RvUrOmIJWngwIFBrV+/fkHNOmaIY7XNjTYKT80vv/zSXN4KlS1dujSoLVmyJKhZ517s1LjLly8398cKpVnrtGpoHqzrs9UOY2tFDjnkkKBmTaNvnUPWlNH33ntvUDvvvPPMbVvBQ+v6bj0fK8hovQ9Y50rR7RGs83fTTTc1H9vQGHEAAADR6DgAAIBodBwAAEA0Og4AACBao4cjrVnD6hOcateuXVCzgmFFrrzyyqBmhWIuuOCCoPbuu+8GtYMPPjioWcHKd955x9wfKwB3wgknBLW99947qFlBmdatWwc1K1BqzTRYtD9WoMcKXCKO1Y6s0GLbtm3N5a0g5cKFC4Pa7Nmzg5o166S1bStoZgUmJXvWSysshvqxrqXWa1c0U6MVwrOCftY66/N6WqFyyQ6qW9cVa5bI999/P6i9/PLLQW3AgAFBrej9wjoW1vuSdY203pc6duwY1KxZJ63zWbJfh5122imo7bfffubylcSIAwAAiEbHAQAARKPjAAAAotFxAAAA0WoNR8bO6GgpZ5Y7KzSy7777BjUrKDNq1Kig9uyzzwa1cmY2/PGPfxzUrFnyLrnkkqA2ceLEoGaFXYqCblaw7KWXXopafv78+UHNCv6UM2OfFYTs2bNnULNmVEMcKxxpnT9FM8pZdWuWus8++yyoWcE56xy32n/ROR47qyDqxzqmRa9JfRS1u5qsUJ51fT722GPN5Z977rmgNnPmzKBmXQ+7desW1E488cSgtuWWWwa1BQsWmPvz6aefBjXr+mwFIV999dWg9vrrrwe1I444IqhZgXZJ6tSpU1Czrs/HHHOMuXwlMeIAAACi0XEAAADR6DgAAIBodBwAAEC0WsORjXUrXGv2RivU99577wW1J598Mqj94Ac/CGr1ve3z6NGjg5o1w+TJJ58c1N54442gVjTz2ieffBLUrPCNNWufFXSzwjyxAVdJWrZsWVCzZhtkZsC6s84pK7BlhZWl+HCk9RpZ7chq1+PHjw9qVthSktq3b2/W0fCsa0VR2M6a0dYKV1ZVVQW1G264IahZM9yOHTs2qF199dXm/ljbtmr9+vULalaY3prtdNasWUHNmklXso+ldY21aptssklQ23nnnYPatttuG9SKrqXWtdg6z0eMGGEuX0mMOAAAgGh0HAAAQDQ6DgAAIBodBwAAEK3WcORmm20W1Kxgyttvvx3UrFv4SvZsZ1tttVVtu/Efu+22W1CLDWL17t3brFu3NbVYAc5TTjklqE2aNCmoWeG3Xr16mdsZNmxYULOO5dy5c4OaFZSxAnXW/pQzs1/s7WZRd9Ztsa1Z4iQ7xGW1DysEZrUPaztWMLlolkIrkNsQMxqu7/70pz8FNeuW1UW3jbZe+y222CKoWTMWWrM8/uhHPwpqVlsout537do1qFmzBXfo0CGoWbPmWqFh6zlb+1i0vFWzZlUdOnRoULPeq6zzvJxZl61gZmNcixlxAAAA0eg4AACAaHQcAABANDoOAAAgWq3hyG9961tB7dRTTw1q1sxkRaHDhx9+OKhZQcH+/fsHtY8++iioWWEXaxvWrF2SdPHFFwe1otu+1vTaa68FNWuWtcGDBwe16dOnm+s8/vjjg9q//vWvoGaFk6xZAK2gjRWoqa/YW+8ijjWrn3X7ecl+ja3bEVusW77HzlBXFOKy1mktj3iHH354ULOum1bYrm3btuY6rbCdNbPiyy+/HNSsoO12220X1KzAo1WT7PCgNUtt0YylMeobHIwNTFqB1Nhb2BfN9Gnte6WPTyxGHAAAQDQ6DgAAIBodBwAAEI2OAwAAiEbHAQAARKv1VxXW9MlW4tqqbbrppuY6//u//zuoffrpp0Ft4sSJQS02lWr9IuPGG28098da3ppC20qFW1OxWonYgw8+OKg98sgj5v7E6tKlS1CzfslipW4tRVNOW3WrxpTClWUdz6JEuJXqttL11i81rPZvsX4pUc6vKmgf9bNgwYKgZl1/rDS/NSWyZL9OVnvYfPPNg1qbNm2CmvUad+7cOahtvPHG5v5Y11jr+mXVrOdinRfWtaucX4RZy1u/MFm5cmVQs85f61eBRWLPc+v9a9ddd43eTgxGHAAAQDQ6DgAAIBodBwAAEI2OAwAAiFZrONIKxVhTKi9ZsiSoFQVyrLoVbLGmT7bum249ztrG+++/b+6PFWaMDfn885//DGpnn322uZ36sJ63FbSxjqMVKLWOmbWsZIelrOND+K2yrPBZESs0ZQUhralorXZkrc8KpFnnvWSfU0XXA8R56qmngtpLL70U1KxgeIcOHcx1xl63reuFFWi3rhVWSNCa1lqyr0FWu4udWr8o8F1TUejYCi7GBn9jw82x559kH8sWLVoEtYa4pUBNjDgAAIBodBwAAEA0Og4AACAaHQcAABCt1nDkmDFjgtqFF14Y1Hr06BHU5s6da67TChlaIR0rFGMFTqxAjhUOsbYr2UEU67HdunULarGzcVkBlqIwoRXoscJA1syaVnDVmtXMmtXTCjtJdiDnww8/DGqxMxAijjUDYFFg0mrvVuhq3rx5Qc06T61zL3Z2PElq27ZtULNmBUT9nHnmmVGPO/roo836qaeeGtQGDRoU1Kx2Z12zFy9eHNSsgKH1OMm+TlohXyt8a9Viw41Fszda50F9gofW+qxtF4U1rfcGKzj/4IMP1mHvysPVHgAARKPjAAAAotFxAAAA0eg4AACAaLWGI60w1fbbbx+14mOOOcasDx8+PKjtv//+Qc2awWzEiBFBzQp3WWEe6/ajRfWf/exnQc26DbYV3LECPlaIrGimRis0aYVqdt9996B2zz33BLWjjjoqqD300ENB7aCDDjL354033ghqVoCqXbt25vKoG+vcK7pVfWxgywrAWuFgK7BlzTpZFPC1liccufbcfffdZdVr2nnnnYOaNUNl7969g5o1a2VRyNcK1cbOHGmFNa3HWaHjorZphThjg8hWWNzatrWPRTNexs4G+8wzzwS1008/3VxnXTHiAAAAotFxAAAA0eg4AACAaHQcAABAtFrDkVbAo+iWnzXddddd0fXzzjsvap3WDJULFiwIaj179gxq06dPj9pGfRXNpldT7C1fJXvWvr322iuoWbfeHTZsWFB7+eWXg9qWW25pbrt9+/ZBzQqUzpgxw1wedfPmm28GNStYLBXPfFfTsmXL6rw/H3/8cVArmuHOYoXA0Dw8//zzUTWsPxhxAAAA0eg4AACAaHQcAABANDoOAAAgWq3hSCsIac2cZdViQ5TlmDVrVtTj6huEtEKhVq1o5ryaYmcbK4cVhLRYQUjLu+++W4+9QaVZs7+dcMIJ5mNff/31qHVaIVuL1dbfeuutoFY0++kWW2wR1JhZFFh3MOIAAACi0XEAAADR6DgAAIBodBwAAEC0WsORFmvGw3JmQWwOrGBnfcKe69rxQcOzZo4saoOx7WvChAlBzbqlsHVreOuW3J988om5nVtuuSWovf322zG7CKAZYMQBAABEo+MAAACi0XEAAADR6DgAAIBodBwAAEC0sn9VAaDhffTRR0Ft6dKl5mPr84ufZcuWBbWqqqqgFjtdtSRNmTKlzvsDoOljxAEAAESj4wAAAKLRcQAAANHoOAAAgGiEI4FmYuXKlWa9Q4cOdV6nFaxs3759UFu+fHn0OjfaKLysfPnll+XtGIAmixEHAAAQjY4DAACIRscBAABEo+MAAACiEY4EmolHH33UrPft27fO67zrrruC2nbbbRfUyglHrlq1qs77A6DpY8QBAABEo+MAAACi0XEAAADR6DgAAIBoznu/tvcBAAA0E4w4AACAaHQcAABANDoOAAAgGh0HAAAQjY4DAACIRscBAABEo+MAAACi0XEAAADR6DgAAIBodBwAAEA0Og4AACAaHQcAABCNjgMAAIhGxwEAAESj4wAAAKJt1FArdqlbJenVfBtvSDrJJ35ZHdd1m6SHfeL/tobHHSjpckntJLl8mfPqsL09JX3hEz/e+FsfSbf5xO9Zo/6CpFaSOktqI+nj/E+H+cTPiNjmT33i/7dkGw/7xA8qc79HSrpGUjdJXtIzks4u97i71A2W1NMn/tFylmvOGru9utSNkvRzSR9JqpI0XVJqtbmG4FL3lKRRpW3Tpe4iSUfl/9xe2fGQpFt84n8Tsc7DJL3tE/96yTbO84l/qYz9miHps/yfG0q6V9LlPvErYtfR1DVmW3OpO1nSf+f/HCDpLUmrJD3uE3/hGtY9WtISn/hrjL+N94n/mlHvJOk4n/jra9Qfl3Sqsvb1h7o+3xrr3FNZGx5VUttE0j/zf3ZX9lzn5v8e6RP/xRrW+ZX9z7dxnk/8wZH7tM4e71INOeKw3Cd+cP7m94WkM0v/6FK3YSU35lI3SNLvJJ3gE99f0iBlF+O62FNS8CLVxid+J5/4wZIulXR3/twHV1+YXerW1En7aR328z9c6rpJukfSj33it5XUX9LjktrXYXWDJR1Un/1phhq1vebu9okf4hO/taQrJd3rUte/5oMi2k5F+MT/rLrdavXxGFzdaXCpcy51tV0zDlN2sayvvXzit5c0UlI/SX+o+YAGej0aS6O1NZ/4W0te05nKju3gNb2JRazXehPbUFInSd+rUW8jqbNP/MeSzpHUtj7bXsN+zS95vjdKurakHX+R709t51Mn1dj/Mre/XhzvRrkgSRonaYe895ZImiVpsEvd9soumHsq+7R+nU/8713qnKTfStpb0nvKRg/W5AJJP/OJf1OSfOK/lFTda9xC0i2SuirrfZ7sE/+BS90hki6W1FLSfEnHKxstOFPSKpe6EyT90Cd+XF2edN6D7Cmpj6R5LnX/kDTcJ/4H+d8fVjZCcICkNi51kyRNlXSRpA1d6m5S1oH5WNJ/+cQvr2Vz35f0J5/45/Ln7yX9Ld9O5/z595O0TNIZPvFT8hGKX+XPebmkk5Ud78vy/dlV0hU+8XfX5fk3Y43RXr/CJ36sS90fJJ0h6f/LP62Pl/R1SQ/m//6lstGJeco+ac1yqTtbWXv9UtLrPvHHuNTtIenX1auWtLtP/Geqg3z06zFJYyXtIukwl7qpPvFV+d+PlHSwsjf3QyXt4VJ3saQj8lUc5VJ3vbIL3KnlnEs+8Utc6s6U9GHehndQ3OvRQ9Ldkjoou8adpexY/lHS8PyY3OITf21djkmFNXpbs1jtKP/TgLzt9Zb0q5JO5BKf+Kqa+y1piqQt82vZEz7x5+fP4al8Gz0ljXWpm+cTv5dL3bHKPjQ5SY/4xP+4ev2Sfi9pL0kLJB3jE189clCX53ebpE8lDZH0ikvdZyr5dO9S95qydnxl6f5LekRSlUvd35R9GH1Z2YdTX9d9ybfXrI93g2cc8t7dgVo97DlS0kU+8QOUDaUs8okfIWmEpNNd6vpKOlzStsqGS09Xyad/l7rLXOoONTZV/aJafifpzz7xO0i6XVL1sOszknb2iR8i6S5JF+QjBKU91Tp1GkoMU/amf1zRA/LeaPWnkOPz8tbKLhYDJS1UfiF2qTszv5jWVNvzTyVNzJ//TyX9Oa+/qexNZYiykZL/zXvlpaMm61WnoRHbq+UVSduV/LuTT/weytrrbyUd6RM/TFkn8Gf5Yy6UNCR/bavbxXmSvp9/6tlNWaewPrZVdv4M8Yl/33pA/hXLg5LOz9vNu/mfNvKJH6nsk08iSS51PV3qor4G84lfrOwNcuu8FPN6HCdpTP78d5Q0SdlFtpdP/KB8NOPWMp5/g1jLba0mqx1JWXvcP9+3xKWuhbFs6X5fKOndvA2cn//9QGVD9b/R6k/he7nU9ZR0lbJO0GBJI/Kvu6Ts6+ZXfOKHSvqX8rZTT9tI2scn/txaHmPt/xBl7XeAsg9fX5fW7+PdkCMO1Z+gpaxX/UdljXyCT/x7eX0/Zb3tI/N/d1R2gdhd0p0+8askzXSpe7J6pT7xl9ZhX3aR9K38v/8i6er8vzeTdHf+CaWlsgtUpT24hpGCIu/5xE/K//tlZaMW8om/sQ7r2lV5x8Mn/kmXuk1c6joq+0T2J5e6rZV9CrMa6fqiKbTXmp8eqztt2yrrGD7hUidl3/3Pyv82RdLtLnX3S7o/rz0r6ZcudbdLutcn/qMy9sHyvk/883Vc9t78/0vb8EyV91VY6XGJeT1elHRLftG93yd+kkvddEn9XOp+q+xT5D/q8mQqpCm0tZqsdiRln0pXSFrhUjdHWX6qZnsq3W/L15V1ZmsaIemp6k+2eXvdPd/+v7W6/f+fVrej+rgnP27lmlB9DuWvWx9Jz6zPx7shOw7L8x7/f+QXvaWlJWVfBYyp8biDlL2RlWOqsk/3kyMeW73u30r6pU/8g/kQ0Ogytxmj9Pl+qa+O8rSuZbnSMNgqZV8n1Kb6+T9g/M0azvTKgqRjfeIPz4ekn1rDNtZljd1eLUOUheWqVW/bSZrqE7+Lscw3lZ38h0q6xKVuoE/8lS51jyh7c37epW6f6q/w6mhpjX+XPtfa2rC0uh2vUh2uNy517ZVdqN9WNnqwxtcjX253ZcfmLy51P/eJ/7NL3Y7KPs19X9K3JZ1S7v5UyFpvay51typrbzN94g+S0Y7yh9a8DlmvYc32UbqdfpI+9HYosZyvWSpxflXqWlyXdrxOHe+1/XPMMZLOqh6OcanbxqWunaSnJR3jUrdhPhqwV8S6fi7ppy512+Tr2sCl7kf538ZLqv4O6XhlX1FIWS+++tcPJ5Ws6zPVLVS4JjOUfX+5gUvd5sqGnKqtLBiWivU7SSe51O1UXXCpO8Glrruy43l8XttT0rx8CLj0+Y8qWVdDPf/mrpLt9Stclks4Q9JNxp/fktTVpW6X/LEtXOoGuiyouLlP/FhlGZ9Oyr6P3dIn/lWf+KskvaSvfv1RCbNd6vrn2z+8pF7RduNSV6Usp3S/T/wC4yHm6+GyTNMcn/iblH2aH+pS10XSBj7xf5d0iaShldrPBtJgbU2SfOJPzoe3DypqR3Xc75pt4EBlIW3r7y8oy8R0cVnQ71hlw+RS9t5UPdpynFZfsytlhvI24FI3VFLfgv2viHXteK/tjsPNkl5XFlZ5TVk4YyNJ90l6R9l3fzdo9ZMr/F7JJ36Ksu+h7nSpe0PSa5J65H8+W9LJLnVTJJ2o1T+XGS3pHpe6ccoCZ9UeknS4S90kl7rdKvNUJWVDyO/lz+saZd9pV/uDpCn58FGhooyDT/xsZZ2ja1zq3sqPwW6SFit7nsPz53+lVneSrpZ0hUvds8qGv6uNVRbSmeRSd3T5T3OdVbH2mjs6P8ZvK8ueHOET/0bNB+WfHo6UdJVL3WRl39l/Tdlr9n8uda9Kmqgsl7NQ0jkuda/lj12uLNxYSRdKeljSk1r9lYmU5YTOd6mb6FK3ZdHCbs0Zh7H58Z0g6QNJ3y14XNHrsaekSS51E5V9RfdrSb2UBcYmSbpN0k/W8BzXtkq3tdoUtaOy+cTPl/Rs3v5+riz4XfpG9gdJj7nUjfWJn6XsdRirbKT4FZ/46hHTpZIGutS9rOw7+cvqsj+1+Lukznl7OEvZiJa1/4XW5+PtfP3CoesdVzCPA9CcOGMeB6CSXOpaSXrWJ354HZZd4vNf7tTymD1VYx6H9VlDH+9SjfVzTADAeiQP+ZX9Joa6aczjvba/qmiOFiob6gSas9uUtWWgyYn89DtDX/1FAuqonNEGia8qAABAGRhxAAAA0WrNODjnmvxwxIYbhtO6r1oVP8fHDTfcENQGDhwY1JYtC+8RYtUWL14c1BYuXBjUnnjiCXN/HnnkEbNek3PhT3Kb2uiR974i0+HWR3Now5YNNgj79P/+97/rtc5Ro0YFtZUrVwa1zz//PKj16dMnqP3iF7+I3rb1fCz1fY6V1hTasNR823E5jjjiiKC2zTbbBLXly+Pm09tll3Dak7Fjxwa1G2+sy5x6zUul2zEjDgAAIBodBwAAEI2OAwAAiEbHAQAARKv155jrUiDn+uuvN+vf/W44m60VerRCW61bh/dFsZatqgp/ImuFOiXprLPOCmq///3vgxrhyDjrUhsuxznnnBPU9thjj6A2c+bMoDZkyJCg1qJFeBuVX/7yl+a277zzzog9bB6aQhuWmkc73mGHHYLaYYcdFtT23Xdfc/kvv/wyqHXo0CGozZgxI6httdVWQc26Pr/3XnhTSWsbkh1U/9e//hXUnnmm0rfRqDzCkQAAYK2h4wAAAKLRcQAAANHoOAAAgGjrTTjy8ccfN+s777xzUHv33XeDWu/evYOaFXC0ZuKbPXt2UOvatau5P++8805Q23333c3H1hQbmGysYGVTCJY11zZshXatmfUkO2z25z//OahZwTBrNkkrMGmtb//99zf3Z6+99gpqv/3tb4Pab37zm6A2d+5cc51rS1Now1L92rF1vhfVrRD4lltuGdSSJAlqLVu2jKotXbrU3B/rGmRdY61rZ5cuXYLahAkTzO3U1L59e7NuBYKt4/PZZ58FtdNPPz1q242FcCQAAFhr6DgAAIBodBwAAEA0Og4AACBaswpHxt5Ce9CgQUHt6aefNtf5xRdfBLU5c+YENSuQs2DBgqC2ySabRK2ve/fu5v5YgZzhw4cHtWnTpgW1jTYK75JuzcZGOLJpuemmm4LaUUcdFdQWLVpkLm+9xrGz8Fm3u7ZmP23Xrl30/rRq1SqqtmLFiqB2wgknBLWic7cxNIU2LK3ddnz11VcHtf79+wc1K9htBQ+ta7YktW3bNqgtWbIkqFnXWOsaOW7cuKhtd+zY0dyfWbNmmfWatttuu6D26KOPBrVrr702an0NgXAkAABYa+g4AACAaHQcAABANDoOAAAgGh0HAAAQLYzhN2FFadyarJS6dW92yf6FwcCBA4Oa9csIa3rczTbbLKhZ94ovJ5H+4x//OKhZU5paSXpLQ/yCAnHatGkT1PbZZ5+gZiW6reluJfvXRlZt+fLlQc1qw59//nlQ69u3b1ArakfWlMLWL5CqqqqC2m233RbU+vXrZ24Hcaxfzkh2e+rVq1dQs177efPmBTXrVxGxbVOKb5/Wr+Y233zzoGa9Xzz11FNB7YMPPjD3x/q1xaabbhrUOnXqFNSGDBkS1Lp16xbUrNsRNAeMOAAAgGh0HAAAQDQ6DgAAIBodBwAAEK1JhCOt8I4V3LEe9+qrrwY1K8BihbMkeyrdxYsXm4+tyQojWoEcK4Bp3cNdssMyO++8c1B7++23g1qapkHt9ttvN7eDtWP06NFBzQqVWcFDa3r0IrHt0AooWtMEW229qA1by1vToVvTCbds2TKode7cOah9+umn5rYRKgrVWo477rigZoVlrddp/vz5Qc0KGBaFaq02Zm3Hepw1TbrV3q2p/rfffntzf6yAshWSt46vdf6dcsopQe2KK64wt93UMeIAAACi0XEAAADR6DgAAIBodBwAAEC0JhGOjA3v3H///UFtwIABQW3hwoVBzQpnSXaAxprBzHqcFWqznosVLrICZEXbscJEVqjNCto8//zzQe3dd981t42Gt+uuuwY16/W1QmVWmFCyg2HW7HxWqMx6nBXsatGiRVB77bXXzP3ZbrvtgprVXq3Qo/W8f/7znwe1U0891dw24lnXoG222SaoWSFYa4bJlStXBjXruls0w21sSN4KYVrXtBUrVgS1Dh06BLU99tjD3B/r3Jg4cWJQs2b7tUKU1gzCXbp0CWrWrJxNDSMOAAAgGh0HAAAQjY4DAACIRscBAABEaxLhSIsVErRuVWrNIFfOrVwtVpDLCoxZM/nFBt2s4I5kh3esoI31vK0g0vHHHx/ULrvsMnPbaHjXX399UNt7772D2kEHHRTUrICiZLc5K1RmPc6qWeeeFcwsCpVZ54UVIJs6dWpQe+CBB4LauHHjzO2gfo488sigZs3UaIUjreuUdct4qx2Wc3t4K/hrzQw8dOjQoGYFw++5556gNmXKFHN/rOupdS3/9re/HdSsa7b1/I4++uigdt1115n705Qw4gAAAKLRcQAAANHoOAAAgGh0HAAAQLQmG47cdtttg1qnTp2CmjXLo6UoHGnNVmbVrNnOevToEdSscFHsPhaJDVdajxs2bFi9to3Ksm5zHnvr86eeesqsDxw4MKjNnDkzqBXNnlpT7C25i25Vb82oai1/wAEHRO0PGsa+++4b1KxZGa1QrtVGrGuSdT202kLRY2Nnk7Susdb+fOc73wlqVhhesgPB1uyY1kyP1nO0QqbWbJLNASMOAAAgGh0HAAAQjY4DAACIRscBAABEa7LhyM022yyoWSEdK3BiBRmtmc4kOwxk3QbbCgNZgRyrZs2oVk5g0grpWLfEtcJvffr0id4OKqsoBFaTNXujZdq0aWbdChLHziZphc+sZa1wcdF+W+2wPrcKjg3IwTZq1Cizbl2Dim7dXpN13bVmB7VmEbWupZL9mnbt2jWoTZ48Oaq2dOnSoGZdi4v2x7rGWqxjZm3bOi969uwZ1C644AJzO1dffXXU/jQGRhwAAEA0Og4AACAaHQcAABCNjgMAAIjWZMOR1qxmVtjMCk5ZoR8rrCLZoa927doFNes21i+++GJQGz58eFAbNGhQULMCnEX7Y4WGrKCN9bx79eplbgcNLzb0aL3mVmDLCvIWiQ2qWe3IOqcs1ix6RescO3Zs1DotBCHrp3v37mbdCv9Z1z6r3VghQ6u9W23BmiFSsq/v1mtvtTtrWWum4cWLF0ctK9nP0QpC9uvXL6hZx9EK3S9atCioWe81TQ0jDgAAIBodBwAAEI2OAwAAiEbHAQAARKPjAAAAojXZX1VsscUWUY+zErZWenXOnDnm8j169Ihafuuttw5qVsrd+hXDsmXLglpRIt1K07dt2zZqnVY6vz5T/aJxxP764pNPPjHrRSn1mqxfS8TWLNYU8EXLP//881HrjP2FCeJdeeWV0Y/deeedg5p1LT766KODmvVLntjp8ouWt6a2ttqd9esL6xppLVv0izvr1xZdunQJalOnTg1qf/3rX4Pa9OnTg1o5tx5oShhxAAAA0eg4AACAaHQcAABANDoOAAAgWpMNR1qhxdgpp60wYVEY0ZpO1aoVBWhiHmcFd1asWGEuHztta1EwrSZr2tTYsCWaloULF5p1K1BonRexbcY6z6x2WTRVr/XYovMPTYsVYrVqVtj8ggsuCGqvv/56UCuaQtyaht+69lnhdSsgbJ0XltatW5t163yxzqvHHnssqFmByXUJIw4AACAaHQcAABCNjgMAAIhGxwEAAERrsuFI677pVnjGCiNaM8117tzZ3I41M5kV+rLWaQV3rBBYhw4dgpr1XCQ7OGQ9dsaMGUFtyy23DGrWbGy9e/cOam+++aa5P2h4sTNHfvTRR2bdah+xwTArCByraIZJqw3PmjWrzttB/RSFWC1WINBqI927dw9qc+fOjdq2Fc6W4mdRrKqqCmrWPlqBSStYWcQ6h6xzdbPNNotan/V+UfQ+0NQx4gAAAKLRcQAAANHoOAAAgGh0HAAAQLQmG460AjBWcOeVV14JalZI5/vf/765HStwZgUKrcCXtT9WGMh6XNFMelZw6OOPPw5q1113XVC79tpro7bdrVu3oEY4cu2JDUcOGzbMrFttqT63oo4N0xXtt7X8gAEDgtoLL7wQ1LiFduXFti8p/vhboT5rO7G3u5biQ+RWwNG6zsUG2otCmbHHIvb4rkttmxEHAAAQjY4DAACIRscBAABEo+MAAACiNdlwZLt27YKaFS6xbjU8efLkoFbO7GmxAUdrf6wwkDXDXtGtZS1W+Gb8+PFBLXa2wE6dOkVvG5VVn7Zw7rnnmnVr9lOrLVghSisIHHuL9aJzyjovzjzzzKB26623Rm0HTY81U6PVtmNn4S2qW0HI2BkYretmfa/F1raLZsKM2Z/mihEHAAAQjY4DAACIRscBAABEo+MAAACiNdlwpBXassJdn3zySVStiBXysQI91i1araCMtWw5t3KdN29eULPCbzNnzgxq7du3D2qLFi0KatYMbWgcsSFda6bFonZktWErsGWdP7FhMetx1jkqSStWrAhq1vOJVd9AGyrPeo0t1utUFOK22qcVSl+yZElQs2Yats4161wpascW632gY8eO0cuvKxhxAAAA0eg4AACAaHQcAABANDoOAAAgWpMNR1ohFIsV/rMChkWsgKM1w5d161UrfGPVrFnNikJyscHF2FnIrMeVEwbC2jFy5MigFjszaH1ZYURLUTuyZp60zskePXoEtVmzZgW1cmZ9ReOwXhPrWlPOaxc786R1zY69jlthy3JY+9OmTZt6rbM5YsQBAABEo+MAAACi0XEAAADR6DgAAIBodBwAAEC0JvuritatWwc1637t1vTSVprWms5UsqdEtX4FYU33a027aiWDrV9KFP1qxJpO1fpFR7du3YLap59+GtSsJH67du3MbaPhWW3YMmLEiKBWlFC3XuPGmJK56NcX1rat1Hvfvn2DmvWrithfEGHtstqn1UaK2o11PY29flnLWtfNLl26BLWi94aiek3r469+GHEAAADR6DgAAIBodBwAAEA0Og4AACBakw1HWmEqK3Rl1QYNGhTUZs6caW7Hmi7UCmNZgcnYqUatKXit8Kdkh+es/dlhhx2CmvUc+/TpE9TWx/vHNzfW62u1Qck+V6x2FDtFuhVei22Xkh1os9Zpnafjx4+P3g6aFus1tqZ4Lno927ZtG9QWLlwY1KzzwFrWarNWiLKcaaitfV8fw+aMOAAAgGh0HAAAQDQ6DgAAIBodBwAAEK3JhiOtgJUVbLGChwcddFDU4yQ7VGMFLmMDNNZ+WyGdohkErRkqq6qqgtrGG28ctaz1XNbH+8evDVZYLHZGx+233z6oWTODSlKrVq2CmtXerSBkbJDR2u+iNhy7/G677RbU/vCHPwQ1wpGNpz7HOrZtF23Dqltt23ofsNpi7HWuKKi+dOnSoGa1bes9ZF3HiAMAAIhGxwEAAESj4wAAAKLRcQAAANGaRDjSCpdYYUTrNqmdOnUKav379w9qRUEZK9Dz2WefRe2jddtVK2hjBWqKgm7WdqxwpHWr7tgQ5voY5mnKrIDi/Pnzg1pR+Cz2tr71uf2vFVwrWp917lrtcOjQoXXeH6xdLVu2DGqxt9Auul21tU4r8P3FF18ENesaaT2unBCl1Y6tc5CZIwEAAGpBxwEAAESj4wAAAKLRcQAAANGaRDiyffv2QS02VDN48OCg1qVLl6BWFCyzZtizwmrW8tbtjK39th5XTljTmsFsyy23jFrWCrVZ+4jKiw0j9u3bN6hZgavFixdHbye2Frs+S9E5ZbV361bIvXv3jtoOmh4ryGixrqVFrDCj1RatbVvXUytYaZ1XVnuV7PcbK1xZzm251xW8gwAAgGh0HAAAQDQ6DgAAIBodBwAAEK1JhCOtAExs0O+TTz4JauXcxjr2dsFWoNAK/lghMCtkUzR7mrW8Fb6xQp1WuMg6Zh07djS3jcqKvUXxHnvsEdSKAlv12U5sG7Zqsedo0Xasc8qaHXOrrbYKatOmTTO3g8qLbUudO3cOarG3bS+69lnLW/tjXeesIKS1rHVLbmsW3iJW216wYEH08jXFPuemhhEHAAAQjY4DAACIRscBAABEo+MAAACiNYlwpBVOiQ1YWbNOWoFJ6/bbkj0LWWwwzQqHxc7KWPQ4q26FZVq1ahXUpk+fHtR23HHHoLbFFlvE7CIaycCBA4Na7C2Ka6vXFBuErE9gsoj1WOsW9P379w9qhCMbT2wwz7qNdWz41rp2FT3WuhbHzv5oXdutbRQF52OfTzlB5nUFIw4AACAaHQcAABCNjgMAAIhGxwEAAESj4wAAAKI1iTjojBkzgtrixYuD2pw5c4LaK6+8EtQuvvjioGb90kKKv5e6lbC1pn221hf7SwnJnk7VShFvvvnmQe3mm28OaocffnhQmzdvnrltVFbRlMw1Wa9lUdLbYk23a7Uja53WPi5dujSoWe3Vmh69SOwU8tYvTB566KHo7aBxWG3Oal/WFM9F58WSJUui1hnbtq32Zf0Couhcs371YymaQntdxogDAACIRscBAABEo+MAAACi0XEAAADRmkQ4MjbE0rVr16D2xBNPBLWhQ4cGtW7dupnbjp2u19of6z7s1vqsqU+LLF++PKpmhUIvu+yyoNaxY8egFhv6QeMYMmRIULPajPVaSlKXLl2CWmww02Kdj1ataMppqz537tygZk0Xf+ihhwa1K6+80twO1p7u3bsHtX79+gW1WbNmBTXrOi7ZIUUreGiFIy3W9NDWebXxxhuby1v7Hjsl97qOEQcAABCNjgMAAIhGxwEAAESj4wAAAKI1iXCkFYD561//GvU4a5a7SZMmVWS/mptnnnkmqN17771B7c4772yM3UEkKxzZq1evoNanTx9zeWvmSSvwtckmmwS1Nm3aBDUr3GiFwhYtWmTujzWjqnWeWiHdF154wVwnmpZHHnkkqE2ePDmoWQHyDh06mOu0Zt3t3LlzULParBWYrE+tiHUOWW07VnMNWzLiAAAAotFxAAAA0eg4AACAaHQcAABANNdcwxkAAKDxMeIAAACi0XEAAADR6DgAAIBodBwAAEA0Og4AACAaHQcAABCNjgMAAIhGxwEAAESj4wAAAKLRcQAAANHoOAAAgGh0HAAAQDQ6DgAAIBodBwAAEI2OAwAAiLZRQ63YpW6VpFfzbbwh6SSf+GV1XNdtkh72if/bGh53oKTLJbWT5PJlzqvD9vaU9IVP/Hjjb30k3eYTv2eN+guSWknqLKmNpI/zPx3mEz8jYps/9Yn/35JtPOwTP6jM/R4p6RpJ3SR5Sc9IOrvc4+5SN1hST5/4R8tZrilp7PbnUtdN0h8lbS6phaQZPvEH1WV79dmPMtY1Wtk+3lZS21/SVfk/t1LWhpdLmuIT/52IdQ5WSbvJt7HEJ/6aMvZrZ0m/VnYutZJ0t0/86NjlI7cxQ9Jwn/h5lVxvQ2vMNu1Sd7Kk/87/OUDSW5JWSXrcJ/7Cumyz0lzqnpI0qvT66lJ3kaSj8n9ur+x4SdItPvG/iVjnYZLe9ol/vWQb5/nEvxS5T/V6H2guGnLEYblP/OD8ze8LSWeW/tGlbsNKbsylbpCk30k6wSe+v6RBkqbXcXV7SvpaOQv4xO/kEz9Y0qXKLnaD8//NyPdvTZ20n9ZhP/8jf+O6R9KPfeK3ldRf0uOS2tdhdYMlVfRNby1o1PYn6TJJT/jE7+gTP0BSk7i4SpJLnXOpW+O57hM/prrdSnpJ0vH5v//TaVjDcRus+rebP0k6I9+HQZL+Ws/1VUzEOdzQGq1N+8TfWtIWZkraK//3f9p1A5xDhWKPvU/8z0r2e3nJdfg3+XrWdC4cpqyjVCcVeB+oqIZ6jRrrSYyTtEP+ST6RNEvSYJe67SVdqeyNupWk63zif+9S5yT9VtLekt5TNnqwJhdI+plP/JuS5BP/paTrJcmlbgtJt0jqKmmupJN94j9wqTtE0sWSWkqaL+l4Zb3EMyWtcqk7QdIPfeLH1eVJ55+4ekrqI2meS90/lH3S+UH+94eVjRAcIKmNS90kSVMlXSRpQ5e6m5R1YD6W9F8+8ctr2dz3Jf3JJ/65/Pl7SX/Lt9M5f/79JC1TdmGeko9Q/Cp/zsslnazseF+W78+ukq7wib+7Ls+/CWmM9tdD0j+q/+ETP0X6z+jVaEnzlL0Rvqysc+td6oZJ+qWkqvzvo3ziZ7nUnS7pDGXtcpqkE2t+snSpu1zZ6MYpks6V9O38OdznE5/ko1aPSRoraRdlF8T3I55HIP+Efouk/ST9zqXuTOWfwlzquijrZGyjGu0mX3xA/qmtt6RfRXzq21TZ6yOf+FWSqj/5jc7X0a/muvLz9Gxlx+sFSd/ziV/lUneDpBHK2vfffOKTGs+rjaT7JP1d0h3KXvPtlV0XR/vEP+BSN0rSNyW1VjaSuXf0gWtYjdGmAy51S5S12f0lnZtfQ07J/3yzT/yvao6YutSdJ6nKJ360S93Zyq6vX0p63Sf+GJe6dmrAY2+dCy51U33iq/K/HynpYEl/kHSopD1c6i6WdES+iqNc6q6X1EnSqeW+HxjvAz+R/X50m0pGgVzqlvjEV7nU9ZB0t6QOyo7PWT7x41zq9pOUKnud383Xs6Tm+SrprnL2N0aDZxzyHtaBWj1kNFLSRfmnslMlLfKJH6HsBD/dpa6vpMMlbausIZ2ukk//LnWXudQdamyq+qJs+Z2kP/vE7yDpdknVF69nJO3sEz9E2cG9IO8Z3ijp2rynWKdOQ4lhyt70jyt6QN6Lr+4dH5+Xt1Z20g+UtFB5I3apOzO/cNdU2/NPJU3Mn/9PJf05r78paff8+V8q6X994r/QV3vLzbrT0Ijt7zpJf3SpG+tSd5FLXc+Svw2RdI6yTzL9JH3dpa6FsovlkT7xw5Sd6D/LH3+vT/wIn/gdlQ1Jn1rjOV2t7A32ZEn7KGsrI5V94h/mUrd7/tBtlbX7IT7xdeo0lPjcJ35Xn3jzIlRLu9lO2ZvMSElJ/rzlUvdojWNU7VpJb7nU3edS912XutYlfwvW5VLXX9LRkr6ef9JbpewDgJS9zsMl7aDszWCHknVVSXpI0h0+8Tcp66w/mbeFvST9PH9Dk7I3m5N84ptEp6ER27SlnaTXfOJ30uoPGztJ2jnf1pA1LH+hpCH5taj6OtYYx36N54LPvpp+UNL5eRt+N//TRj7xI5Wdw4kkudT1dKkr56vc0veBovejIsdJGpO37x0lTco77BdL2scnfqiyzvuPSpap9Xytr4Yccaj+BC1lveM/KmusE3zi38vr+ynrNR+Z/7ujsovg7pLuzD9xzHSpe7J6pT7xl9ZhX3aR9K38v/8i6er8vzeTdHfeo2uprCdeaQ+uYaSgyHs+8ZPy/35ZWW9VPvE31mFduyrvePjEP+lSt4lLXUdlPdg/udRtrSwT0aIO626qGrX9+cSPcanrp2z06EBJE/Ovz5Rv8yNJyvepj7LO4CBJT7jUSdKGyj9pSxrkUvc/yj7hVEkaU7KpSyS94BN/Rr6+/fLnMTH/e1X+HD6Q9L5P/PNrOE6x6tqBfMQnfoWkFS51c5Tlbz7yBfkPn/jLXOpuV/acjpN0rLJPz0Xr+oayi/KL+XFsI2lO/vhvu9Sdoew610NZx21K/rcHJF3tE397/u/9JB2afzqWsk+5vfP/fsIn/tM6Pv9KagrX1FXKRmik7Lpyn0/8UklyqbtX0m7K3nyLTJF0u0vd/ZLuL9nnhj729TkX7s3/v/Q6PFPlfS1X+j5Q9H5U5EVJt+Sd7vt94ie51O2hrD0/m7f7lpKeK1mmQT/wNWTHYXneQ/qP/AkuLS0p+ypgTI3HHaTsjawcU5VdQCZHPLZ63b+V9Euf+AdLhpQrrfT5fqmvjvK0VrEVJf+9StkFsTbVz/8B42/WsKRXFiQd6xN/eD6c99QattGcNHb7U36Bu0PSHfnXULsr+wqs5mu5Ub7tqT7xuxiruk1ZmGpyPly7Z8nfXlQ2qtA5355T9nXS72s8hz766nOtr6J2XFsbluznXqv8k94N+Vd1c13qNqllXU7ZV3Q/KV1H/in7PEkjfOIX5MPApfv6rKQDXeruyL/Wc5KO8Il/q8Z6dlJlj2N9NHqbNnyedz6qt2Wp7Tr3TWXnxaGSLnGpG6jGOfY111N6LGLbcFT7jdy+tS//OW75V0stJckn/ul8FPGbkv7iUvdzSQuUdaqOrcP26m1t/xxzjKSzSoYvt8mHqJ6WdIxL3Yb5aMBeEev6uaSfutRtk69rA5e66qGb8ZKOyf/7eGVfUUhZb7w69XpSybo+U91ChWsyQ9n3kBu41G2ubIix2srq41BHv5N0Un6yScq++3Wp667seB6f1/aUNM8nfrG++vxHlayroZ5/U1Ox9udSt7dLXdv8v9tL2lLZp/4ib0nq6lK3S75Mi/wiKmXHfla+X8fXWO5xZd9hP5JvZ4ykU1zqqr+v7eVSt2nMk6+HGco6qZJ0ZEm93u3Gpe6b+UVTyj4pr1I2OlPkn5KOrH7OLnWdXZZp6qDs4rnIZcHhA2ssd6myTt31+b/HSPph9bYjhtybqkpeU9fkaWV5gbb5Ng5XNhIyW9Km+chmK2X5AbkslLi5T/xYZZm0Tlo9otbYx362S13/fJ8OL6k3xrWv6P1ohlafV/+lfAQ4b89z8q/U/ihpqKTnlX3luVX+mLbV732NYW13HG5WFn56xaXuNUm/V9aju0/SO8q+w7tB0r+qFyj6Ps5nYbRzJN3pUveGpNeUDU9KWXDqZJe6KZJO1OqfGY2WdI9L3Thl4bRqD0k63KVukkvdbpV5qpKyTznv5c/rGkmvlPztD5Km5MO0hVxBxsEnfrayxniNS91b+THYTdJiZc9zeP78r9TqTtLVkq5wqXtW2VB5tbHKQm2TXOqOLv9pNhsVa3/KTviX8mP8nLKg2ItFG84zAUdKusqlbrKkSVr9vfMlykJ+TyjLodRc9h5JNykbEh6nbJTjOZe6V5UFYhv6wneNsjen8ZK6lNSj240rzjicqCzjMEnZMO7xJZ9wAz772dzFkv6RH/snJPXwiZ+s7OubqcryI88ai58jqbXLMiOXK7tQT8nbwuW17X8TVsk2XSuf+FeUjY5NUNZeb/aJn+gTv1JZUPYFSQ9rdRveUNL/5e10orIc2UKtnWN/Yb5vT2r1V4RSlnU736VuokvdlkULu/IzDqWK3o9uUpbFmaAsN1I9arCnslzDRGVfOf/aJ36usg97d+breV5ZBqhROO8rMXq1/nAF8zgAzYkz5nEAmhNnzOOAxrG2RxwAAEAzsrYnNGmOFiobngOas6dUe3YAaOpuE214reCrCgAAEI2vKgAAQLRav6pwzlV8OMK58Ke/1qhH7OPqq0+fPkHtO98J7+fz73//O6i1bds2qLVq1SqopWka1BYvXmzuT2M978bgva/TtLaV1BBtGOuPptCGpXWrHY8ePdqsL1y4MKgtWxbew8u6FltatAh/3b7hhuGtG/r27Wsuf+6550ZtpzmodDtmxAEAAESj4wAAAKLRcQAAANHoOAAAgGi1/hxzbYYjY5e1arHhGUmaOnVqUNtqq62CWsuWLYPaF198EdSs53L11eHNzy69tC43+VytOYQom0KwbF0KlaHxNYU2LK1b7bghrlOxAfsvv/wyqG20kf0bgQMOOCCojRkzxnhk00c4EgAArDV0HAAAQDQ6DgAAIBodBwAAEK3Rb3IVG+qzZviyQo+xQcizzz7brFdVVQW1adOmBTUrCLlgwYKg1r59+6B2zDHHBLXx48eb+/P444+b9RjWsbU0tRAlgHXTnnvuGdSKrj9vv/12nbcTG5y3ZqLs2bOnuc6RI0cGteYajqw0RhwAAEA0Og4AACAaHQcAABCNjgMAAIjWJGaOjJ390Xrc+eefH9ROO+20oFY0O9iKFSuCmjVLpBWEtB63dOnSqMdZt+SW7PDOVVddFdT++te/msvXtDZnmGwKs+6tSzPuofE1hTYsNd92/OMf/zioXXHFFeZj33nnnaBWdJ2syXq/iJ0lsk2bNuY6X3311aD2jW98I2p/mhpmjgQAAGsNHQcAABCNjgMAAIhGxwEAAESj4wAAAKI1+pTTVqLfqnXv3j2ovfzyy0Ft/vz5Qc36BcTixYvN/bF+ddCpU6eg1q1bt6A2Y8aMoGb9qmLlypVBreiXDRtvvHFQu+iii4La//zP/wS1/v37B7VVq1aZ2wGAhtauXbugVnTts34FYf3qLfZXYdbjrOvh8uXLzeWtfUeGEQcAABCNjgMAAIhGxwEAAESj4wAAAKI1ejgydgrkp59+OqjNmTMnqFnhyA033DCqJtlhGStI+eGHH5rL12RNX9q6deug1qpVq6j1SfZz7Nq1a1CzpqE+4ogjgtranIYawPrDus5Z00NL0gYbhJ9jrZp1PbVqVkjeCmAW4ZpYjBEHAAAQjY4DAACIRscBAABEo+MAAACiNYmZIy+99NKox82dOzeoWaEYa6bGokBO7Oxi1vIdO3YMalbw0FrfsmXLzP2x7hdvbdsKTG611VZBbccddwxqkydPNrcNAA2tKKhuXbdbtGgR1Kzw+syZM4Pa1ltvHfU465orSZ9//rlZByMOAACgDHQcAABANDoOAAAgGh0HAAAQrdHDkZbTTjstqFnhP+sWq1bw0Aq7lHN7aWv5li1bBrX6zMBYFMj54osvgtqSJUuCWq9evYKaNcvad7/73aD2ve99L2YXAaBe3nzzzejHWtfoTp06BbVx48YFtYsuuiioTZ06NahNnz49qHXr1s3cn3nz5pl1MOIAAADKQMcBAABEo+MAAACi0XEAAADRGj0cWVVVFdSsW6+2bds2qG2yySZBzZqBMXYGsqLHWqzbscYGIWNnopTsgGPsrbotW2yxRdTjEM8KxVqvW2wg15pJz1q2aMa9WNZ+W+160003DWqHHHJIUDvggAPM7UybNi2o/eQnPwlqsc8bzdeUKVOCmtUOi+pWzQqWF83EW5N13bXekyR735FhxAEAAESj4wAAAKLRcQAAANHoOAAAgGiNHo7cbLPNglrsrajrEzYrCjIWBXVqsgI5seFIa3+sUFrROq3lrVt6WzNrWjNeon6sIGRR2LWuYtulVPlA4WeffRbUbr755qBWFEg7+OCDo7ZT6f0uauvWbKxWAHTgwIEV3R+UN3OkFZK3rn1Wu4u9FluPK2o3r732WtQ610eMOAAAgGh0HAAAQDQ6DgAAIBodBwAAEK3Rw5F9+/YNalYYa/ny5UHNCjR9/PHHQa1z585BbdGiReb+WDMwWmEqK7hjLRsb+CoKv1nhHSuMZ+2Pte3YGSYRr9IzQlZ6u5I0dOjQoHbFFVcEtRNPPDGoWQHmO+64I6jNmDHD3PaPfvSjoHbkkUcGte9///vm8jGsY/v888+bj/3Vr34V1MaPHx/UCEdW3tKlS4Na0Wy91jXRus4tXrw4qFmz61qs9VnBd0l69dVXo9a5PmLEAQAARKPjAAAAotFxAAAA0eg4AACAaHQcAABAtEb/VUX37t2DmjWFqHWPdKtmJc2tJG/RtKLWLxas6aBbtGhR52XLma7aWt5KIVu/OrGmPbZ+iYLGEfsriNjHWYlwSbr88suD2vDhw4Oa1YZ/+MMfBrW///3vQc2acvqyyy4z9+dvf/tbUDvppJOC2osvvhjUrOmqrV9Q3HDDDUHtjTfeMPfn4YcfDmrf+973gtrChQvN5VFZs2fPNuvWddJqs3Pnzo1aNnYb1vuFJE2bNi1qnesjRhwAAEA0Og4AACAaHQcAABCNjgMAAIjW6OFIK+BlBQI7deoU1KxwpBVQtKaMLmKFJq19tKZDtYI7sdu2Al+S9Pnnn0ftjxWos0KUTDndtGy++eZBrV27dkHtqKOOCmpWcFCKb3PWtM9nn312UDv66KOD2i9+8YugNnbsWHM7o0aNCmpWCHPMmDFBbdy4cUFtxYoVQW3AgAFBbccddzT3x5rmvnfv3kFt/vz55vKorFmzZpl1KzhvXXetWxR06NAhatuxYUvUjhEHAAAQjY4DAACIRscBAABEo+MAAACiNXo40gqnWEHBtm3bBjUrBGaFGzt27BjUiu4BbwUzrXu7W7OLWQHFTTbZJKhZ4S4r4CPZx8LaH2sGNCtYae2jFSi1Zp1E/Vjt8Nhjjw1qRxxxRFCzXnOrHUnSs88+G9QeeuihoDZy5Mig9uCDDwa1nXbaKagdcMABQe3SSy8192f69OlBzQpmDhw4MKideuqpQe0HP/hBUDvrrLOCWlG48Rvf+EZQe+yxx4LaNttsYy6PyrLahyT16NEjannrGmkFjGOXnTFjRtSyWI0RBwAAEI2OAwAAiEbHAQAARKPjAAAAojV6ONIKOFqBSSscZs04Fntr66KZxT799NOofbTCmlZYzbpdtjXjZdFttRcvXhzUrODiokWLglps6NGaldM6DusqayZOK1wVG7iS7NCVNTuh1WamTp0a1Kzbplu3kpakfv36BbUlS5YENet132qrrYLaSy+9FNROO+20oNanTx9zfyZMmBDUtttuu6B27rnnBrV//vOfQa1z585BrVevXkFtxIgR5v5Y55R1zbFqqLyimRqt65c1c+QHH3wQ1GJnyLXWx+2zy8eIAwAAiEbHAQAARKPjAAAAotFxAAAA0Ro9HGmFtqxgizUz4rJly4KaFaixAmjWLH6SHZaxatZ2LNYMk1awsmvXruby8+bNC2rdunWL2vaCBQuCmhX4sm5fu66GI61ZEK0go9VmrHYg2WHX2HVar+8ZZ5wR1KzgoRVklOwZQ63HWrOnWueUtd/33XdfULNmk5SkXXfdNai99tprQc26xbj1ep144olBbeLEiUGtKNz4zjvvBDVrRtWi1xuVZYWBJftW8tb5Yl3nimZVrcl6jT/88MOoZbEaIw4AACAaHQcAABCNjgMAAIhGxwEAAERr9HBk7O2brbCLNSOkFayMnU2yaDvWrJXW7butZa1ZJ61QWtHMkVZoy1rnpptuGtRiZ44sCmaui2Jv1WvNSloUuLICvtZslNZrOXPmzKB2+OGHB7Vygnoff/xxULMCudZMmNYtjq3bU1szWT788MPm/uy///5Bbe+99w5q1vGx9tE6FtbxtmZTLWIdH+t1ReUVvU5WwNi6plnhyKJbdcesb10NhjckRhwAAEA0Og4AACAaHQcAABCNjgMAAIjW6OFIK9RkBfisMJY1g+Ls2bODWjm3Q7Zut22FsWJnJrOCh1aA0zoOkrTJJpsENWs2SitwaQU4rWMbOxPlusBqC9YxtmZftMJ7kt02rVkLrdfICrpas+NZs1MWhfesbVszQsbOSjpo0KCgZgWGi25l/NlnnwU1KxBnBVetGWNjZ4ncbLPNzP2x6tY5NW7cOHN5VJY1O6hkB8atW6pbt+W2Ar0WK4A5dOjQqGWxGiMOAAAgGh0HAAAQjY4DAACIRscBAABEo+MAAACiNfqvKqxfMVi/WLAeZ6Xc33jjjaA2bNiwoGalzKXiqahr6tSpU1CzUvNW4t76ZYOVPJfsNP2ECROC2uabbx7UrFSyleIvSsOvix599NGgtu+++wa1bbbZJqhZ6W1J+uSTT4Ka1YZjp023ftlgTYNr/RpEktq3bx/UrF8Gbb311kHNaofWeTZlypSgVvRLowEDBkSt0/q1hPXLD2t6aOvXS0XTdL/yyitBzUrhz5kzx1weldWzZ0+zHjvN+ltvvVXnbVvbWJ+uh5XCiAMAAIhGxwEAAESj4wAAAKLRcQAAANEaPRxZFPCqyQoUPvvss0HNCmhZAUNrilrJnoI0dsppa53W1LzWNLrWfeGL6m+++WZQO+yww4La4sWLo9ZXzpTczd2CBQuC2gMPPBDUrOmP99lnH3OdI0eODGrWdNALFy4MatZrZLGmJC9qM9b0yVYY8Zlnnglq7777blCzpnG3zqkdd9zR3B8rzGuFhq1zzwrzWsfRel2LpghH07Llllua9digen1Yba5o+n8UY8QBAABEo+MAAACi0XEAAADR6DgAAIBojR6OtMKDVqjJqr300ktB7ZprrglqAwcODGozZsyI3EM7LGPN5FcfRWFNazZKyyWXXBLUrJkjrfV17949ahvrKivoarWPm2++2VzeCpdaszJaITArKGvNfmq9lkWs2R+tEKYV4LTCYtZMelZocfr06eb+WG3OmqnR2p9YVoC5aOZB6zlaNcKVjcNqC5K02WabRS1vvYdY4VuLFTCOveZiNUYcAABANDoOAAAgGh0HAAAQjY4DAACI1ujhSCvE0rJly6BmBbQeeuihqG1MnTq1/B0rYc3EV2n1DeS88847Qc261bAVBLRm5UQ8q31MmjQpqtbUWIFA6/lZNWv2xsZSTnjUmpGwMWYphK3o2mcFVi3W+0VsONIK0BKOLB8jDgAAIBodBwAAEI2OAwAAiEbHAQAARGv0cGRsqMkKyrz11ltRy1qz8xUFAq2ZxKx9LCeMVZMVyClaX2xw0Zpt0ApHWtshHAlgbbGC70WsW6pb1/dY1vtKbLASqzHiAAAAotFxAAAA0eg4AACAaHQcAABAtEYPR8beurac22DHbKO+YcRYVhCynG3EBilffvnloLb77rsHNet2yMyaB2BtKSeoXumZHssJqqMYIw4AACAaHQcAABCNjgMAAIhGxwEAAERr9HDkkiVLgpoV1rNCLLHBFitkExvKLGc7DSF23ydPnlzn9S1evLj8HQOACrAC25J9rbLEhs3nzZsX1KxZKwlHlo8RBwAAEI2OAwAAiEbHAQAARKPjAAAAotFxAAAA0Rr9VxU77LBDUGvRokVQa9u2bVCL/cVBfX9VUZ+UbX0TurH7PmfOnKDWqlWroGaliIcPH17HvQOA+nn//ffN+m677RbUPv/886Bm/TLPYv16w7oezp49O2p9WI0RBwAAEI2OAwAAiEbHAQAARKPjAAAAojV6OHLChAlBrWXLlkHNCkfGBhxjpyRdm6xpraX4ff/444+D2qRJk4KaFfxZtGhR1DYAoNJeeOEFs37KKacEtaqqqjpvx7rGWuHzV199tc7bWF8x4gAAAKLRcQAAANHoOAAAgGh0HAAAQDRX20yHzrkmf6NyKwDTHO6vXhSObA77Hst7bz/JRtQc2jCarqbQhqV1qx3vuuuuZv2xxx4Lap9++mlQ22KLLaK28+GHH0at7+CDD45evrmqdDtmxAEAAESj4wAAAKLRcQAAANHoOAAAgGi1hiMBAABKMeIAAACi0XEAAADR6DgAAIBodBwAAEA0Og4AACAaHQcAABDt/we7/T0xPPye3QAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 648x648 with 9 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot predictions\n",
        "plt.figure(figsize=(9, 9))\n",
        "nrows = 3\n",
        "ncols = 3\n",
        "for i, sample in enumerate(test_samples):\n",
        "  # Create a subplot\n",
        "  plt.subplot(nrows, ncols, i+1)\n",
        "\n",
        "  # Plot the target image\n",
        "  plt.imshow(sample.squeeze(), cmap=\"gray\")\n",
        "\n",
        "  # Find the prediction label (in text form, e.g. \"Sandal\")\n",
        "  pred_label = class_names[pred_classes[i]]\n",
        "\n",
        "  # Get the truth label (in text form, e.g. \"T-shirt\")\n",
        "  truth_label = class_names[test_labels[i]]\n",
        "\n",
        "  # Create the title text of the plot\n",
        "  title_text = f\"Pred: {pred_label} | Truth: {truth_label}\"\n",
        "\n",
        "  # Check for equality and change title colour accordingly\n",
        "  if pred_label == truth_label:\n",
        "      plt.title(title_text, fontsize=10, c=\"g\") # green text if correct\n",
        "  else:\n",
        "      plt.title(title_text, fontsize=10, c=\"r\") # red text if wrong\n",
        "  plt.axis(False);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ce6dc44-90a5-48c3-91a5-810fa084d98b",
      "metadata": {
        "id": "5ce6dc44-90a5-48c3-91a5-810fa084d98b"
      },
      "source": [
        "Well, well, well, doesn't that look good!\n",
        "\n",
        "Not bad for a couple dozen lines of PyTorch code!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab108078-6770-4cb9-ac62-a761ff159aba",
      "metadata": {
        "id": "ab108078-6770-4cb9-ac62-a761ff159aba"
      },
      "source": [
        "## 10. Making a confusion matrix for further prediction evaluation\n",
        "\n",
        "There are many [different evaluation metrics](https://www.learnpytorch.io/02_pytorch_classification/#9-more-classification-evaluation-metrics) we can use for classification problems.\n",
        "\n",
        "One of the most visual is a [confusion matrix](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/).\n",
        "\n",
        "A confusion matrix shows you where your classification model got confused between predicitons and true labels.\n",
        "\n",
        "To make a confusion matrix, we'll go through three steps:\n",
        "1. Make predictions with our trained model, `model_2` (a confusion matrix compares predictions to true labels).\n",
        "2. Make a confusion matrix using [`torch.ConfusionMatrix`](https://torchmetrics.readthedocs.io/en/latest/references/modules.html?highlight=confusion#confusionmatrix).\n",
        "3. Plot the confusion matrix using [`mlxtend.plotting.plot_confusion_matrix()`](http://rasbt.github.io/mlxtend/user_guide/plotting/plot_confusion_matrix/).\n",
        "\n",
        "Let's start by making predictions with our trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "065b8090-c9c5-43df-b5c1-b45ba33af1be",
      "metadata": {
        "id": "065b8090-c9c5-43df-b5c1-b45ba33af1be",
        "outputId": "e3acda46-ff75-471e-8362-d878929780d5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ddb83e1f77d840b981ecebc11d584069",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Making predictions:   0%|          | 0/313 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Import tqdm for progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# 1. Make predictions with trained model\n",
        "y_preds = []\n",
        "model_2.eval()\n",
        "with torch.inference_mode():\n",
        "  for X, y in tqdm(test_dataloader, desc=\"Making predictions\"):\n",
        "    # Send data and targets to target device\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    # Do the forward pass\n",
        "    y_logit = model_2(X)\n",
        "    # Turn predictions from logits -> prediction probabilities -> predictions labels\n",
        "    y_pred = torch.softmax(y_logit.squeeze(), dim=0).argmax(dim=1)\n",
        "    # Put predictions on CPU for evaluation\n",
        "    y_preds.append(y_pred.cpu())\n",
        "# Concatenate list of predictions into a tensor\n",
        "y_pred_tensor = torch.cat(y_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "362002d9-ec41-4c74-a210-b5d4f53410c4",
      "metadata": {
        "id": "362002d9-ec41-4c74-a210-b5d4f53410c4"
      },
      "source": [
        "Wonderful!\n",
        "\n",
        "Now we've got predictions, let's go through steps 2 & 3:\n",
        "2. Make a confusion matrix using [`torchmetrics.ConfusionMatrix`](https://torchmetrics.readthedocs.io/en/latest/references/modules.html?highlight=confusion#confusionmatrix).\n",
        "3. Plot the confusion matrix using [`mlxtend.plotting.plot_confusion_matrix()`](http://rasbt.github.io/mlxtend/user_guide/plotting/plot_confusion_matrix/).\n",
        "\n",
        "First we'll need to make sure we've got `torchmetrics` and `mlxtend` installed (these two libraries will help us make and visual a confusion matrix).\n",
        "\n",
        "> **Note:** If you're using Google Colab, the default version of `mlxtend` installed is 0.14.0 (as of March 2022), however, for the parameters of the `plot_confusion_matrix()` function we'd like use, we need 0.19.0 or higher."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6c0a05d-d3e0-4b86-9ef7-ee6ea5629b07",
      "metadata": {
        "id": "e6c0a05d-d3e0-4b86-9ef7-ee6ea5629b07",
        "outputId": "910ab29f-28e5-47ce-c760-c5e4a76e2348"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mlxtend version: 0.19.0\n"
          ]
        }
      ],
      "source": [
        "# See if torchmetrics exists, if not, install it\n",
        "try:\n",
        "    import torchmetrics, mlxtend\n",
        "    print(f\"mlxtend version: {mlxtend.__version__}\")\n",
        "    assert int(mlxtend.__version__.split(\".\")[1]) >= 19, \"mlxtend verison should be 0.19.0 or higher\"\n",
        "except:\n",
        "    !pip install -q torchmetrics -U mlxtend # <- Note: If you're using Google Colab, this may require restarting the runtime\n",
        "    import torchmetrics, mlxtend\n",
        "    print(f\"mlxtend version: {mlxtend.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5245ede6-fd7f-40ad-a0b3-ae678544b84a",
      "metadata": {
        "id": "5245ede6-fd7f-40ad-a0b3-ae678544b84a"
      },
      "source": [
        "To plot the confusion matrix, we need to make sure we've got and [`mlxtend`](http://rasbt.github.io/mlxtend/) version of 0.19.0 or higher."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21383f88-a2dd-4678-94c6-479c592da0ab",
      "metadata": {
        "id": "21383f88-a2dd-4678-94c6-479c592da0ab",
        "outputId": "cc0b33fc-dabf-41aa-8c61-78ee89d59aa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.19.0\n"
          ]
        }
      ],
      "source": [
        "# Import mlxtend upgraded version\n",
        "import mlxtend\n",
        "print(mlxtend.__version__)\n",
        "assert int(mlxtend.__version__.split(\".\")[1]) >= 19 # should be version 0.19.0 or higher"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c91b9346-e25f-48ab-967e-425649331dc6",
      "metadata": {
        "id": "c91b9346-e25f-48ab-967e-425649331dc6"
      },
      "source": [
        "`torchmetrics` and `mlxtend` installed, let's make a confusion matrix!\n",
        "\n",
        "First we'll create a `torchmetrics.ConfusionMatrix` instance telling it how many classes we're dealing with by setting `num_classes=len(class_names)`.\n",
        "\n",
        "Then we'll create a confusion matrix (in tensor format) by passing our instance our model's predictions (`preds=y_pred_tensor`) and targets (`target=test_data.targets`).\n",
        "\n",
        "Finally we can plot our confision matrix using the `plot_confusion_matrix()` function from `mlxtend.plotting`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7aed6d76-ad1c-429e-b8e0-c80572e3ebf4",
      "metadata": {
        "id": "7aed6d76-ad1c-429e-b8e0-c80572e3ebf4",
        "outputId": "a6b2dabb-639a-44b7-ed8c-6c9c296cba07"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdgAAAHMCAYAAAB2nrkUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAACH30lEQVR4nOzdd3gUVRfH8e9Jg9ARQkvoLVRTCdKbFOm9iSCgYO+9V1QsCIjYxYIgqPQqvUOQoqAUBV4IHekBU7jvHzOJCyYQILOz6Pk8T57szs7u/HIzO2fmThNjDEoppZTKXn5uB1BKKaX+jbTAKqWUUg7QAquUUko5QAusUkop5QAtsEoppZQDtMAqpZRSDghwO8C/QUCu/CYwf1G3Y/xDlRL53I6QoXM+emqYj8bC30/cjpAh30xlOZ2U6naEDOUO8nc7QoZ8dNb32Xnsp5/WHjbGhFxqPC2w2SAwf1HKD3jP7Rj/sOy5Zm5HyFCijy78UlJ9czGTN6dvfk39fLTwA/y046jbETIUVbag2xEy5KvXQxDxzXksOFB2ZWU87SJWSimlHKAFVimllHKAFlillFLKAVpglVJKKQdogVVKKaUcoAVWKaWUcoAWWKWUUsoBWmCVUkopB2iBVUoppRygBVYppZRygBZYpZRSygFaYJVSSikH+OZVxP/l8uYM4IUOValQNA8YwzM/bKZ+pcI0qRLCOQN/nk7iqe82cejkXwBUKpqHZ9tXIU+OAM4ZQ4/Rq0lKOee1vMeOHePOQbexedMviAijP/qEuNo3eG36F0pNTaVZ/TiKlQjlm4mTGXBLL37ftgWA48ePkz9/fhauWOu1PNu3bWHQrb3Tn+/auYNHn3yOrj1uZtCtvdn9v12ULFWaDz8fS4GC7l3sfcS77zDms09AhGrVa/DBR5+SM2dO1/KkGTSwPzNnTCOkSBHWrv/Fq9M+sG8PLz16J38eOoD4+dG+e1+69R3MyNefZdn82QQGBRJasixPvjaSvPnyM3vKBMZ+PCL9/b9v2cSnPyykUtUaXss8Z/YsHn7wPlJTU+nXfyCPPPq416Z9KeEVy5I3T178/P0JCAhg2co1bkdytb3E6bsoiEghYJ79tBiQChyyn9cyxiRl8r4ywDRjTPUMXnsRWGyM+TGD1/oBc4wxez2G9QTKAcuAJGPM8iv+gzIQXLySuZy76bzSuRo/7TzGd2sTCPAXggP9OWcMp/+y7jLTu3ZJyhfJw4tTfsXfT5hwZxxPTPyFLftPkT84kJNnkzmXhX/bmmy6m85t/ftRp149bu0/kKSkJBITEylQoMAVf97V3k1n1Ih3WP/TT5w8eYJvJk4+77VnnniEfPny88gTT1/252bH3XRSU1OJCC/DjHlL+eyj9ylY8DruefBRRrz9BseOHeWZF4dc9mdmx9109iYk0KxxfdZu2ERwcDB9enWnectW9Lml3xV/ZnbdTWfpksXkzp2Hgf1vybYCm9W76Rw+uJ8jhw5Qudr1nD51kgGdmjBk1Jcc3L+X6NoNCAgIYNTQ5wG485Hnz3vv71s28/gdvZkwf12Wc13t3XRSU1OpUbUS02fOJTQsjHq1Yxnz1TdUqVr1qj43u+pAeMWyLF2xhsKFC2fL513t3XScaq/gQFlrjIm51HiOdxEbY44YYyKMMRHAaOCdtOeZFdcsfOazmRRXf6AfUOKCl1oCs4BGQJ0rmWZ2yZ3Dn+gyBflubQJgLdRPnk1JL64AwUH+6TN8nQqF2Lr/FFv2nwLg+JmsFdfscuLECZYuXUy/WwcAEBQUdFXF9WrtTdjD3Fkzublv/3+8Zoxh8vcT6dS1uwvJLEsWzqdM2XKULFWa2TOm0q1XHwC69erDrOlTXMsFkJKawpkzZ0hJSSExMZHixS/8mrijXv0GXHfdda5Mu3CRYlSudj0AufPkpXT5Shw6sI+4ek0ICLBWbKpdH8PB/Xv/8d65076jWZvOXs27ZvVqypevQNly5QgKCqJr9x5Mmzr50m/8j3K7vXxiH6yIVBOR1SKyXkQ2ikhF+yV/EflIRDaJyBwRCbbH/1xEutiPd4rIsyKyFOgJxABf258VLNYqUATwJzAYeMB+rb6IlBaRefY054lIKY/PHy0iS0Rkq4i0ya6/NaxgMEdPJ/Fyp2pMuDOOFzpUJTjQ+jfc26w8Pz5Sn9bXF2fkvN8BKF0oFwbDB30j+fbOOG6tVzq7omTJjj/+oHDhEAYN7E/t2CjuGDSQ06dPezWDp6cefYjnXh6Cn98/Z90Vy5YSUqQI5StUzOCd3jHp+2/p0MUq8IcOHaRoseIAFC1WnMOHDl3srY4qERrKffc/RHiF0pQvXYJ8+fPT7MbmruXxRfv2/I9tmzdS7fro84ZP/+5rbmjwz96geTN+4MY2nbwVD4C9exMICyuZ/jw0NIyEhASvZrgYEaHtTS2oExfDJx9/6HYc19vLJwosVuF7197KjQH22MMrAu8ZY6oBx4DMVhfPGmPqGWO+AuKB3vYW8hkgEthgjNnB+VvQS4CRwBfGmJrA18Bwj88sAzQEWgOjRSRbdlYF+PlRpXhexq/eTddRqziTlMqABmUBGP7j7zQbuoTpG/bRq3ZJe3whsnRBHpvwC7d8tIamVYsQV857a/spqSmsX/cTAwcNZuWan8idOzdvvvGa16bvafbM6RQOCSEiMjrD17+fMI5OXXt4OdXfkpKSmDNjGu06eHerJiuOHj3KtGlT2LTlD7bvTCDx9Gm+GfuV27F8RuLpUzx1T1/uffJVcufJlz58zPtv4e8fQPN2Xc8bf9OGeHIGB1Ou0tV1NV6ujLpyfemm5PMWLmXF6rVMmjqDD98fxdIli13N43Z7+UqBXQE8KSKPAaXtwgiwwxiz3n68FqvoZWT8RT67JTAzk9duAMbaj78E6nm89q0x5pwxZhvwBxDu+UYRuV1E4kUkPjXx+EUmf779J85y4MRf/LznBABzNh2gaom8540zfeN+mlUrCsCBE2eJ33GUY4nJnE0+x5Kth/8xvpNCQ8MIDQujVq04ADp26sL69Vnf55SdVq9czqwZ04isWoHb+/Vm6aIFDB5wCwApKSlMnzKJjp27XuJTnDN/7ixqXB9JSBHrfxcSUoQD+/cBcGD/PgqHhLiWbcH8HylTpgwhISEEBgbSrkNHVq3I1kMRrlkpyck8dU9fmrftQqMWbdOHz/j+G5YtmM1zb33wj4Xyj9O/p1lr769IhYaGsWfP7vTnCQl7KFHCN7r6gfQsRYoUoW37DsSvWe1qHrfby5UCKyId7W7a9SISY4wZC7QDzgCzRaSJPepfHm9LJfOjni/WZ9kcmJPFaCaTx/94boz50BgTY4yJ8c+VP4sfD0dOJbH/+FnKFM4FQO3y1/H7wdOUKpQrfZzG4SHsOGT9Scu2HaFSsTzkDPTD30+IKVuQ3w96r4u2WLFihIWVZOsW6yjdBfPnUaVKFa9N39MzL7zCz1t3sm7zdj78/GvqNWzM6E++AGDRgnlUqFSZEqFhrmQD+GHi+PTuYYDmrdry7dgvAfh27Je0uKltZm91XMmSpVizahWJiYkYY1i4YD6Vw935P/oSYwxDnryX0uUr0aP/XenDVy7+ka8/epfXR48lZ3Cu895z7tw5FsycTLPW3u0eBoiJjWX79m3s3LGDpKQkJowfR+s27byeIyOnT5/m5MmT6Y/n/TiXqtX+cYyqV7ndXq6cpmOM+QH4Ie25iJQD/jDGDLcf18TaarwSJ4G89ufmBwKMMUc8XsvnMe5yoAfW1mtvYKnHa11FZAxQFusI5C1XmOcfXp32G693rUGgv7D7zzM88/0mXuhYlTKFc2OMYe+xs7w4+VcATpxN4Ytluxg3OA4DLNl6mMVbD2dXlCx5653h3Nr3ZpKTkihTthwffPypV6efFT9MHO/qwU2JiYksXjCPocNGpQ+758FHuL1vL8Z++TmhYSX5aMw3ruWLrRVHh06dqRsXjX9AANdHRNJ/4O2u5fF0y809WbJoIYcPH6Z8mTCeefYF+vUf4JVpb1y7ilmTx1O+clX6tmsAwKAHn2HYy4+TnPQX9/ezimi1iBgeffFtANavWU5IsRKElirjlYyeAgICeOfdkbRt3YLU1FT69utP1WrVvJ4jIwcPHKBHV6u9UlJS6NajJ81btHQ1k9vt5fhpOudNTOR54JQx5s0Lhj8B3AwkA/uBXliFMP00HRF5GMhjjHleRD63X5soIjuBGGPMYXu8zsCrWFvDbwHljTHP269VAiYC54B7gN3Ap0BhrFOHbjXG/M/+/KNY+4OLAg8aY6Zl9ndd7mk63pJdp+lkt6s9Tccp2XGajhOy4zQdJ2TXaTpOyOppOt52tafpOMWbdeBy+NL+ZU9ZPU3Hq9/ctEKXwfAhwIUnCP4JVPcY502Px/08Hpe54LO+A74DEJGPgY89XtuKtXXsqQkZW2aMeSCT15RSSqmL8s1V42xijBnodgallFL/Tf/qAnulPLeQlVJKqSvhK6fpKKWUUv8qWmCVUkopB2iBVUoppRygBVYppZRygBZYpZRSygFaYJVSSikHaIFVSimlHKAFVimllHKAFlillFLKAVpglVJKKQdogVVKKaUcoNcizgZVSuRjmQ/eGu66Vm+4HSFDR2Y86naEDCWcOuN2hAzlzuHvdoQM+eGbtxIDiCxTwO0I1xRfvS3ctU63YJVSSikHaIFVSimlHKAFVimllHKAFlillFLKAVpglVJKKQdogVVKKaUcoAVWKaWUcoAWWKWUUsoBWmCVUkopB2iBVUoppRygBVYppZRygBZYpZRSygFaYJVSSikHaIFVSimlHKAF1occO3aMXt27ElG9CpE1qrJq5QqvTv+ezjGs/XgA8R/1Z8yTbckR6M+z/eqz+sNbWTm6H1Nf60bxQnnSx3+4Z21+GXM7Gz4bSLOYsl7NCjDi3XeIiahOTGQN+vbpxdmzZ7027SfuH0ztaqVp3TAmfdiw11+kbeNatGtam1u7t+XA/n0ALFs0j47N69KmUSwdm9dlxdKFXsl4x+0DKFuyGLWiap43fPSokUTWqEJsZA2efvIxr2S5mDmzZ1GzWmWqhVdg6BuvuR3nPKmpqdSOjaJTh7ZuR0nni+21e/duWjRrTESNKkRdX42Rw991O1I6N7OJMcZrE7scIlIImGc/LQakAofs57WMMUmuBMtAVHSMWbZyzVV/zm39+1GnXj1u7T+QpKQkEhMTKVCgwBV/3uXcD7ZEoTzMG9abyAGfcDYpha+eac+sVb8zeelWTiZaTX1nh2jCSxfi3nfnEF6qEGOeakf9u7+geKE8zHijOzX6fcS5c5een7LjfrB7ExJo1rg+azdsIjg4mD69utO8ZSv63NLvij8z4WjW7we7ZsVScuXOzaP33Mb0RfEAnDp5gjx58wHwxcej2L71N158Yzibf15PoZCiFC1WnK2/bqJ/z/YsXb89y9MqXiDn5f0htqVLFpMnTx5uH9CP1T9tBGDxwgUMfX0IEydNJUeOHBw6eJCQIkWu6PMD/K9+/Tw1NZUaVSsxfeZcQsPCqFc7ljFffUOVqlWv6nOza7k2fNjb/LR2LSdOnuD7SVOv+vOu9r6rTrXX1dq3bx/79+0jMiqKkydPUicumm8nTnI9l1PZggNlrTEm5lLj+ewWrDHmiDEmwhgTAYwG3kl7boxJEhGv3ixeRBy96/WJEydYunQx/W4dAEBQUNBVFdcrEeDvR3COAPz9hOAcAew7ciq9uALkCg4kbbHVpm5FJiz8laTkVHbtP87ve48RW7m4V/OmpKZw5swZUlJSSExMpHjxEl6bduwN9chf4LrzhqUVV4DExNOIfUPyqjUiKFrMapuK4VVJ+usvkv76y/GM9eo3oGDB8zN+/NFoHnz4UXLkyAFwxcU1u6xZvZry5StQtlw5goKC6Nq9B9OmTnY1U5o9e/Ywa+YM+vUf4HaUdL7aXsWLFycyKgqAvHnzEh5ehb17E1xOZXEzm88W2IyIyOci8raILABeF5EIEVkpIhtF5AcRKWiPt1BEYuzHhUVkp/24moisFpH19nsq2sNv9hj+QVoxFZFTIvKiiKwCbnDyb9vxxx8ULhzCoIH9qR0bxR2DBnL69GknJ3mevUdOMWzCaraOvYMd397NidN/MW/tTgCev7U+28beQY8mVXnp8yUAhBbKw56DJ9Lfn3DoJCUK5/Va3hKhodx3/0OEVyhN+dIlyJc/P81ubO616Wfm7SHP0yCqElO/G899jz79j9dnT5tEleo1CbILnLdt37aN5cuW0rj+DbRs1pi18Vff83I19u5NICysZPrz0NAwEhJ8Y8H86EMP8PKQ1/Hz853FpC+3V5pdO3eyfv06YmvFuR3lH7ydzXfmnKyrBDQzxjwEfAE8ZoypCfwMPHeJ9w4G3rW3imOAPSJSBegO1LWHpwK97fFzA78YY+KMMUuz/S/xkJKawvp1PzFw0GBWrvmJ3Llz86YX968UyJODNnUqUuXm0ZTr/h65cwbSo6nVhfL8Z0uo2Ot9xs3fzOD20dYbMujqMnhvd8PRo0eZNm0Km7b8wfadCSSePs03Y7/y2vQz8+ATz7P4p6207dydLz/94LzXtv22maEvP8NLQ0e4lA5SUlI4duwo8xcv5+Uhr9O3d49s6069EhlN+2q7UbPDjOnTCCkSQlRUtNtRzuOr7ZXm1KlT9OzWmaFvDSNfvnyXfoMXuZHtWiywE4wxqSKSHyhgjFlkDx8DNLjEe1cAT4rIY0BpY8wZoCkQDawRkfX283L2+KnAdxl9kIjcLiLxIhJ/+PChjEa5LKGhYYSGhVHLXrPq2KkL69evu+rPzaomUWXYuf84h4+fISX1HJOWbqV2tdDzxvl23mY61K8EQMLhk4QV+XsmDQ3Jy77Dp7yWd8H8HylTpgwhISEEBgbSrkNHVq1Y7rXpX0rbjt2ZM31S+vP9exO4q39P3hjxEaXKlMv8jQ4LDQ2lXfuOiAgxsbXw8/Pj8OHDLuYJY8+e3enPExL2UKKE97r6M7Ny+TKmT5tKeMWy3HJzTxYtmE//vn3cjuWz7QWQnJxMz26d6d6zNx06dnI7znncynYtFtis9Jum8Pffln6EiDFmLNAOOAPMFpEmgABjPPbvVjbGPG+/5awxJjWjCRhjPjTGxBhjYgoXDrnSvyVdsWLFCAsrydYtWwBYMH8eVapUuerPzardB09Qq0oJgnNYu7YbR5Zmy/+OUD60YPo4retUYOvuPwGYvnw7XRtVISjQn9LF8lMhtCBrtuzzWt6SJUuxZtUqEhMTMcawcMF8Kod7r70ysvOPvw9cmjd7OuUqVAbgxPFj3HZzJx568gWiazm6p+GS2rRrz6KFCwDYtm0rSUlJFC5c2LU8MbGxbN++jZ07dpCUlMSE8eNo3aada3nSvPjKELbv2M1v23bwxVff0LBxEz4d86XbsXy2vYwxDL5tAJXDq3DfAw+6Hec8bmbz6oFC2ckYc1xEjopIfWPMEqAPkLY1uxNrq3Q10CXtPSJSDvjDGDPcflwTmANMFpF3jDEHReQ6IK8xZpc3/x6At94Zzq19byY5KYkyZcvxwcefem3aa37bxw+Lt7Di/X6kpJ5jw/YDfDJ9A2OebEvFsOs4Zwz/O3CCe4fNBuDXXYf5btFvrPtkACmp57h/+NwsHUGcXWJrxdGhU2fqxkXjHxDA9RGR9B94u9em/8DgvqxevoSjfx6hfmRF7n3kaRbNm82O7Vvx8/OjRFgpXnhjOABfffoB/9vxB++98xrvvWN1+382bgqFQpw9wOjWPr1YsmQRRw4fpnL5Ujz59HP06dufO28fQK2omgQFBfHBx5+52sUYEBDAO++OpG3rFqSmptK3X3+qVqvmWh5f56vttXzZMsZ+/SXVq9cgLjoCgBdefpWWrW5yNxjuZvPZ03Q8icjzwCmgOjDNGDPRHh6BdYRxLuAP4FZjzFERCQe+td8zH7jZGFNGRJ4AbgaSgf1AL2PMnyLSHXgCa6s3GbjLGLNSRE4ZY/JwCdl1mk52u5zTdLwpO07TccLlnKbjTVd6mo7TsuM0Haf46nLNl/aXqiuX1dN0roktWI8u2wuHrwdqZzD8N6yt0zRP28OHAEMyGH88MD6D4ZcsrkoppVRGfHcVVCmllLqGaYFVSimlHKAFVimllHKAFlillFLKAVpglVJKKQdogVVKKaUcoAVWKaWUcoAWWKWUUsoBWmCVUkopB2iBVUoppRygBVYppZRygBZYpZRSygFaYJVSSikHXBN301FX5uisx9yOkKGCrd9yO0KGjkz1rRtFpzlyKsntCBkKyZfD7QiZOnk2xe0IGcoXHOh2hAzp7f2coVuwSimllAO0wCqllFIO0AKrlFJKOUALrFJKKeUALbBKKaWUA7TAKqWUUg7QAquUUko5QAusUkop5QAtsEoppZQDtMAqpZRSDtACq5RSSjlAC6xSSinlAC2wSimllAO0wCqllFIO0ALrI7Zu2UJcTGT6T9FC+Rk5fJjbsdi9ezctmjUmokYVoq6vxsjh73o9wz0do1j7YV/iP+jLmMdbkyPQn071K7H2w76cnvkgURWLpo8bGODHBw+1YM3oW1j1fh/q1wxzPN/g2/tTOqwoMZE10of9+eeftGnVnJpVK9GmVXOOHj3qeI6MfPLBSJrVjaJpnUg+Hj0CgDdffZ7m9WNo2bAWvTu3Zv++va5kSzNn9ixqVqtMtfAKDH3jNVezHD92jAF9ulM3ujr1YmqwZtVKXnj6cepGV6fRDVH069WF48eOuZrRl9rLk68uw9xsL58qsCKSKiLrReQXEZkgIrkuMf5CEYmxH+8UkcLeSZr9KlWuzKr4dayKX8fyVfEE58pFu/Yd3Y5FQEAAr73xFut//pVFS1fywej3+HXzZq9Nv0ShPNzZIYq6d39NzKAx+PsLXRuFs2nnYXq8OIWlP+85b/z+rWoCEDv4C9o8PpHXbm+E07eUvLlPPyZNnXnesLeGvkajJk3YuHkrjZo04a2h3l8Qbvl1E9988SlT5y5l9uI1zJs9gx2/b2fQ3Q8yZ0k8sxatpmnzm3j3zVe9ni1Namoq9997F5OnzmTdxs1MGPeNV+evCz392IM0btaCZWt/Yf7ytVSqHE7Dxk1ZtGo9C1f8RPkKFRn+9uuu5fO19vLki8swt9vLpwoscMYYE2GMqQ4kAYPdDgQgFq+11YL58yhXrjylSpf21iQzVbx4cSKjogDImzcv4eFV2Ls3wasZAvz9CM4RgL+fEJwjgH1HTrFl959s2/PPrcLwUoVYsO5/ABw6fobjp84SXamYo/nq1W/AdQWvO2/Y9KlT6H1zXwB639yXaVMmO5ohI9u2/kZUTC2Cc+UiICCA2nXrM2v6ZPLmy5c+TmLiaQT3bmq9ZvVqypevQNly5QgKCqJr9x5Mm+r9tgI4eeIEK5YvpfcttwIQFBRE/gIFaNT0RgICAgCIjo1jb4J3539PvtReF+MryzC328vXCqynJUAFEWkkItPSBorISBHpd7E3isiD9lbwLyJyvz3sdRG502Oc50XkIfvxIyKyRkQ2isgL9rAyIvKriIwCfgJKZvtfmIkJ346ja/ce3ppclu3auZP169cRWyvOa9Pce+QUwyauYeuXt7Hjm8GcOJ3EvJ92ZTr+z38cpO0N5fH3E0oXzUdkxaKEheT1Wt40Bw8eoHjx4oC1knLo0EGvZ6gcXo1VK5Zy9M8jnElMZMHc2exLsLb433j5WeJqlGfSxHE89MSzXs+WZu/eBMLC/v5qhYaGkeBSAdu18w8KFSrMfXcMpGm9WB64exCnT58+b5yxX35O0xtbuJIPfKu9LsZXlmFut5dPFlgRCQBaAT9fwXujgVuBOKA2cJuIRALjgO4eo3YDJohIc6AiUAuIAKJFpIE9TmXgC2NMpDEm86V6NkpKSmLGtKl06tzVG5PLslOnTtGzW2eGvjWMfB5bQE4rkCcHbW6oQJW+H1Ou1wfkzhlIjyZVMh1/zOxfSDh8imUjb2boHY1ZuXkvKannvJbXl1SsHM4d9z5E786t6dOtLVWq18Df3hJ79OkXWfXz73To0oPPP37ftYzGmH8ME6f79DORkpLKzxvW0XfAIOYtXUOuXLkZ8fYb6a+/M3QIAQEBdO7ey5V84FvtlRlfWoa53V6+VmCDRWQ9EA/8D/jkCj6jHvCDMea0MeYU8D1Q3xizDigiIiVE5HrgqDHmf0Bz+2cd1pZqOFbBBdhljFmZ0URE5HYRiReR+MOHD11BzIzNnjWTiMgoihYteumRvSQ5OZme3TrTvWdvOnTs5NVpN4kszc79xzl8/AwpqeeYtGwbtauWyHT81HOGRz9YSO07v6Tb85MpkCcn2xO8f4BRkSJF2bdvHwD79u0jJKSI1zMA9Lj5VmYsWMnEafMoUKAgZctVOO/1Dl26M3PqJFeygbVFsWfP7vTnCQl7KFEi8/+vk0qEhlIiNIzo2FoAtO3QiZ83rAdg/NdfMHfWDEZ9/IWrBc2X2iszvrQMc7u9fK3Apu2DjTDG3GOMSQJSOD9nzkt8xsXm/olAF6wt2XEe4w/xmG4FY0xaYT+d0YcAGGM+NMbEGGNiChcOuUSkrJsw3je6VtIYYxh82wAqh1fhvgce9Pr0dx88Qa0qxQnOYW15NY4oxZb//Znp+ME5Ashlj9skqjQpqef47SLjO+WmNm35+qsxAHz91Rhat23n9QwAh+2u6YQ9/2PWtMm069yNHb9vT3997szplK9Y2ZVsADGxsWzfvo2dO3aQlJTEhPHjaN3GnbYqUrQYJULD2L5tCwBLFs6nUngV5s+dzchhb/LF+O/Jleuix106zpfaKzO+tAxzu70CvDalK7cLqCoiObCKa1Ng6UXGXwx8LiKvYRXPjkAf+7VxwEdAYaChPWw28JKIfG2MOSUioUBy9v8Zl5aYmMj8eXMZMWq0G5PP0PJlyxj79ZdUr16DuOgIAF54+VVatrrJK9Nfs2U/PyzZxor3+pCSeo4N2w/yycyNtKtTgbfvbELh/MF8/1JHNv5+iHZPfUdIgVxMfaUz54xh75FTDHhjhuMZ+/bpxZLFCzly+DAVy5Xk6Wee56FHHqdPr+588dmnhJUsxVfffOt4jowM6teDo3/+SWBgIC+9MYwCBQry2H138Pv2rfj5+RFashRD3hzhSjawjlJ/592RtG3dgtTUVPr260/VatVcy/Pq0He4c2BfkpKSKF2mLO+O+pgWjeqQlPQX3dq3AqwDnYYOe8+VfL7WXhfytWWY2+0lGfVRu0VEThlj8mQw/A2gPbAN6+jiKcaYz0VkIfCwMSZeRHYCMcaYwyLyINDffvvHxphhHp/1M3DYGNPYY9h9wED76SngZiAVmGYf0XxRUdExZtnKNZf99zrN1/bNpCnY+i23I2ToyFTvb6FnxZFTSW5HyFBIvhxuR8jUiTOurCNfUr7gQLcjZMiX6oAnX12GBQfKWmNMzKXG86kt2IyKqz38UeDRDIY38nhcxuPx28DbmXxWjQyGvQtkdAWFSxZXpZRSKiO+tg9WKaWU+lfQAquUUko5QAusUkop5QAtsEoppZQDtMAqpZRSDtACq5RSSjlAC6xSSinlAC2wSimllAO0wCqllFIO0AKrlFJKOUALrFJKKeUALbBKKaWUA7TAKqWUUg7wqbvpXKsMkJzqe7d7CvDR1acDkx9wO0KGCjV60u0IGdr348tuR7jmBPnqzK/+U3QuVEoppRygBVYppZRygBZYpZRSygFaYJVSSikHaIFVSimlHKAFVimllHKAFlillFLKAVpglVJKKQdogVVKKaUcoAVWKaWUcoAWWKWUUsoBWmCVUkopB2iBVUoppRygBVYppZRygBZYF+3ZvZs2LZoSG1GNuKgavD9yePprH4waSXTNKsRF1eCZJx9zMSWMePcdYiKqExNZg759enH27FlXcmTWXkNefoHwciWpFxdFvbgo5sya4ZU893Svy9qv7if+q/sY80IPcgRZd3+8o8sNbPjmQdZ+dT+v3NnyvPeULJqfQz8+z/096zue7+zZszRtUJt6cVHcEFOTIS8/n/7ah++PJDaiKjfE1OTZp9ydv+bMnkXNapWpFl6BoW+85lqOs2fP0rS+3V7RNRny0vMAvPbyC1QtX4r6cdHUj4v22vyVGV9pr4ykpqZSOzaKTh3auh0l3e7du2nRrDERNaoQdX01Rg5/12vTvqbvBysiqcDPQCCQAowBhhljzrkaLIsCAgJ4+bWhRERGcfLkSRrWiaVx02YcPHiA6dOmsHzNenLkyMGhgwddy7g3IYH33xvB2g2bCA4Opk+v7kz4dhx9bunn9SyZtRfAnffcz70PPOS1LCUK5+POrnWI7PUOZ5NS+OqlnnRtVpP/7T9Gm/pVib3lXZKSUwkpmPu8971xbxvmrNzqlYw5cuRg8owfyZMnD8nJybRq1oBmzVty9swZZkybwtJV61yfv1JTU7n/3ruYPnMuoWFh1KsdS5s27ahStarXs+TIkYPJMz3aq2kDmrWwVpDuuOc+7rnfe/NXZnypvTLy3oh3CQ+vwomTJ9yOki4gIIDX3niLyChruVEnLpqmzW70Sptd61uwZ4wxEcaYasCNwE3AcxeOJCI+uSJRrHhxIiKjAMibNy+Vw8PZuzeBTz4czQMPP0qOHDkACClSxM2YpKSmcObMGVJSUkhMTKR48RKu5MisvdwS4O9HcI5A/P39CM4ZxL7DJ7m9YxxvfrmQpORUAA4dPZ0+ftsGVdmx90827zjglXwiQp48eQBITk4mOTkFEeHTjz/g/od8Y/5as3o15ctXoGy5cgQFBdG1ew+mTZ3sSpYM2wtxJUtmfKm9LrRnzx5mzZxBv/4D3I5ynuLFixMZ9fdyIzy8iteWG9d6gU1njDkI3A7cLZZ+IjJBRKYCc0Qkt4h8KiJrRGSdiLQHEJFqIrJaRNaLyEYRqWiPO11ENojILyLS3en8u3btZOP69cTExvH79m2sWLaUJvVv4KYbG7M2fo3Tk89UidBQ7rv/IcIrlKZ86RLky5+fZjc2dy1PGs/2Avho9HvUiY3grkEDOHr0qOPT33v4BMO+WcLWHx5jx5QnOHHqLPNWb6NCycLUvb4siz+6kznv3UZ0lTAAcuUM5KGbG/LKp/Mcz+YpNTWV+rWjqVSmOI2aNCUmNo7t27axYvlSmjW8gdYtGvPTWvfmr717EwgLK5n+PDQ0jIQE91aaUlNTqR8XTaXSxWnUtCkxtdLmr1HUrRXJ3YMGcswL81dmfK29PD360AO8POR1/Px8t6zs2rmT9evXEWv/X53muy1xBYwxf2D9TWmr5DcAfY0xTYCngPnGmFigMTBURHIDg4F3jTERQAywB2gJ7DXGXG+MqQ7McjL3qVOn6NOzK0OGvk2+fPlISUnh2NGjzFu8nJdefZ1+N/fAGONkhEwdPXqUadOmsGnLH2zfmUDi6dN8M/YrV7KkubC9Btw2mPWbt7F01U8ULVacpx9/2PEMBfLmpE39qlTpMpRy7YaQOziQHi0iCAjwo2C+YBrcNoonR87kq5d6AvDMwGaMGLeU02eSHM/myd/fnyUr17Jp6y5+WruGzZt+seavY8eYu3A5L77yOrf26ena/JXRdEXc22r09/dnyaq1bNq2i5/irfbqf9tg1m3aypKVaylarBhPP/6Ia/l8rb3SzJg+jZAiIURFRbsdJVOnTp2iZ7fODH1rGPny5fPKNP9VBdbmObfNNcb8aT9uDjwuIuuBhUBOoBSwAnhSRB4DShtjzmDt120mIq+LSH1jzPF/TETkdhGJF5H4I4cOXXHY5ORk+vTsQrfuvWjXoRNgbTW27dARESE6thZ+fn4cOXz4iqdxNRbM/5EyZcoQEhJCYGAg7Tp0ZNWK5a5kgYzbq0jRovj7++Pn50ff/gO9ssXfJKYCO/f+yeFjp0lJPcekhZuoXaM0CQdPMGnhLwDE/7qHc8ZQuEBuYquW5JW7WvHbd49yd7e6PNK3EYM73+B4zjT5CxSgXv2GzJs7m9DQUNq262DNXzHuzl+hoWHs2bM7/XlCwh5KlHBnF4Qnz/b6x/zl4ha/r7bXyuXLmD5tKuEVy3LLzT1ZtGA+/fv2cTtWuuTkZHp260z3nr3p0LGT16b7ryqwIlIOSAXSjto47fky0NneZxthjClljPnVGDMWaAecAWaLSBNjzFYgGqvQDhGRZy+cljHmQ2NMjDEmplBIyBXlNcZw9+CBVK5chbvveyB9eOu27Vm8cAEA27dtJTkpiUKFC1/RNK5WyZKlWLNqFYmJiRhjWLhgPpXDq7iSJbP22r9vX/rjaZMnUaVqNcez7D5wnFrVShGcIxCAxjEV2LLzIFMXb6JRdHkAKpQsTFCAP4ePnabZnR8S3vkNwju/wchvlzF0zEJGf7fC0YyHDx3i+LFjAJw5c4aFC+ZRsXJlbmrbnsWL/p6/klycv2JiY9m+fRs7d+wgKSmJCePH0bpNO1eyZNhelSqfP39N8c78lRlfai9PL74yhO07dvPbth188dU3NGzchE/HfOl2LMBabgy+bQCVw6tw3wMPenXaPnnwz5UQkRBgNDDSGGMy6DaZDdwjIvfYr0caY9bZRfkPY8xw+3FNEfkN+NMY85WInAL6OZF55fJljBv7FdWq16BenLUT/tkXXqZP3/7cNWgAtaNrEhgUxPsff+ZaN1BsrTg6dOpM3bho/AMCuD4ikv4Db3clS2btNfHbcfy8cQMiQqnSpRk2YrTjWdZs3s0PC35hxed3k5J6jg1b9/HJ5NUYAx881Zn4r+4jKTmVgS9PcDxLZvbv38edt/cnNTWVc+fO0bFzF1q2akNSUhJ3Dx7IDTHXExQUxPsffura/BUQEMA7746kbesWpKam0rdff6pWc6eA7d+/jztv60/qObu9OnWh5U1tGDSg79/zV6nSvDPifVfygW+117Vi+bJljP36S6pXr0FcdAQAL7z8Ki1b3eT4tMWtfS/ZIYPTdL4E3jbGnBORfkCMMeZue9xgYBhQB2trdqcxpo2IPAHcDCQD+4FeQCwwFDhnD7/DGBOfWY7I6BizaNlqR/7GqxHg5/6+mYyknPPNea5ok6fcjpChfT++7HaEDOUM8nc7QqbO2kdx+5qcgb7ZZr5aB3xh/3JGggNlrTEm5lLjXdNbsMaYTOdWY8znwOcez88AgzIYbwgw5ILBs+0fpZRS6or8q/bBKqWUUr5CC6xSSinlAC2wSimllAO0wCqllFIO0AKrlFJKOUALrFJKKeUALbBKKaWUA7TAKqWUUg7QAquUUko5QAusUkop5QAtsEoppZQDtMAqpZRSDtACq5RSSjngmr6bjq8QINDfN2+r5IsOn/zL7QgZ2uujt4WrcKd795S9mD0f93A7QqZOnU1xO0KGfPd2dW4nyJiP3q0uy3QLVimllHKAFlillFLKAVpglVJKKQdogVVKKaUcoAVWKaWUcoAWWKWUUsoBWmCVUkopB2iBVUoppRygBVYppZRygBZYpZRSygFaYJVSSikHaIFVSimlHKAFVimllHKAFlillFLKAVpgfUh4xbLERtYkLiaSurVj3Y4DwNYtW4iLiUz/KVooPyOHD/Pa9B+7bxCxVUvTskFM+rAZU76nZf1oKhTNzcb1a88b/7dNP9OlVSNa1o+mVcNY/jp71mtZU1NTaXhDDD06twPg6J9/0rFNC2JqhtOxTQuOHT3qeIYKxfKy4MUW6T873u/MoOaVeLxTDRa91JIFL7ZgwsONKFYg53nvC70uFztHd+aulpUdz3ihObNnUbNaZaqFV2DoG695ffqePho1nKY3RNK0ThR3DezD2bNn2fzLRto3b0izutHc2rMTJ0+ccDWjL7WXp/dGvEtMZA1iIqp7dRlxKW6217+ywIpIMREZJyK/i8hmEZkhIpUu8zMKiMidTmXMzMy581kVv45lK9d4e9IZqlS5Mqvi17Eqfh3LV8UTnCsX7dp39Nr0O/fow2fjJp2fKbwqoz77hlo31DtveEpKCg/eOYCXhg5n1pK1jP1hFgGBgV7LOvq94VSqHJ7+fNhbr9OwURPiN/5Gw0ZNGPbW645n2L7/JI2fnU3jZ2fT9Lk5JCalMH3tHkbO+JWGz8yi8bOzmbM+gYfbVz/vfS/3imTez/scz3eh1NRU7r/3LiZPncm6jZuZMO4bft282es5APbtTeCzD99j2vzlzFv+E+dSzzHl+2955L47ePy5l/hx2VpatG7H6BFvu5IPfKu9PG3a9Aufffoxi5etYmX8embOmM72bdvcjuV6e2VaYEXkpIicsH9Oejw/KSLursJdhIgI8AOw0BhT3hhTFXgSKHqZH1UA8HqB9WUL5s+jXLnylCpd2mvTrHVDPQoUuO68YRUqhVOuwj/Xl5Ys/JHwqtWpUr0mAAWvK4S/v3ducJ2QsIe5s2bQp1//9GEzp0+lR+9bAOjR+xZmTJvilSxpGlQtys6Dp9hzJPG8G5DnyhGA8bjDdquoUHYdOsWWBO9/rdesXk358hUoW64cQUFBdO3eg2lTJ3s9R5qUlBTOnj1DSkoKZ84kUrRYcf7YtpXadeoD0KBRU2ZOneRaPl9rrzRbfvuVWnFx5MqVi4CAAOo3aMCUyT+4Hcv19sq0wBpj8hpj8tk/eT2e5zXG5PNawsvXGEg2xoxOG2CMWQ8sFZGhIvKLiPwsIt0BRCSPiMwTkZ/s4e3tt70GlBeR9SIy1BvBRYS2N7WgTlwMn3z8oTcmeVkmfDuOrt17uB0jUzt/346I0K9bO9o1vYEPvLil8eSjD/L8K6/h5/f3V+rgwQMUK14cgGLFi3Po0EGv5QHoGFeK71f+7++MnWuw4a12dLmhNK/98AsAuYL8ufemKgydtMmr2dLs3ZtAWFjJ9OehoWEkJCS4kqV4iVAG3f0AtWtWJLpKGfLmy0fDJjdSuUo15sycBsC0yd+zd+8eV/KBb7WXp6pVq7NsyRKOHDlCYmIis2fNJGHPbrdjud5eWeoiFpF6InKr/biwiJR1NtZVqQ6szWB4JyACuB5oBgwVkeLAWaCjMSYKqzi/ZW8FPw78boyJMMY84o3g8xYuZcXqtUyaOoMP3x/F0iWLvTHZLElKSmLGtKl06tzV7SiZSklJIX71ct5+/1PGT53H3BlTWLZ4gePTnT1zGiEhRYiIjHZ8WlkV6O9Hy8hQpqz5u8C++t3PXP/QFCau2MXAphUBeKxjDUbP3sLpv1Iy+yhHeW5Jp7G+ft537NhR5sycyvJ1vxG/eQeJiYl8/+1Y3hzxAWM+Hs1NjW/g9KmTBAYGuZIPfKu9PIVXqcKDDz9K25ua06FtK2rUqIl/QIDbsVxvr0sWWBF5DngMeMIeFAR85WQoh9QDvjHGpBpjDgCLgFhAgFdFZCPwIxBKFrqTReR2EYkXkfjDhw9lS8ASJUoAUKRIEdq270D8mtXZ8rnZYfasmURERlG06OX2tHtPsRKh1LqhPtcVKkxwrlw0bNaCTRvXOz7dVSuWM3P6VK6vUp6BfXuzZNECBvW/hSJFirJ/n7Vfc/++fYSEFHE8S5pmNYuzcddRDp346x+vfbdyF21iwgCIKleI57pH8NObbRnUvBL3t6nKALv4ekNoaBh7PLZ0EhL2pH8PvG3pwvmULFWGQoVDCAwMpFWb9sSvXkmFSpUZ+/10ZixYQfvO3Sldtpwr+cC32utCfW8dwPJVa5kzbxEFr7uOChW8Nx9lxu32ysoWbEegHXAawBizF8jrZKirtAnIaFMis9WW3kAIEG2MiQAOADkzGTedMeZDY0yMMSamcOGQK82a7vTp05w8eTL98bwf51K1WvVLvMt7Joz37e5hgAaNm7Fl88+cSUwkJSWF1cuXUtHjoCOnPPviq2zatosNv/7Ox2O+pn7Dxnzw6Re0vKkN477+AoBxX39Bq9ZtHc+SplPtUny/clf683JF86Q/bhkZyrZ91rzWdsg8oh6eStTDU/lgzlaGTdvMJ/O8d3BKTGws27dvY+eOHSQlJTFh/Dhat2nntel7Cg0rybr41ZxJTMQYw7LFC6hYKZzDdtf+uXPnGP7WEG7uN9CVfOBb7XWhgwetdtr9v/8xZdIPdO3e0+VE7rdXVrbhk4wxRkQMgIjkdjjT1ZqPtUV6mzHmIwARiQWOAt1FZAxwHdAAeAToDhw0xiSLSGMg7Qiek3hxReLggQP06NoJsLo6u/XoSfMWLb01+YtKTExk/ry5jBg1+tIjZ7P7BvVl1bLFHP3zCHWvr8B9jz5N/gIFefHJh/jzyGEG9upM1eo1+fzbKeQvUJD+g++lY4v6IEKjpi1ofGMrr2dOc/9Dj9G/Tw+++uIzwsJK8tlX470y3eAgfxpWK8aDn8enD3um6/VUKJaXcwb2HDnNQx6vuSkgIIB33h1J29YtSE1NpW+//lStVs2VLJExtbipXUdaNa6Nv38A1WteT6++A/jqs48Y84k177dq04Huvfu6kg98q70u1LtHF/48coSAwEDefnckBQsWdDuS6+0lGfVRnzeCyMNAReBGYAjQHxhrjBnhfLwrIyIlgGFYW7JngZ3A/cDtQCvAAC8bY8aLSGFgKhAIrAfqAq2MMTtFZCxQE5h5sf2wUdExxldOq7kW7DvmvXNTL0fB3O7tW7uYindOcDtChvZ87Ls9GodP/rNr3BcUzpvD7QgZOnfu4nXALX5+7u9fzkhwoKw1xsRcarxLbsEaY94UkRuBE0Al4FljzNxsyOgYuxu7WwYvPWL/eI57GLghk8/plf3plFJK/Rdk9TCvn4FgrC2/n52Lo5RSSv07ZOUo4oHAaqzTXLoAK0Wk/8XfpZRSSv23ZWUL9hEg0hhzBEBECgHLgU+dDKaUUkpdy7Jyms4erCNq05wE3L9Eh1JKKeXDMt2CFZEH7YcJwCoRmYy1D7Y9VpexUkoppTJxsS7itHNAf7d/0rh/ZWmllFLKx2VaYI0xL3gziFJKKfVvcsmDnEQkBHgUqIbHJQSNMU0czKWUUkpd07JykNPXwG9AWeAFrKsi6WWLlFJKqYvISoEtZIz5BOseq4uMMf2B2g7nUkoppa5pWTkPNtn+vU9EWgN7gTDnIimllFLXvqwU2JdFJD/wEDACyAc84GgqpZRS6hqXlYv9T7MfHgcaOxtHKaWU+ne42IUmRmBdWCJDxph7HUmkso2Ib97qqUTBYLcjZMhXb9nlq7eFK9j8VbcjZOronCfdjpChU2dT3I6QoXOXuG2pW4ID/d2OcFUutgXrG3dkVkoppa5BF7vQxBhvBlFKKaX+TbJymo5SSimlLpMWWKWUUsoBWmCVUkopB1yywIpIJRGZJyK/2M9risjTzkdTSimlrl1Z2YL9CHgC+4pOxpiNgG+eN6CUUkr5iKwU2FzGmAtvsO6bJ3MppZRSPiIrBfawiJTHvuiEiHQB9jmaSimllLrGZeVaxHcBHwLhIpIA7ABudjSVUkopdY3LyrWI/wCaiUhuwM8Yc9L5WEoppdS17ZIFVkSeveA5AMaYFx3KpJRSSl3zstJFfNrjcU6gDfCrM3GUUkqpf4esdBG/5flcRN4EpjiWSCmllPoXyMoW7IVyAeWyO4iC8IplyZsnL37+/gQEBLBs5Rq3I3H27FmaNW5A0l9/kZKaQsdOXXjmuRfcjsXu3bsZeOstHDiwHz8/P/oPuJ27773P7VgAjHj3HcZ89gmIUK16DT746FNy5szpaiZf+D/e0yWWfjdFYAxs2nGQ21+fxmM316VNnUqcM4ZDx05z++vT2HfkFADVy4Uw8oFW5M2dg3PnDPXu+Iy/klO9ktUX2stTVLUK5MmTJ33Z8OPiVbzx6ot8+fknFCpcGICnnnuZG1u08mqu48eO8eA9g/ht8yZEhHfe+4gZUycxZ+Y0AoOCKFO2HO+O+pj8BQp4LdOe3bsZNLBf+rKhX//buPPue3nphWeZMW0Kfn5+FA4JYfSHn1G8RAlHs4i5xH0AReRn/r4vrD8QArxojBnpaLJ/5ngK6AWkAueAQcaYVVf5mQuBh40xmd6aLyvjREXHmOwohuEVy7J0xRoK21+Yq5Ud94M1xnD69Gny5MlDcnIyTRrW48233yWudu1sSHjl9u3bx/59+4iMiuLkyZPUiYvm24mTqFK16hV/ZnbcD3ZvQgLNGtdn7YZNBAcH06dXd5q3bEWfW/pd8Wf6+fnm//Fy7gdbonAe5r17C5G3fsjZpBS+erYjs1ZtZ/KSLZxMTALgzo4xhJcuzL3DZuHvJ6z4YAADhkzh5z8Ocl2+YI6dOpvl/9HV3g/Wqfn+Su8HG1WtAnMXrUwvpgBvvPoiuXPn4a77HryqTHDl94O9Z1B/4urU4+a+/UlKSuJMYiLr1q6hXsPGBAQE8NKzTwDwzItDrujzr+R+sPv37WP//n1ERFrLhgZ1Yvnm2+8pERpGvnz5AHj/vRFs+W0zw0a8f0W58gX7rzXGxFxqvKxswbbxeJwCHDDGePVCEyJyg50jyhjzl4gUBoK8meG/SkTIkycPAMnJyaQkJ/vEjdyLFy9O8eLFAcibNy/h4VXYuzfhqgpsdklJTeHMmTMEBgaSmJhI8eLOriVnhS/8HwP8/QjOEUBySirBOQLYd+RUenEFyJUzMH1NvllsOX754yA//3EQgD9PnPFqVl9oL1938sQJVixfyvDRnwAQFBREUFAQjZremD5OdGwcUyd979VcxYoXp5jHsqFyeDh79yYQXuXvZUNi4mmv/D8veqEJEfEDphtjdtk/Cd4urrbiwGFjzF8AxpjDxpi9IvKsiKwRkV9E5EOxW0xEForI6yKyWkS2ikh9e3iwiIwTkY0iMh4I9vhb3xeReBHZJCKu9AWJCG1vakGduBg++fhDNyJkKDU1lbjoCEqVKEKTZjdSKy7O7Ujn2bVzJ+vXryO2lvu5SoSGct/9DxFeoTTlS5cgX/78NLuxuduxAHf/j3sPn2LYt6vYOu5udky8jxOn/2Je/A4Anu/fkG3j7qZHs+q89NliACqGXYfBMOX1Hiz/oD8Pdvd+j4kvzfciQtcOrWhavxZffPpR+vBPPhxFw9qR3HvHQI4dPerVTLt2/kGhQoW5746BNK0XywN3D+L06dPnjTP2y89pemMLr+bytGvXTjauX09MrPW/e/G5p6lSoTTfjhvLU884v5i/aIE1xpwDNohIKceTXNwcoKRdLEeJSEN7+EhjTKwxpjpWsfTc2g4wxtQC7gees4fdASQaY2oCrwDRHuM/ZW/y1wQaikhNB/+eDM1buJQVq9cyaeoMPnx/FEuXLPZ2hAz5+/uzau16tu/cQ/ya1Wz65Re3I6U7deoUPbt1Zuhbw9K7f9x09OhRpk2bwqYtf7B9ZwKJp0/zzdiv3I4FuPt/LJAnJ23qVqRKr1GU6zqc3DkD6dGsGgDPf7qIij1GMu7HXxjcwfpKBvj7Uad6SW59ZTJN7/2CdvUq0SiyjNfygm/N99PnLmL+0jWM+34an370PsuXLqHfwEGs2biFBcvXUrRYcZ598hGvZkpJSeXnDevoO2AQ85auIVeu3Ix4+430198ZOoSAgAA6d+/l1VxpTp06RZ+eXXlt6Nvpy4ZnX3iZX7fvoluPXnww+j3HM2TlUonFgU32HXWmpP04HcyTMeYUVjG8HTgEjBeRfkBjEVll7yduAlTzeFtav8RaoIz9uAHwlf2ZG4GNHuN3E5GfgHX251y0r1FEbre3eOMPHz50FX/d30rYO9yLFClC2/YdiF9z4SWg3VWgQAEaNGzEnDmz3I4CWF13Pbt1pnvP3nTo2MntOAAsmP8jZcqUISQkhMDAQNp16MiqFcvdjnUeN/6PTaLLsHPfMQ4fTyQl9RyTlmyhdrWw88b5dv4mOjQIByDh0EmWbPgfR06c4cxfKcxa9TuRlYp6La8nX5jvi9m7GUJCinBT2w6sW7uGIkWK4u/vj5+fH336DWDd2kwPE3FEidBQSoSGER1bC4C2HTrx84b1AIz/+gvmzprBqI+/cKVrPTk5mZt7dqFb91606/DPZUPXbj2Z4oWu66wU2BewtgxfBN7y+PEqY0yqMWahMeY54G6gNzAK6GKMqYF11x/PQzX/sn+ncv6+5n/szReRssDDQFN763b6BZ+VUZ4PjTExxpiYwoVDrvTPSnf69GlOnjyZ/njej3OpWq36VX/u1Tp06BDHjh0D4MyZM8yf9yOVK4e7GwrrIJTBtw2gcngV7nvg6g/yyC4lS5ZizapVJCYmYoxh4YL5VA6v4nYs1/+Puw+coFbVUIJzWF/FxlFl2PK/I5QPLZg+Tus6ldj6vyMAzF3zB9XLFyE4RwD+fkL960vx687DXsvrdnt5On36NKc8lg0L580lvGo19u//+5LwM6ZOIrxqtcw+whFFihajRGgY27dtAWDJwvlUCq/C/LmzGTnsTb4Y/z25cuXyaiawlg13DR5I5cpVuPu+B9KHb9++Lf3xjOlTqVSpsuNZsnKQ003GmMc8B4jI68AiZyL9k4hUBs4ZY9JaKALYgtWde1hE8gBdgImX+KjFWIV5gYhUt98PkA/rghrHRaQo0ApYmJ1/w6UcPHCAHl2tNa2UlBS69ehJ8xYtvRkhQ/v37eO2/n1JTU3lnDlH5y7duKl1m0u/0WHLly1j7NdfUr16DeKiIwB44eVXadnqJldzxdaKo0OnztSNi8Y/IIDrIyLpP/B2VzOB+//HNb/t5YdFv7HigwGkpJ5jw/b9fDJtHWOeak/FkoU4d87wv4PHufedmQAcO3WW4RNWsfT9WzEGZq/azqxVv3str9vt5enQwQP069UFsLplO3XrQdMbW3DnbX35ZeMGRISSpcrw5vBRXs/26tB3uHNgX5KSkihdpizvjvqYFo3qkJT0F93aW6cMRcfGMXSY892xaVYuX8a4sV9RrXoN6sZFAVbX8Jeff8q2bVvx8/OjZKlSDBt+ZUcQX46snKbzkzEm6oJhG+0tPa8QkWhgBFAA60jm7Vjdxfdj3Zt2J7Ab2GWMed7z1Br7iON4Y0wZEQkGPsPq/l0PVADutcf7HIgD/sDa+p1ijPncm6fpZDc96vHyZMdpOk7IjtN0nHA5p+l429WepuOUKz1Nx2lXepqO067kNB1vuOrTdETkDuBOoJyIeO6rzAssu/qIWWeMWQvUyeClp+2fC8dv5PH4MPY+WGPMGTK5Wbwxpl8mwxtlNFwppZS6mIt1EY8FZgJDgMc9hp80xvzpaCqllFLqGpdpgTXGHAeOAz29F0cppZT6d8jKUcRKKaWUukxaYJVSSikHaIFVSimlHKAFVimllHKAFlillFLKAVpglVJKKQdogVVKKaUcoAVWKaWUcoAWWKWUUsoBWmCVUkopB2iBVUoppRygBVYppZRyQFZuuK4uIfWc4cQZ37vPY75g3/z37j161u0IGcqfK9DtCBlKTEp1O0KGfPWeqwDRz81xO0KG1r7Q3O0IGUr10Xsh+/vovZCzSrdglVJKKQdogVVKKaUcoAVWKaWUcoAWWKWUUsoBWmCVUkopB2iBVUoppRygBVYppZRygBZYpZRSygFaYJVSSikHaIFVSimlHKAFVimllHKAFlillFLKAVpglVJKKQdogVVKKaUcoAXWZcePHWNAn+7Ui6lO/dgaxK9eye39etG0XgxN68UQU6MiTevFuJZv65YtxMVEpv8ULZSfkcOHeW36j983iFpVS9Oqwd9t8NoLT9K8bgStG9Xijn7dOXH8GABH/zxC744tqVk2hOefeMBrGQGiqlWgQVwEjepE06xB3Hmvvffu24TkDeTI4cNezQTw6QcjubFuFM3qRPLJ6BEAbPp5Ax2aN6BVw1q0aVKH9WvXeD2XpzmzZ1GzWmWqhVdg6BuveX36eXMG8E7P65l6f12m3FeH60vmT3+tX73SbHqlOQXsWxnmDw7kswExrHm2CU+1Dfd6VnC/vTzdcXt/yoQVJTayRvqwpx5/hMgaVYiLvp4eXTtx7Ngx9wLibnv9KwusiDwlIptEZKOIrBeROBHZKSKFMxi3nYg8nsnnNBKROk5mffrxB2nSrAVL439h3rK1VKwUzoefj2Xe0njmLY2ndbuO3NS2g5MRLqpS5cqsil/Hqvh1LF8VT3CuXLRr39Fr0+/Uow+fjpt03rC6DZswY1E80xeupmz5iowe/iYAOXLk5IHHn+Xx51/1Wj5PP0z/kYXL1/Lj4lXpwxL27Gbhgh8JK1nK63m2/LqJb774lClzlzJr8RrmzZ7Bjt+3M+T5J7nv0aeYuWg1Dz7xLENecO++rqmpqdx/711MnjqTdRs3M2HcN/y6ebNXMzzROpyl2w7TdtgyOo9cwR+HTgNQLH8O6lQoxN6jZ9LHTUo5x4gftzN01lavZkzjC+3lqXeffkyaOvO8YU2a3siadT+zau0GKlasyFtvDHEpnfvt9a8rsCJyA9AGiDLG1ASaAbszG98YM8UY84/VGhEJABoBjhXYkydOsHLZUnrdcisAQUFB5C9QwDMbU3+YSMcu3Z2KcFkWzJ9HuXLlKVW6tNemWeuGehQocN15w+o3akZAgHUz+YjoWPbvTQAgV+7cxMTVIUeOnF7LdylPP/4wz700BBHv3zh6+9bfiIypRXCuXAQEBBBXtz6zp09GRDh18gQAJ08cp0ix4l7PlmbN6tWUL1+BsuXKERQURNfuPZg2dbLXpp87hz/RZQryXbw1DyWnGk6eTQHgsZvCeWvWVjxvRX4mOZWfdh0jKfmc1zJ6cru9LlSvfgMKFjz/+9n0xubp38/YuNokJCS4EQ1wv73+dQUWKA4cNsb8BWCMOWyM2Wu/do+I/CQiP4tIOICI9BORkfbjz0XkbRFZAIwHBgMP2FvB9bM76K6df1CocGHuu3MgzerF8uDdgzh9+nT66yuXL6VwSBHKla+Y3ZO+IhO+HUfX7j3cjnGeCWO/oEHT5m7HQETo2qEVTevX4otPPwJg1vSpFC9Rguo1rnclU6XwaqxesZSjfx7hTGIiC+bOZm/CHp595U1efe4JatcozyvPPsFjz7zkSj6AvXsTCAsrmf48NDTMqwvkktfl4mhiEq90rsbEu2rzQseqBAf60zg8hAMnzrJl/ymvZckKt9vrcn35+Wc0b9HStem73V7/xgI7BygpIltFZJSINPR47bAxJgp4H3g4k/dXApoZYzoDo4F3jDERxpglniOJyO0iEi8i8X8eubJ9aykpqfy8YR39Bgzix6VryJU7NyPfeSP99R8mjveZrdekpCRmTJtKp85d3Y6SbtQ7rxMQEED7zu4X/elzFzF/6RrGfT+NTz96n+VLl/DOm0N4/KnnXctUsXI4g+99iN6dW3NLt7ZUrV6DgIAAvvrsQ555eSgrf/6dZ195g0fvHexaRmPMP4Z5c2vf30+oUjwv41btoct7KzmTlMqdTctze6NyjPzxd6/lyCq32+tyvPHaK/gHBNC9Z2/XMrjdXv+6AmuMOQVEA7cDh4DxItLPfvl7+/daoEwmHzHBGJOahel8aIyJMcbEXFfoH7t2s6REaCjFQ8OIiqkFQJv2ndi4YT0AKSkpzJg6ifadfKOgzZ41k4jIKIoWLep2FAC+H/8V8+fO5O1Rn/nEAqZY8RIAhIQU4aa2HVixbDH/27mTRnWiiapWgb0Je2havxYHDuz3aq4eN9/KjAUrmTBtHgUKFKRMuQp8N+4rWtn79Vu378yGn+K9mslTaGgYe/b8vQcnIWEPJUqU8Nr0Dxw/y4ETf/HznuMAzPnlAFVL5CW0YDDf33MDcx6uT9F8OZh4V20K5wnyWq7MuN1eWfX1l2OYNWM6n475ytXvp9vt9a8rsADGmFRjzEJjzHPA3UBn+6W/7N+pQEAmbz+dyfBsV6RoMUJDw9i+bQsASxbNp1LlKgAsXjiPCpUqUyI0zFtxLmrCeN/pHl40fw4fjHybD76YQHCuXG7H4fTp05w6eTL98cJ5c4mIiuHXHXv5adN2ftq0nRKhYcxbspqiRYt5NdvhQwcBSNjzP2ZNm0z7zt0oUqw4K5ctBmDZ4gWUKV/Bq5k8xcTGsn37Nnbu2EFSUhITxo+jdZt2Xpv+4VNJ7D9+ljKFrfmodvlCbN57kgZDFtL8zSU0f3MJB078RZf3VnL4VJLXcmXG7fbKirmzZ/H2m28w/rvJ5HL5++l2e2VWZK5ZIlIZOGeM2WYPigB2ATUyfVPmTgL5silahl554x3uHNiX5OQkSpcpy7D3PgZg0nff0rGzb3QPJyYmMn/eXEaMGu31ad8/qC+rli/m6J9HqBtRgfseeZrRw98kKekv+nVrA0BEdC1eGmqdgtIwJpxTJ0+SnJTE3JlT+Xz8VCraKy1OOXTwAP16dQGsbv9O3XrQ9MYWjk4zqwb368HRP/8kMDCQF98YRv4CBXl92Cief/JhUlNSyJEjJ6+9/Z5r+QICAnjn3ZG0bd2C1NRU+vbrT9Vq1bya4dVpv/F6txoE+vux588zPP3dLxcdf87D9cmTI4BAf6FJlSLc/tlafj/knfVyX2gvT/369GLJ4oUcOXyYSuVK8tQzz/PWG6/xV9JftLvJOjYitlYcw9/z/rID3G8vyaiP+lomItHACKAAkAJsx+oujgdijDGHRSQGeNMY08juPo4xxtwtIp8D04wxE+3PqgRMBM4B91y4HzbN9ZHRZs6ilc7+YVcgX7Bvrj/tPXrW7QgZym+f6+hrEpMuucfCFUXy5XA7Qqain5vjdoQMrX3B/QPyMpJ6zjfrgL+f+7t/MhIcKGuNMZe8QIFvLoGvgjFmLRmfWlPGY5x4rFNwMMZ8DnxuP+53wWdtBWo6kVMppdS/279yH6xSSinlNi2wSimllAO0wCqllFIO0AKrlFJKOUALrFJKKeUALbBKKaWUA7TAKqWUUg7QAquUUko5QAusUkop5QAtsEoppZQDtMAqpZRSDtACq5RSSjlAC6xSSinlgH/d3XTcEOAnPnurM18Uel2w2xGuKXly+ubX9K9k37yNHvjubeEKxt7tdoQMHVk1wu0IGTpxJtntCFdFt2CVUkopB2iBVUoppRygBVYppZRygBZYpZRSygFaYJVSSikHaIFVSimlHKAFVimllHKAFlillFLKAVpglVJKKQdogVVKKaUcoAVWKaWUcoAWWKWUUsoBWmCVUkopB2iBVUoppRygBdZH7N69mxbNGhNRowpR11dj5PB33Y6Ubs7sWdSsVplq4RUY+sZrbsdJp7kuj6/k2rNnN21aNqVWZHVqR9fk/feGA/Dzxg3c2KgudWIj6N65PSdOnHAtI7jfXvf0bszaiU8RP+FJxgzpR46gAGpUCmXhmIdY8+2TTBw2iLy5cwIQGODPB8/fzJpvn2TV+MepH13R63lHvPsOMRHViYmsQd8+vTh79qzXM6Q5fuwYA/p0p250derF1GDNqpW88PTj1I2uTqMboujXqwvHjx1zPIfPFVgReUpENonIRhFZLyJx2fjZjURkWnZ9XnYKCAjgtTfeYv3Pv7Jo6Uo+GP0ev27e7HYsUlNTuf/eu5g8dSbrNm5mwrhvNJfmuioB/gG8PGQoq9f9wtyFy/j4g/f57dfN3HvnIJ576VWWr1lPm3YdGP7Om67kA/fbq0RIfu7s2ZC6vd8gpuur+Pv50bVFNO8/24unh08mtturTFmwgQf6NgWgf6e6AMR2e5U2g0fy2oMdERGv5d2bkMD7741gyYo1xK/7mXOpqUz4dpzXpn+hpx97kMbNWrBs7S/MX76WSpXDadi4KYtWrWfhip8oX6Eiw99+3fEcPlVgReQGoA0QZYypCTQDdrubyiIijt71unjx4kRGRQGQN29ewsOrsHdvgpOTzJI1q1dTvnwFypYrR1BQEF2792Da1Mlux9Jc13CuYsWLExH597xeqXI4+/YmsH3bFurWawBA46bNmDr5B1fygW+0V4C/P8E5AvH39yM4ZxD7Dh2nYukiLF27HYD5K3+jQ9MIAMLLFWPB6i0AHDp6iuMnzxBdtZRX86akpnDmzBlSUlJITEykePESXp1+mpMnTrBi+VJ633IrAEFBQeQvUIBGTW8kIMBajEfHxrE3wfnlq08VWKA4cNgY8xeAMeawMWaviOwUkRdE5CcR+VlEwgFEJLeIfCoia0RknYi0t4eXEZEl9vg/iUidCyckIrH2e8qJSLSILBKRtSIyW0SK2+MsFJFXRWQRcJ+3GmHXzp2sX7+O2FrZtvF+xfbuTSAsrGT689DQMBK8MGNeiua6PL6aa9eunfy8YT3RsXFUqVqNGdOmAjDp+4kk7HFv3drt9tp76DjDvpjH1pkvsWPuK5w4dYZ5K39j8+/7aNOoBgCdbowirGhBAH7emkDbRjXw9/ejdIlCRFYtSVixgl7LWyI0lPvuf4jwCqUpX7oE+fLnp9mNzb02fU+7dv5BoUKFue+OgTStF8sDdw/i9OnT540z9svPaXpjC8ez+FqBnQOUFJGtIjJKRBp6vHbYGBMFvA88bA97CphvjIkFGgNDRSQ3cBC40R6/OzDccyJ2wR0NtMfaQh4BdDHGRAOfAq94jF7AGNPQGPPWBZ9xu4jEi0j8ocOHsuevB06dOkXPbp0Z+tYw8uXLl22fe6WMMf8Y5s2up8xorsvji7lOnTrFLT278eobb5MvXz5Gjv6Yjz8cRcM6tTh18iSBQUGuZXO7vQrkDaZNoxpUafMc5Zo/Re7gIHrcFMug579mULcGLPv6UfLkykFScioAYyavIOHAMZZ9/ShDH+nMyg07SElN9Vreo0ePMm3aFDZt+YPtOxNIPH2ab8Z+5bXpe0pJSeXnDevoO2AQ85auIVeu3Ix4+430198ZOoSAgAA6d+/leBZHuz0vlzHmlIhEA/WxCuZ4EXncfvl7+/daoJP9uDnQTkTSCm5OoBSwFxgpIhFAKlDJYzJVgA+B5vbWcXWgOjDX/gL5A/s8xh+fSdYP7c8hOjrmn9/GK5CcnEzPbp3p3rM3HTp2uvQbvCA0NIw9HlsSCQl7KFHCna4fT5rr8vharuTkZG7p1ZWuPXrSrkNHACpVDueHqbMA2L5tK3NmzXAtn9vt1SQunJ17j3D46CkAJs3fQO3ryzJuxhra3vkeABVKFaFV/WoApKae49G3vk9//4LPH2T7/7Jvxf9SFsz/kTJlyhASEgJAuw4dWbViOT173ey1DGlKhIZSIjSM6NhaALTt0IkRbw8FYPzXXzB31gwmTp3tlRUmX9uCxRiTaoxZaIx5Drgb6Gy/9Jf9O5W/VwwE6GyMibB/ShljfgUeAA4A1wMxgOeq8D7gLBDp8RmbPD6jhjHGs2/j/L4FhxhjGHzbACqHV+G+Bx70xiSzJCY2lu3bt7Fzxw6SkpKYMH4crdu0czuW5rqGcxljuPuO26hUuQp33/tA+vBDBw8CcO7cOYa+/iq3DhzkSj5wv7127/+TWjXKEpwzEIDGtSqzZccBQgrmAayt6cdva8FHE5cCEJwzkFw5rcVck7hwUlLP8dsf+72Wt2TJUqxZtYrExESMMSxcMJ/K4VW8Nn1PRYoWo0RoGNu3WfuklyycT6XwKsyfO5uRw97ki/HfkytXLq9k8aktWBGpDJwzxmyzB0UAu4AambxlNnCPiNxjjDEiEmmMWQfkB/YYY86JSF+srdI0x4ABwBwROQ0sB0JE5AZjzAoRCQQqGWM2ZfsfeBHLly1j7NdfUr16DeKiIwB44eVXadnqJm/G+IeAgADeeXckbVu3IDU1lb79+lO1WjVXM2muazvXyhXLGD/2K6pWr0G9uGgAnn3hJX7/fTsff/A+AG3bd+DmW/q5kg/cb681v+zihx/XsWLsY6SknmPDb3v45Ltl3NalHoO6WweCTZ6/ni8mrwQgpGBepo66i3PnDHsPHWPA02O8lhUgtlYcHTp1pm5cNP4BAVwfEUn/gbd7NYOnV4e+w50D+5KUlETpMmV5d9THtGhUh6Skv+jWvhVgHeg0dNh7juaQjPY1uMXuHh4BFABSgO3A7UA8EGOMOSwiMcCbxphGIhIMDAPqYG2J7jTGtBGRisB3QCKwALjHGJNHRBoBD9vjlAJmAv2xto6HYxXmAGCYMeYjEVlojx9/sdzR0TFm2aqLjqLUv85fyd7bx3e5cgT6X3okFxSMvdvtCBk6smqE2xEydOqvFLcjZKhovqC1xpiYS43nUwX2WqUFVv0XaYG9fFpgL8+1XmB9bh+sUkop9W+gBVYppZRygBZYpZRSygFaYJVSSikHaIFVSimlHKAFVimllHKAFlillFLKAVpglVJKKQdogVVKKaUcoAVWKaWUcoAWWKWUUsoBWmCVUkopB2iBVUoppRzgU/eDvVYZrJtI+xoRcTtChlJSz7kdIUO+2l6+KijAd9fPz/ronX7+XO2bd625rtY9bkfI0NE1I92OcFV89xuilFJKXcO0wCqllFIO0AKrlFJKOUALrFJKKeUALbBKKaWUA7TAKqWUUg7QAquUUko5QAusUkop5QAtsEoppZQDtMAqpZRSDtACq5RSSjlAC6xSSinlAC2wSimllAO0wCqllFIO0ALrI7Zu2UJcTGT6T9FC+Rk5fJjbsdi9ezctmjUmokYVoq6vxsjh77qW5Y7bB1C2ZDFqRdVMH7Zxw3oaN6hDnVpRNKhTi/g1q13I1Z8yYUWJjazxj9fefftN8uTw4/Dhw5orE+EVyxIbWZO4mEjq1o51LcfZs2dpWr829eKiuCG6JkNeeh6A115+garlS1E/Lpr6cdHMmTXDtYy+sJy4p3dj1k58ivgJTzJmSD9yBAVQo1IoC8c8xJpvn2TisEHkzZ0TgB6tYlg57vH0n9Nrh1OzUqhX8w4a2J9SJYoQHVHdq9MFEF+8j2l2EpFU4GdAgFTgbmPM8uycRlR0jFm2ck22fV5qairly4SxeOlKSpUufcWfkx33N923bx/79+0jMiqKkydPUicumm8nTqJK1apX/JlXej/YpUsWkydPHm4f0I/VP20EoH3rFtx17/00b9GK2bNmMOytN5k5d/4Vff6Vtldartv692XNup/Th+/ZvZu7Bt/G1q2/sWRFPIULF76iz79STufyy6bb54ZXLMvSFWuytX3+Srn8ecwYw+nTp8mTJw/Jycm0atqAIW++w7w5s8mdJw/33P/QVefKkY330M2u5QRk/X6wJULyM++zB4js/Apn/0rmq9f7M2vpJgZ3b8Dj7/zA0rXbuaV9bcqEFuLFUdPPe2+1CiWY8M7tVG37fJZzZcf9YJcuWUzu3HkY2P8W1q7/5ao/DyA4UNYaY2IuNd5/YQv2jDEmwhhzPfAEMMTtQJeyYP48ypUrf9VfmuxQvHhxIqOiAMibNy/h4VXYuzfBlSz16jegYMHrzhsmIpw8cQKAE8ePU7x4cZ/IBfDYIw/y8pDXXbuRu6/m8lUiQp48eQBITk4mOTkFwXfbyK3lRIC/P8E5AvH39yM4ZxD7Dh2nYukiLF27HYD5K3+jQ9OIf7yvW8tovp211qtZwfoeXHfdP78H3vBfKLCe8gFHAUQkj4jME5GfRORnEWmfNpKIPCMiv4nIXBH5RkQe9mbICd+Oo2v3Ht6cZJbs2rmT9evXEVsrzu0o6V578x2efuIxwsuX5qknHuX5l151OxIA06dOoUSJEtSoeb3bUc7ji7lEhLY3taBOXAyffPyhq1lSU1OpHxdNpdLFadS0KTH2vP7R6FHUrRXJ3YMGcuzoUVczpnFjObH30HGGfTGPrTNfYsfcVzhx6gzzVv7G5t/30aaRtSui041RhBUt+I/3dmkexbez4r2a123/hQIbLCLrReQ34GPgJXv4WaCjMSYKaAy8JZYYoDMQCXQCMuwGEJHbRSReROIPHz6UbWGTkpKYMW0qnTp3zbbPzA6nTp2iZ7fODH1rGPny5XM7TrpPPhzNa0Pf4rffd/HaG29x1+Db3I5EYmIiQ19/laefe9HtKOfx1VzzFi5lxeq1TJo6gw/fH8XSJYtdy+Lv78+SVWvZtG0XP8WvYfOmX+h/22DWbdrKkpVrKVqsGE8//ohr+dK4tZwokDeYNo1qUKXNc5Rr/hS5g4PocVMsg57/mkHdGrDs60fJkysHScmp570vtnppEs8ms/n3fV7N67b/QoFN6yIOB1oCX4jVNybAqyKyEfgRCAWKAvWAycaYM8aYk8DUjD7UGPOhMSbGGBNTuHBItoWdPWsmEZFRFC1aNNs+82olJyfTs1tnuvfsTYeOndyOc56xX31Buw5Wpo6du7I23vsHOV3ojz9+Z+fOHdwQG0HVSmVJ2LOHerWjObB/v+bKQIkSJQAoUqQIbdt3cOVAtQvlL1CAevUbMm/ubIoULYq/vz9+fn707T+QtWuz73iLK+XWcqJJXDg79x7h8NFTpKScY9L8DdS+vixbdx6g7Z3vUbf3G3w7ay079py/0dG1RfR/busV/hsFNp0xZgVQGAgBetu/o40xEcABICe4u9Nlwnjf6h42xjD4tgFUDq/CfQ886HacfyhWvARLFy8CYNGC+ZSvUNHlRFC9eg127jnA5q072Lx1B6FhYSy1t3401/lOnz7NyZMn0x/P+3EuVat5/2hPgMOHDnH82DEAzpw5w8IF86hYqTL79/291TVtyiSqVK3mSj5Pbi0ndu//k1o1yhKcMxCAxrUqs2XHAUIKWvuuRYTHb2vBRxOXpr9HROh0YyQTZnt//6vb/lMFVkTCAX/gCJAfOGiMSRaRxkDakQJLgbYiklNE8gCtvZUvMTGR+fPm0r6D72wlLl+2jLFff8miBfOJi44gLjqCWTPdOU3h1j69aNqoLtu2bqFy+VKM+ewTRoz6gCcff4QbYiN54bmnGf7eaK/n6tenF00a1mHb1i1UKleSMZ994vUMGfHVXJ4OHjhAs0b1iYuOoEGdOFq2uonmLVq6kmX//n20bdmMurUiaVK/No2bNKPlTW147unHqRMbQd1akSxZtJBXX3/LlXxp3FxOrPllFz/8uI4VYx8jfsKT+InwyXfL6NYyho2TnmXDD8+w79Bxvpi8Mv099aIqkHDgGDsTjng9L8AtN/ekUf0b2LplC+XLhPH5p977HvyXTtMBa+v0SWPMdBEpjNX9GwisB+oCrYwxO0XkeaAnsAs4BCw0xnyU2TSy+zSd7OKrR4le6Wk6TvPV9vJV2XWajhOu5DQdb8jO03SyU1ZP0/G27DhNxwlZPU0nwBth3GSM8c9k+GHghkze9qYx5nkRyQUsBtxdZVVKKXXN+dcX2Cv0oYhUxdonO8YY85PbgZRSSl1btMBmwBjTy+0MSimlrm2+uUNAKaWUusZpgVVKKaUcoAVWKaWUcoAWWKWUUsoBWmCVUkopB2iBVUoppRygBVYppZRygBZYpZRSygFaYJVSSikHaIFVSimlHKAFVimllHKAXos4Gwh6q7PLEeCv63X/Br5620Hw3dvCHUtMdjtCho6sGuF2hAwV9NHb6GWVb86FSiml1DVOC6xSSinlAC2wSimllAO0wCqllFIO0AKrlFJKOUALrFJKKeUALbBKKaWUA7TAKqWUUg7QAquUUko5QAusUkop5QAtsEoppZQDtMAqpZRSDtACq5RSSjlAC6xSSinlAC2wPmTO7FnUrFaZauEVGPrGa27HAWDQwP6UKlGE6Ijqbkf5B19sL/DdNvOV9rrj9gGULVmMWlE1zxs+etRIImtUITayBk8/+ZhL6c6XmppK7dgoOnVo61qG7du20KxebPpPpZKF+WjUcAbd2jt9WK0alWhWL9a1jADvjXiXmMgaxERUZ+TwYV6f/j29G7N2wpPEf/sEY17tR46gAGpUDGXh5w+yZvwTTBx2O3lz5wSgSVxlln39CGvGP8Gyrx+hYWwlRzI5WmBFpKOIGBEJz+L4O0WkcAbDT13mdC9r/It8Tj8RKZEdn3Upqamp3H/vXUyeOpN1GzczYdw3/Lp5szcmfVF9+vZj8rRZbsf4B19tL/DNNvOl9urdpy8/TJlx3rDFCxcwfeoUVsavZ826n7nv/odcyXah90a8S3h4FVczVKhYmR+XruHHpWuYvWglwcG5aNWmPR989nX68NbtOnBT2w6uZdy06Rc++/RjFi9bxcr49cycMZ3t27Z5bfolQvJzZ4+G1L15KDHdhuDvJ3RtEc37z/bk6eFTiO0+hCkLNvLALU0BOHLsNF3u+4DY7kO47dmv+PSlPo7kcnoLtiewFOjh8HSc0g/wSoFds3o15ctXoGy5cgQFBdG1ew+mTZ3sjUlfVL36DbjuuuvcjvEPvtpe4Jtt5kvtVa9+AwoWPL99Pv5oNA8+/Cg5cuQAIKRIETeinWfPnj3MmjmDfv0HuB0l3ZJF8yldthxhpUqnDzPGMGXSd3To0s21XFt++5VacXHkypWLgIAA6jdowJTJP3g1Q4C/H8E5AvH39yM4OIh9h45TsXQRlv60HYD5K3+jQ9PrAdiwZQ/7Dp8AYPPv+8gRFEhQYEC2Z3KswIpIHqAuMACPAisijURkoYhMFJHfRORrEZEL3hssIrNE5LYMPvcREVkjIhtF5IWLTP8tEflJROaJSIg9LEJEVtrv/UFECmY2XES6ADHA1yKyXkSCs6VhMrF3bwJhYSXTn4eGhpGQkODkJK9p2l6Xx9fba/u2bSxftpTG9W+gZbPGrI1f43YkHn3oAV4e8jp+fr6zJ23ydxPo0Pn8Qrpq+VJCQopQrnxFl1JB1arVWbZkCUeOHCExMZHZs2aSsGe316a/99Bxhn05j60zXmTHnJc5cfIM81b+xubf99GmYQ0AOjWLJKxowX+8t2PTCDZs2UNSckq253JyzukAzDLGbAX+FJEoj9cigfuBqkA5rEKcJg8wFRhrjPnI8wNFpDlQEagFRADRItIgg2nnBn4yxkQBi4Dn7OFfAI8ZY2oCP19suDFmIhAP9DbGRBhjzlyQ5XYRiReR+EOHD2WxSTJnjPnHsAvWO5QHba/L4+vtlZKSwrFjR5m/eDkvD3mdvr17ZJjZW2ZMn0ZIkRCioqJdy3ChpKQk5sycRtsOnc8bPum78f8out4WXqUKDz78KG1vak6Htq2oUaMm/gHZv0WYmQJ5g2nTqCZV2jxPuRZPkzs4Bz1uimHQC2MZ1K0+y75+hDy5c5KUnHre+6qUK8bL97bj7lfGOZLLyQLbE0hLPc5+nma1MWaPMeYcsB4o4/HaZOAzY8wXGXxmc/tnHfATEI5VcC90DhhvP/4KqCci+YECxphF9vAxQIPMhl/qjzPGfGiMiTHGxIQUDrnU6JcUGhrGHo81voSEPZQo4ZXe6WuSttfl8fX2Cg0NpV37jogIMbG18PPz4/Dhw67lWbl8GdOnTSW8YlluubknixbMp39fZ/bTZdX8ubOocX0EIUWKpg9LSUlhxtTJtOvU1cVklr63DmD5qrXMmbeIgtddR4UK3tuibhJXmZ0JRzh87BQpKeeYNH8DtWuWY+vOA7S9axR1ew/l21nx7Njz9zwVWqQA49+6jYHPfnne8OzkSIEVkUJAE+BjEdkJPAJ09+gK/stj9FTAc1VnGdDqwm7jtI8GhthblBHGmArGmE+yEMm9VeEsiomNZfv2bezcsYOkpCQmjB9H6zbt3I7ls7S9Lo+vt1ebdu1ZtHABANu2bSUpKYnChf9xvKPXvPjKELbv2M1v23bwxVff0LBxEz4d86VreQAmffctHTp3P2/YkoXzqFCxMiVCw1xK9beDBw8CsPt//2PKpB/o2r3nJd6RfXbvP0qtGmUIzhkIQONaldiyYz8hBfMAVm/N4wNb8tF3SwHInyeY74cP5tkRU1ixYYdjuZzagu0CfGGMKW2MKWOMKQnsAOpl4b3PAkeAURm8Nhvob+/fRURCRSSjoyH87AwAvYClxpjjwFERqW8P7wMsymy4/fgkkDcLma9aQEAA77w7kratWxBRowqdu3ajarVq3pj0Rd1yc08a1b+BrVu2UL5MGJ9/mpX1Gef5anuBb7aZL7XXrX160bRRXbZt3ULl8qUY89kn9Onbn507/qBWVE1u7dOLDz7+zKe6sN2WmJjIkgXz/nGk8OTvJrh6cJOn3j26EH19Nbp0asfb746kYMF/7u90yppfdvHDvPWs+Pox4r99Aj8/4ZPvl9OtZTQbf3iGDd8/zb5Dx/li8koABndvQPmShXn8tpas/OYxVn7zWHoxzk7ixH4OEVkIvGaMmeUx7F6gClbX7cPGmDb28JFAvDHmc3trNwarwH4KHDLGPCoip4wxaUX1PmCg/bGngJuNMb9fMP1TwDvATcBxoLsx5pCIRACjgVzAH8CtxpijFxneGXgVOAPccOF+2DTR0TFm2ar4K24vpa5FKann3I6QKX8/3yzOxxKT3Y6QofzBgW5HyFCh2ve6HSFDZ9eNXGuMibnUeI4U2P8aLbDqv0gL7OXTAnt5rvUC6zvHnyullFL/IlpglVJKKQdogVVKKaUcoAVWKaWUcoAWWKWUUsoBWmCVUkopB2iBVUoppRygBVYppZRygBZYpZRSygFaYJVSSikHaIFVSimlHKAFVimllHKAFlillFLKAXo3nWwgIoeAXdn0cYWBw9n0WdnNV7NprsujuS6P5ro8/4VcpY0xIZcaSQusjxGR+KzcBskNvppNc10ezXV5NNfl0Vx/0y5ipZRSygFaYJVSSikHaIH1PR+6HeAifDWb5ro8muvyaK7Lo7lsug9WKaWUcoBuwSqllFIO0AKrlFJKOUALrMoWIiJuZ1BKqewkIn727ytavmmBVVdNRMTYO/NF5EYRCXU704V8YQXAFzJci0Qkjy+0nYgEuJ3hcni2mYgE+UKOa4mIFATy2U8jruQztMBe49JmXhEJFpFcbmTwKK51gceAk27kyMwFKwBtRaSAyxmaiEhVb2e4IM91Ho8ru5nlYkSkIvAlV7iAy8Yc+YFY+/GNbv//LuWC+e0WoFfa1piXc1QCbnGzwF+F+sBjIvIC8OWVrOhpgb3GGWOMiLQHpgA/ikgfEcnt7Rwi0gUYC7xrjDnhS18oz61r4CHA38UM9wOvA2e8nSGNvaBtIiLDRWQw1kIk36Xe5wZjzDZgB/C4iNR0MUpRoIGITAZGkH2XRnWEx/wWA7QDJhpjznlj2h4r/fWBV4G7gQ4iksMb088uxpgpQC3gPuBOY8wpc5mn3WiBvcaJSDhwF/AU8ArQB+htv+ZY10wGnz0ZOAHcD2CMSRIRrxeyzNhb158BbxtjjrjxZReRJlj/m3rGmB0iEikiTb2dwxhzzhgzEWsN/VXgOXulKNDbWTIjFj8AY8yDWEX2OW8X2bT53BizFQjFWuB+C/zlzRxXQkSigY+xepS8tkJnr/TXB94HPgHWAw2A7r604p2RDJZrw7H+3zfby9rL+zw9D/baJSIVgCFY/8cu9rAbgPFAT2PMMoem69n91AJIBX4BDmF9mX4yxvS1X/c3xqQ6kSOrGe3nubHapYQxJsob2TLIUBF4HDgGnAPigETgc2PMOKdyZJTHXsF4BaiEtWLUzxiT4nSGrLggZyFjzBH78UtAdawVgo1eztEXaAbMByoCfwJjjTF7RaQwcORyt26y24Xzmz3sNqAv8AAQ762MIvIokMcY86w9rw0AOmIV/B+MMUneyHE5Lvh/dwYCgNPGmGkiMhQojtWOnYCzxpgxl/pM3YK9xlywhrUT+AkoaO8XymWMWQGMw7pzhCM8ZsKHsQpGS6z9ZBWBKKC6iEyyx3W1uIpIMxFpAxQEbgbWi8jktOLq1Fb2BRnuEJFOWMV0HlACmIDVdbcY64vsqAvyVAEKG2MeNsa0w+oy/8Z+rZG90uQaj5x3A8NE5FURKW+MeQbYADwjIlFOZhCRfB45amPN43cYYz4DVgFhQBcReRJ4FnC9+9Mj70ARecb+fn6JNa89C8R4cT/sb0CciFQ1xvxljBllD68N+OQ+f4/2uxd4FLge6C8inxtjHgEOAu8AjwDrsvqh+nON/PB3j0M9oCfQzn7+MNZlwJ4EmmDtH6rncJYKWGuiYG0JTQZy2M8DgSVYhURcbK+HgEXASGAhcAOQB/jIfu7nhQx3A2uAChm81tv+ooZ7sU0ewCrq84APsFay8wLfY62srQPKu/U/88h5m50zDNiO1U1X335tKFbhyOHQtMsDTwA5sVbMfgDigToe47QGngFWADXdbi+PXPcBP9rLgY3Ag/bwx+zvZJQD00xbLkUDTYFSQBDW7oensLrVKwEzge+AZ9xup4v8LTnt/3cF+3kQ8DXwmP08HCiS5c9z+w/Sn8ueAVoAP9tFbR7wvT38XmA18C5woz0s2wrIhYUSKA18YU9vmkdx7eSNwpWFvJU82uYx+8vtZ//kA94DSjqcobC9sKtmF/aewINAQ6zu4XlADS+2yc3AEvvxq8Bp4FOP17sAZVz6f8UC7bG2BPPYRbSYPV//CLwGzPYosoUdzFIWKIB15HIFj3n9QTxWPux5Kbcb7eWZ4YI87wCCtdI93W5Pf/v1u7N7nvcorq2ArcDTwAEgxi64jwErsbb6w4GuwBtpmdz+yWC5lgtrpby1x7BWWMduXP7nu/0H6s9lzQx+9he9u8ewmcB79uPnsHbK1wUCs3G64vG4O1AFa81uJNZWT5j92kBgLZexhudQOxXG2iobDnwKzEhrD6wVgHwXfrGyu53s5wF2G43HWnP/BKu77l6srfwCDrfDhXlqYm1d3IXV45Af+B1r6zXA5f9ZL6wVxNb28yCsLcnZHuP8jnXMQS6n28uef16x/2dlsLo1v8TqAajoZltlkr2F/f+ciLVCMhEIsl8bjL3S7dC0q2H3fNg5DmB1ETe1Xw/B6gloAWwGqrvdXhn8v2/AWinPh7U74HfsHgus3pTJWFu3l7XccP2P1J+LzgBBQGX7cRl7Rh0OdPMYpzQwxn4cCLyFtYaY7Qshe8H8M1DOfn4j1pbFAqwtol+Aai63WYSd6Tq7rZZgb3UAt2J1mxVzYLqeX9b2WFurle08XYCy9muD7YWfowXtgjz5gXz247SVtFb28xextjBCXPp/eW6BvQQsBbraz0vZC+q0faDfAaFOt5fHsJJYXZyj7e9fJWCS/T1we4Ukir+35vMCK+3HTe3ikNaGfYFf076z2TTt8lgrqu09hlXCWrGPt58/BiQBTezn+bB2Sbi6fMjk77kHazfOGKxdR82Bm4AEYBTWSkHVK/pst/84/cn0n14I69D227DOm1wP5MY6DWdf2owKNLYXSiH284DsWlhesJCugbV1Gmo/b4i1nyeta68LvrHvLhZrqzoc6yCFD7D2qbwHbHL6Cw7cASwHBgHJQN20tsQq8D9f6Zf1CvM8bBeF9Vj7fMOwDtJ4D6vH43vsHgiX/293Yh1o9TWwG+hoDx8MLLPnPUf+d57FB+s0s8+wDgoqitUb8qzdXuWwuoxLuNxWAfZ8Nt9j/lptF7Gc9nfxD+Dz7G43rEL6C9aK/HJgsMdrA4FR9uOGdr7aHq9nW69aNv49Fe02KobVPdzMXn5UxFpBrspVdKu7/gfqT4b/9CCs/SWdsboY/8I6NSHt9fuw1kqHY61dpXWrObbvE6u4j8Bamx+NtWU4CY+taZfbrFja328vJMfZC6Jy9pemK/ZWZDZP13MlpIjdJvmB/lj7WP09XnsLh4sr1n6vWlj7EJt4LHi7Ya1s9MPa/3sfMNWponU57Ye1RRSftiDD2vpfA3TxaDtHdjtgrchuwdp3WMuer2/GWqmdgnVqRiGsXpG3cXnL9YLct9v/w6bAEHt42vxWEesgw2xrN7vYrAPa2s9vxir0Efbz+lgHo71r//9qpf2P3W4vj78hbRmRtu+4HDD9gnGeBwZmx/T0PFgfJSJ3YXVzfovVzWOwtn6+M8Yk2xdOOIH1hV+X0Tlw2ZSjBfCkMaahiLTF6pr6wRiz0b6EWE5jzGNOTT+LGeOw1p4N1hZbPqxunw+MMX84OF3PU196YhWzLlhbOSWxFkTJIvIQ1v67P42D55qKSGusrvq3sYp7XaCNMaaP/XpzrIVfa2PMHyISaIxJdirPRXJeeH5wEFb33ChghTEmRURexNrf2dUYM8uhHG2w9h+uwWqzA8AIY533GILVFRxh/z6DtXA+7ESWrMig3fJhFbl+WAcVfYV1MYz9WBeXuMtk42lyIlIPWGyMSbsA/kasbtTiWFt9t2H1qNXD6rJ25P92NdLaUERKAfuNdUGcScBx8/e5+69gnbXz9FVP0O01Cv3JdE1LsA5gusN+fh8wDGvfQD2srrNs32LlnwfG+GHt4J9wwfBeePkUk4wyYu13zol1AYK3gDlY3Y0bgJFeytMe68CS8lhb97/w9z7PrnaWMg5naIh1Okucx7AIrMLlOexT7FO4Lvxfu/C/K8PfuxzewDrtpYz9/CaslUun9rm2sf8vaVvJoVhb0R95jFMI62jmcbh81OsF7dYUa+WpqP38Dqx9h/2xdgGUwaHdNVhH1P5hz+/P2sOCsI4gfiizzG7/2G3WzH58D9Yuk6/sZUYBrP37s+15cAP2sS9XPV23/3D9SZ8BcgJ57cel7N8VsLqqimBtlT2Adfmxg3gcRu5QnkrYpyBgXYhgPDDDfl7FXvh57RSTTDLeYX9JPgIa2sOaALcA27C6zws6nCEGa2sxbUWoiL3w+dxeMMfjhaMmsU4huc9+HGD/zo+1Rfs61pZ9P6wDYFzZ53pBkXgQa5/4VDtbsN1mX9rzWjzZeGDOBTmKYR2YF2s/T5vP62NdkvFuj3Gvw8FTgq4g+91YPSXP2PN42rJiMFb3dl0vZGgKpHD+AWoDLiywvvSDtdvhHNYR/KOwjtGojnWU+BdYGxKDsI6TyLaNhmvq9kv/co2BSiJyFHhCRBpgXVIvFWsLZKqIfIB1xOAwY8wWJ7pl7Su9lMQ64GSkiIw3xiTal4pbICLTjDFtRKS/MeZUdk77MnN2xNpS7YHVTdZOREoaY76yX18FJBljjmbzdCtibdnkwjo4IgGraHUXkeXGmA32ZdZqYBWNLcaY/2VnhgvypM0DZYHj9uBUEfEzxhy3L/F2F9YCRbAuTrLHqTwXkzav2l36UVhbkTmwDmzyN8b0E5FIrAXfcuNc9/5fWAegnRWRnMAjItIIq4t4N9bND0KMMc8ZY/50KMNlE5FmWIWiMdb/NAewUUSijDGjRSQVcGxeS2OMmSci7bC2WiuIdcnWR7CKl8+xvyPfiMhfWCvk3xljfhPr9oMPYPXqRBtjPsj2ibu9ZqE/6WtYflhr1Sexu63s4Y2w9hFFOzjtjE5RqIe1ZXYLf6/hP4l1ErYj3XaXyNgA+9QS+/mjwFP2Y3+srbPvcegcSXs6rbH2Nf2AtZW6E6sYhAEvYB0E5so5flhb7j+mzSf2/JS2JfsAVo+EI1c+upz5DOvI7o1YC7W0A3JKY18kxYs5HsLqEtyDteU8EKvb9TWsLer0I/PdbK8Lnl+Htb+zL/CjPexLrNNhHL1oSib5WmJd/nMT0NLNtsrC/zvteKPOWFuyDT1eHwt0cmLaei1i31EF64u+GIgUkdL2QSgLsbr42ohDt6EzaXOhyK0i8pGIvMzfd8bpCwwWkeexToHpYoxJcCLHJRQFvhCRlvbzTVjXOq1pjEk1xnyOdQWg8k5M3J7uM8ADxpiOxphmWKdzTMPqVXgPOAw8LO7cX3UVVlHoLiLRxrpjToqI9MA6teuMMcbrd4DxvHa2sWzAWhGpgPX/CzTG7MK6gElNESl6wfW2s509v3+AdbTog8AgY8zHxro5RgmsfXD1jTGHnMxxMRccQFdZRKoYY/40xuzD6mH6wR51IdZxB16/FrKxDmJqCzxtfPCApjQe7SjGmO+wvg8/isjT9pZ4NawDSLOdHkXsA0SkHNYlzgZh7V/9Bqu76gmsfXx1sL74Q4wxe7NpmmlH06X9vs2e/lB7Wv2xTgM4jnVR+uuBV40xjsyIF8kZjXVXjkX2BfPfxOoaXoZ1Mrs/1vl4fljndbbI7gWjWDcnP4zVvTpNRHIaY87ar72AdcBXTaxTI1oAXxpj9mdnhizmDMXaF9YUq9fjLNZRzV2MMb94O88F2bpgbYGtMlY3+iCsrYkX7WHJIhJgXLyjj4h0xbp5RXdjzHa3cngSkQexek6SsVZ6B2PtEqmO9f+NwDpVzuvzmyc3zyK4UGZZ7N1fxl7edcXa1z8aa7nmzG4Ttzff/4s/WAdZxGIVhQpYR+W96fF6HqyDiD4G9mIttBtmc4YyF0zvPuAmj2EdsI4eTuseduX6wlhbGEv5+6o1XbH2eTbA2u84GOto6wnA9Q7maI21llvIfp7D47WFQOSFw11qr2Cs7v3nsVaYKrmUI5fH4/uxDsB5Dms3yCB7+ECsLe8bXG6z4nbGTfjIZfzsXDcCM+3HL2NfNhJrRaUnVs+Wz+T1hR/OP5CuFdb535WB4LTX+XvD8iay6WjhTPO43SD/xR97weL5T38Z68IRpTzGCcbaco3wnHHIYH/pFUy/DdYBCjmxtlJfxeoym+QxTlGsfRMFXGojzy/KXcBcoIH9vJtdZNOudRqMg/tePXK0sqdb0H6edn3jyfjQHVXc/rFXRoZhnfoSB4y3hz+MtQ/7Q+wrAGHt4y/lVlaP+ac1GdzxyOVcUVg9SS9j7S9Om99cXSHxxZ8Ll4tYK+aLsfapr8I+RSdt3OxYjmYpl9sN81/9wTqd41Ogsf38dXtGyPAybNk1Q/D3Bbcr20X0e4/XFmLtV/THOjp3Ge5fuD/t6j6DLyiynbGOsm7u5TwXFtlb7P+bq+3kKz/8fX5pB/t5sF1oW9vzVwDW1vUm7C1Z/cmwQAjWbofVWDerSFvBHojVG1DQW0XiWvjBPpWKv3sFx9nP7wdm2cMDvd1mepqOl6QduGHs/7ox5qCI7AF6ikiysa6G9CowV0SamwsOJEp731VmaI51ztdSrCM3hwAhIlLNGLMJa+H4gz1OBWCAMebg1U73KvLWBB4VkYnGOg1BsG62/aIx5jsRScbqXvcaY8xMsW4EvlhERmEdMOFqO/kKESmGdXTuQGPMGhEJxjpiU7AO4ptjrAOv/sDauvgh80/7b0n7fovIfViFdSfWpVCHY61c3ikiRbF23fQ02Xz62bXKXiaEADtEpKcxZoqI/AkcEpGxWCsibYwx50SkG9YuigPeyqcF1gtEJIexj+AUkTpYM8QKY8yzIvIw0N/eL/+kiARiXYklW4/UFZGmWNc1fgBrH3AU1j7FMkCsiBw31o7+G+2jlf2NMSeyM8Ml8p23AmI/3igi64AWInLOGPO+iBjgLRG53xgzxVv5PNlF1h/rtKBIe+VE/fP80sew9genYO03jLHPmayDdcCYrpSI5DLGJNqP62EdlPYBVpH9HKuH5CDWQU3+WAesbXUnrW+yN1b6A5+JSD9jXTPgNBAJ3G6v1PXF2kWxxJvZ9Chih4lIAawLwA/G6qaYgnVJu/8B0+w1rgexDnp63xiz2KEcsVj7cJaLSBWsLuAzWJcJK4S1VbvQWKdMeJ3nEaRiXf+4iDHmS/v5vVhHS35rjJllf5l+NA5ewCErPBeOKn0l6UGs231VwzovdynW8QVpt/9KBJYaHzlK101iXTv6RqzLRDbAOjr+DfP3tZDvwSqs97s9r18L7FPpvsW6dOmvWLsiQoFDWMcCdPP2yrAWWC8Qkcf4+xZSzxnrKiKDsK72M8cuso8Cs4wxGx3O4md3l1TGOr3kNNYl9cpjFf/xJhsvEJ7FTDdiHcyxAevgK7AuHP6pMWaCPc6nWGv1zxhjZnozn8o6EcmDNV+XBCZ79NyMAaYY6zzE/zyxbjTwCtb1fCeLSElgOtYVrAbb4xTC6gUoi/VdTTXGnHMrsy9JW47Zj3sBxY0xb9mng32KdUbEUrvHsBCwwY2VFL3QhIM8uj1fxzrfqi3W7ZHAOq1kI9BeRDoaY95wurjaWc7Zv7dgHSWcE6tb71dggQvFtSXWgmY51i3xWgKnsL4kfez9JmCdTP8b1uUJlY8yxpwyxqwwxnzrUVy7Ym2JrXc1nI+4YF/1ZBHJbYzZjbUF28Lex48x5gjWUbB3GGOStbhaROR6YLr8feGdUOAIgDFmItZV3Sbby9XlxpipbvUA6D5Yh3hcwKEe1q2QPhGRwsDrInLAGLNWRCZi7VdxZZ+Ksa5nPBHrQhIf2V9or7Ev4DADaG/vNymF1V2WA5hoj/aiiLTH6nLsovvtrh0iUhzrCk23YV284XeXI/mKa/JayL7CWBcqSQHGi3VN8gJY3cBpr39vb9wMF5G5QKJbKyfaRewgEWmFdQm9vsaYJfawO7G6Q+8yxqxy++o1diZX7gtqT7s1VlG9wRhzQkS+xrrn5Af269Ww7nIyVxfQ1xb7KOImWDc8+M/vc01ziX3VbbGuGtYB6GhcvFyjr7HbzS+tl01EvsO6DvPv9u9fsVZewDrFMNEYc8aNrGm0wDpErMvWzQBuM8astrs18mHdYqoTVndQHeDUf73rx14RGY51Mn0JoLcx5kxaL4C76ZTKfhfZV/0F1gX8f9R5/2+eywIRCU07jVGsO4zdhnXkddrxJMHAk75wYJgW2GwiIlWx7o863n6eH+vi8IlYp+VUxDof8BtjzMciUtYYs8O1wD5GrFtxzQGK2Yfdp1/vV6n/AvHBayH7gguK691Ab6xjMUYZYzaLyHtYF6RpZ48TZIxJci/x3/Qgp2wgIpWw7mmZfrcbY8xxrCsmBWFdgrAZ1n7FaPt1La4ejDE/Yl3tZ4GIFNHiqv4rRKS4iNyPdVpJXy2u5/Morh2wdjncjbWx8v/27jbW6zGO4/j706EVRcwIm1WkRqtIJrlJWrNJbqat1kbTkpu5ndQWxjBt8YQ2khmrhZRo3Uh5kEohqUR3E+ZBD2LEoif19eC6Dr8dp/qfc/r1P399XtvZ+d9c//91/Xpwvl3X77q+3/GSBkTEvUAbSfX3Xqt6y63Im5xaKB93WQjMjYjX82vt89r/TOBAROxXKjI9nrTt3hqREzi0BT6UdAm58kW1x2VWst9It45udHBtnKSepMpLs/MG0Z2kAiUjJdVFxDBJZ+W/F63mb4ZnsC2Ql4VnkdKa7ZE0ECDfP+wGzAA6K6X8e4h05m1p/fEd+6+I+ICUb/iAg6sdCyLir4hY5OD6L6W0kEW/kzKnjc6z1l+BF0ibm4bnW0pHpJTnkeR7sM2Ud0guJpWUW0g619aWlLVpHanCyqcR8Wxuf2ZE7PLGHTOzg8uz1W9JFZm2RMSM/Ho7Uka8a0k1XNfkzWLtIuLnao33UBxgW0BS58iFjvNS8WjSsvs6YHtEbC5mHDEzs0PLWa3eJmWWG0w6HzyHlAhnr6R7SeerH42ItdUb6eF5ibgFCsG1Tc6MNJN0g70P6fAzDq5mZpXLWa0+JxUkuR5YQjqKs1hSP1JK1Wkc4YIoZXCAPQIK6Qd3kIJsO9J9gVOqOjAzsxpS2J8ykbRZ6TRgF+nM8FZgMqlQydIciFs1LxGXQFJ3+CfgmplZhXKQbUvKI9CNNJOdFBHv5yORu6NG6uE6wJqZWauT97WsBF6KiKerPZ7m8BKxmZm1Onlfy0SgTtIJ1R5PczjAmplZa7WGnP2uFnmJ2MzMWi1JJ0TEn9UeR3M4wJqZmZXAS8RmZmYlcIA1MzMrgQOsmZlZCRxgzY5BkgZJWpgfD5c06RBtO0m6pxl9PCnpkUpfb9DmDUm3NqGvLpI2N3WMZmVygDX7H5FU19TPRMSCiJhyiCadgCYHWLNjnQOsWQ3IM7Stkt6UtEnS3PrD95J+kPSEpFXACElDJa2RtF7Su7mkF5Kuy9+xCril8N1jJE3Lj8+QNF/SxvxzOTAFOFfSBklTc7sJkr7IY3mq8F2TJW2TtBzoUcF1jcvfs1HSvAYJBYZIWilpu6RhuX2dpKmFvse39N/WrCwOsGa1owfwakT0JhWgLs4q90XEFcBy4DFgSERcTCqd+HCupTkDuAG4Euh8kD5eBFZERB9SDthvgEnAdxHRNyImSBoKdAcuBfoC/SRdlSudjAQuIgXw/hVc03sR0T/3twUYW3ivC3A1qaLKK/kaxgJ7IqJ//v5xkrpW0I/ZUXdctQdgZhX7KSJW58ezgPuB5/Pzd/Lvy4ALgNW5MElbUjacnsD39QUoJM0C7mykj8HAbQARsR/Y00hVqKH556v8vAMp4HYE5tcnBZC0oIJr6iXpGdIydAdgaeG9OblS1Q5JO/M1DAV6F+7Pnpz73l5BX2ZHlQOsWe1omBWm+Hxv/i1gWUSMKjaU1LeRzzeXgOciYnqDPh5sRh9vADdFxEZJY4BBhfcau14B90VEMRAjqUsT+zUrnZeIzWrHOZIG5MejgFWNtFkLDJR0HqQ0c7nE11agq6RzC59vzMfA3fmzdZJOAv4gzU7rLQXuKNzbPVvS6cAnwM2S2kvqSFqOPpyOwC5JxwOjG7w3QlKbPOZuwLbc9925PZLOl3RiBf2YHXUOsGa1Ywtwu6RNwKnAyw0bRMRuYAzwVm63FugZEftIS8KL8ianHw/SxwPANZK+Br4ELoyIX0hLzpslTY2Ij4DZwJrcbi7QMSLWk5aqNwDzSKXGDudx4DNgGek/AUXbgBXAEuCufA2vAd8C6/OxnOl4Jc5aKeciNqsBeQl0YUT0qvZYzKwynsGamZmVwDNYMzOzEngGa2ZmVgIHWDMzsxI4wJqZmZXAAdbMzKwEDrBmZmYlcIA1MzMrwd+tN6zC0X7nigAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from torchmetrics import ConfusionMatrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "# 2. Setup confusion matrix instance and compare predictions to targets\n",
        "confmat = ConfusionMatrix(num_classes=len(class_names))\n",
        "confmat_tensor = confmat(preds=y_pred_tensor,\n",
        "                         target=test_data.targets)\n",
        "\n",
        "# 3. Plot the confusion matrix\n",
        "fig, ax = plot_confusion_matrix(\n",
        "    conf_mat=confmat_tensor.numpy(), # matplotlib likes working with NumPy\n",
        "    class_names=class_names, # turn the row and column labels into class names\n",
        "    figsize=(10, 7)\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "381c1c93-df30-451c-b65e-5d4c1680dc30",
      "metadata": {
        "id": "381c1c93-df30-451c-b65e-5d4c1680dc30"
      },
      "source": [
        "Woah! Doesn't that look good?\n",
        "\n",
        "We can see our model does fairly well since most of the dark squares are down the diagonal from top left to bottom right (and ideal model will have only values in these squares and 0 everywhere else).\n",
        "\n",
        "The model gets most \"confused\" on classes that are similar, for example predicting \"Pullover\" for images that are actually labelled \"Shirt\".\n",
        "\n",
        "And the same for predicting \"Shirt\" for classes that are actually labelled \"T-shirt/top\".\n",
        "\n",
        "This kind of information is often more helpful that a single accuracy metric because it tells use *where* a model is getting things wrong.\n",
        "\n",
        "It also hints at *why* the model may be getting certain things wrong.\n",
        "\n",
        "It's understandable the model sometimes predicts \"Shirt\" for images labelled \"T-shirt/top\".\n",
        "\n",
        "We can use this kind of information to further inspect our models and data to see how it could be improved.\n",
        "\n",
        "> **Exercise:** Use the trained `model_2` to make predictions on the test FashionMNIST dataset. Then plot some predictions where the model was wrong alongside what the label of the image should've been. After visualing these predictions do you think it's more of a modelling error or a data error? As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25818e83-89de-496d-8b56-af4fc9f2acc5",
      "metadata": {
        "id": "25818e83-89de-496d-8b56-af4fc9f2acc5"
      },
      "source": [
        "## 11. Save and load best performing model\n",
        "\n",
        "Let's finish this section off by saving and loading in our best performing model.\n",
        "\n",
        "Recall from [notebook 01](https://www.learnpytorch.io/01_pytorch_workflow/#5-saving-and-loading-a-pytorch-model) we can save and load a PyTorch model using a combination of:\n",
        "* `torch.save` - a function to save a whole PyTorch model or a model's `state_dict()`.\n",
        "* `torch.load` - a function to load in a saved PyTorch object.\n",
        "* `torch.nn.Module.load_state_dict()` - a function to load a saved `state_dict()` into an existing model instance.\n",
        "\n",
        "You can see more of these three in the [PyTorch saving and loading models documentation](https://pytorch.org/tutorials/beginner/saving_loading_models.html).\n",
        "\n",
        "For now, let's save our `model_2`'s `state_dict()` then load it back in and evaluate it to make sure the save and load went correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d058e8fa-560f-4350-a154-49593ff403c9",
      "metadata": {
        "id": "d058e8fa-560f-4350-a154-49593ff403c9",
        "outputId": "49baa26a-c9cf-4418-f1f1-ed546fd02548"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model to: models/03_pytorch_computer_vision_model_2.pth\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Create models directory (if it doesn't already exist), see: https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, # create parent directories if needed\n",
        "                 exist_ok=True # if models directory already exists, don't error\n",
        ")\n",
        "\n",
        "# Create model save path\n",
        "MODEL_NAME = \"03_pytorch_computer_vision_model_2.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "# Save the model state dict\n",
        "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=model_2.state_dict(), # only saving the state_dict() only saves the learned parameters\n",
        "           f=MODEL_SAVE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1542284-8132-42ba-b00d-57e9b9037e4e",
      "metadata": {
        "id": "a1542284-8132-42ba-b00d-57e9b9037e4e"
      },
      "source": [
        "Now we've got a saved model `state_dict()` we can load it back in using a combination of `load_state_dict()` and `torch.load()`.\n",
        "\n",
        "Since we're using `load_state_dict()`, we'll need to create a new instance of `FashionMNISTModelV2()` with the same input parameters as our saved model `state_dict()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "634a8f7a-3013-4b45-b365-49b286d3c478",
      "metadata": {
        "id": "634a8f7a-3013-4b45-b365-49b286d3c478"
      },
      "outputs": [],
      "source": [
        "# Create a new instance of FashionMNISTModelV2 (the same class as our saved state_dict())\n",
        "# Note: loading model will error if the shapes here aren't the same as the saved version\n",
        "loaded_model_2 = FashionMNISTModelV2(input_shape=1,\n",
        "                                    hidden_units=10, # try changing this to 128 and seeing what happens\n",
        "                                    output_shape=10)\n",
        "\n",
        "# Load in the saved state_dict()\n",
        "loaded_model_2.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
        "\n",
        "# Send model to GPU\n",
        "loaded_model_2 = loaded_model_2.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feeaebf4-6040-4fa5-852d-5eb8d2bbb94c",
      "metadata": {
        "id": "feeaebf4-6040-4fa5-852d-5eb8d2bbb94c"
      },
      "source": [
        "And now we've got a loaded model we can evaluate it with `eval_model()` to make sure its parameters work similarly to `model_2` prior to saving."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e3bcd06-d99b-47bc-8828-9e3903285599",
      "metadata": {
        "id": "3e3bcd06-d99b-47bc-8828-9e3903285599",
        "outputId": "5d09337c-9882-4811-f95c-db9ee3a3a15d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model_name': 'FashionMNISTModelV2',\n",
              " 'model_loss': 0.32664385437965393,\n",
              " 'model_acc': 88.22883386581469}"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Evaluate loaded model\n",
        "torch.manual_seed(42)\n",
        "\n",
        "loaded_model_2_results = eval_model(\n",
        "    model=loaded_model_2,\n",
        "    data_loader=test_dataloader,\n",
        "    loss_fn=loss_fn,\n",
        "    accuracy_fn=accuracy_fn\n",
        ")\n",
        "\n",
        "loaded_model_2_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2b37855-c0da-4834-a2d4-a0faa8410b65",
      "metadata": {
        "id": "c2b37855-c0da-4834-a2d4-a0faa8410b65"
      },
      "source": [
        "Do these results look the same as `model_2_results`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68544254-c99a-47ec-a32f-9816c21a993e",
      "metadata": {
        "id": "68544254-c99a-47ec-a32f-9816c21a993e",
        "outputId": "133a74af-58d8-4217-84a5-f47a77c6ffd3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model_name': 'FashionMNISTModelV2',\n",
              " 'model_loss': 0.32664385437965393,\n",
              " 'model_acc': 88.22883386581469}"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_2_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ee07f93-4344-4c7a-8b1d-92a56034e7b2",
      "metadata": {
        "id": "0ee07f93-4344-4c7a-8b1d-92a56034e7b2"
      },
      "source": [
        "We can find out if two tensors are close to each other using `torch.isclose()` and passing in a tolerance level of closeness via the parameters `atol` (absolute tolerance) and `rtol` (relative tolerance).\n",
        "\n",
        "If our model's results are close, the output of `torch.isclose()` should be true."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48dcf0ba-7e00-4406-8aaa-41918856361a",
      "metadata": {
        "id": "48dcf0ba-7e00-4406-8aaa-41918856361a",
        "outputId": "748451ac-37c5-4662-9093-c36abc249f34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check to see if results are close to each other (if they are very far away, there may be an error)\n",
        "torch.isclose(torch.tensor(model_2_results[\"model_loss\"]),\n",
        "              torch.tensor(loaded_model_2_results[\"model_loss\"]),\n",
        "              atol=1e-08, # absolute tolerance\n",
        "              rtol=0.0001) # relative tolerance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3969b7d-9955-4b6f-abf8-fe8eedf233a9",
      "metadata": {
        "id": "c3969b7d-9955-4b6f-abf8-fe8eedf233a9"
      },
      "source": [
        "## Exercises\n",
        "\n",
        "All of the exercises are focused on practicing the code in the sections above.\n",
        "\n",
        "You should be able to complete them by referencing each section or by following the resource(s) linked.\n",
        "\n",
        "All exercises should be completed using [device-agnostic code](https://pytorch.org/docs/stable/notes/cuda.html#device-agnostic-code).\n",
        "\n",
        "**Resources:**\n",
        "* [Exercise template notebook for 03](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/03_pytorch_computer_vision_exercises.ipynb)\n",
        "* [Example solutions notebook for 03](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/03_pytorch_computer_vision_exercise_solutions.ipynb) (try the exercises *before* looking at this)\n",
        "\n",
        "1. What are 3 areas in industry where computer vision is currently being used?\n",
        "2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find.\n",
        "3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each. **Note:** there are lots of these, so don't worry too much about all of them, just pick 3 and start with those.\n",
        "4. Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
        "    * Upload your own example image using the \"upload\" button and see what happens in each layer of a CNN as your image passes through it.\n",
        "5. Load the [`torchvision.datasets.MNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) train and test datasets.\n",
        "6. Visualize at least 5 different samples of the MNIST training dataset.\n",
        "7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`.\n",
        "8. Recreate `model_2` used in this notebook (the same model from the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/), also known as TinyVGG) capable of fitting on the MNIST dataset.\n",
        "9. Train the model you built in exercise 8. on CPU and GPU and see how long it takes on each.\n",
        "10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label.\n",
        "11. Plot a confusion matrix comparing your model's predictions to the truth labels.\n",
        "12. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?\n",
        "13. Use a model similar to the trained `model_2` from this notebook to make predictions on the test [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html) dataset.\n",
        "    * Then plot some predictions where the model was wrong alongside what the label of the image should've been.\n",
        "    * After visualing these predictions do you think it's more of a modelling error or a data error?\n",
        "    * As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?\n",
        "\n",
        "## Extra-curriculum\n",
        "* **Watch:** [MIT's Introduction to Deep Computer Vision](https://www.youtube.com/watch?v=iaSUYvmCekI&list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&index=3) lecture. This will give you a great intuition behind convolutional neural networks.\n",
        "* Spend 10-minutes clicking thorugh the different options of the [PyTorch vision library](https://pytorch.org/vision/stable/index.html), what different modules are available?\n",
        "* Lookup \"most common convolutional neural networks\", what architectures do you find? Are any of them contained within the [`torchvision.models`](https://pytorch.org/vision/stable/models.html) library? What do you think you could do with these?\n",
        "* For a large number of pretrained PyTorch computer vision models as well as many different extensions to PyTorch's computer vision functionalities check out the [PyTorch Image Models library `timm`](https://github.com/rwightman/pytorch-image-models/) (Torch Image Models) by Ross Wightman."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "3fbe1355223f7b2ffc113ba3ade6a2b520cadace5d5ec3e828c83ce02eb221bf"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7442511b-bfe9-4ec7-9f5b-9c808f8e560b",
        "3b76784d-4cdb-43d2-a6da-8e4da9a812a9",
        "d7893907-5f82-4c5e-8fde-fa542a9f25af",
        "b54a4e9d-a7ad-404c-920f-485fcff18a92",
        "1eb30af6-a355-49a2-a59f-25169fd27a6e",
        "ac22d685-1b8d-4215-90de-c0476cb0fbdf",
        "9c358955-1d20-4903-b872-a239d2753d88",
        "6478cc5a-7b33-425d-9ab3-6d40168a1aee",
        "6370d45d-ca44-4fa0-a2d7-efaf0a207b91",
        "39a3c646-52f0-4f4b-8527-2fc33d0dfb13",
        "758bc223-a244-4604-a07a-e2fc2f96c2f6",
        "24c5ff68-b0bc-4b09-9da6-696736bc262d",
        "0ba50d51-adb3-4e49-9b9a-85173e747352",
        "ab108078-6770-4cb9-ac62-a761ff159aba",
        "25818e83-89de-496d-8b56-af4fc9f2acc5",
        "c3969b7d-9955-4b6f-abf8-fe8eedf233a9"
      ],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1d3fc81888b945319bb25135d2594c58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2c6fde355824f5caa73c0e1c5e1d4b6",
              "IPY_MODEL_d8889e84a3484ed6a5b7b43d571a3439",
              "IPY_MODEL_7c1b38953b7d41a5baf80174726b8e8f"
            ],
            "layout": "IPY_MODEL_a0836412b4db4586ba8f2463573b39e7"
          }
        },
        "a2c6fde355824f5caa73c0e1c5e1d4b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6e5057dec9340e6bbe0f57c35e5e8f6",
            "placeholder": "",
            "style": "IPY_MODEL_365b29782c984b4aafbc47e97cce55ad",
            "value": "100%"
          }
        },
        "d8889e84a3484ed6a5b7b43d571a3439": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73f668aae3db427e9ed6b15d9bc483dd",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4f47ee32ab147e1980487b68844974d",
            "value": 3
          }
        },
        "7c1b38953b7d41a5baf80174726b8e8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca61dba35b08488f9d20f60fe436a09e",
            "placeholder": "",
            "style": "IPY_MODEL_ea70f864b12f441cb9f38a00a86144ff",
            "value": " 3/3 [00:23&lt;00:00,  7.90s/it]"
          }
        },
        "a0836412b4db4586ba8f2463573b39e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6e5057dec9340e6bbe0f57c35e5e8f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "365b29782c984b4aafbc47e97cce55ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73f668aae3db427e9ed6b15d9bc483dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4f47ee32ab147e1980487b68844974d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca61dba35b08488f9d20f60fe436a09e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea70f864b12f441cb9f38a00a86144ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}